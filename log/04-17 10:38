INFO:root:
 ======== Start Log Recording :04-17 10:38 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 0.007391088864887538

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0008418311481364071 -->grad_value: 0.00016385765047743917 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00010643562563927844 -->grad_value: 1.7607295621502317e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0009067998034879565 -->grad_value: 1.5842218203943048e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0006060600280761719 -->grad_value: 1.5842218203943048e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.000689135689754039 -->grad_value: 0.00011268779053352773 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001147258299170062 -->grad_value: 1.0146414819445226e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.00274044182151556 -->grad_value: 1.953075923211145e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0003757619997486472 -->grad_value: 1.953075923211145e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -5.694558421964757e-05 -->grad_value: -2.204593698706958e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0002671605907380581 -->grad_value: 5.255367341305828e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.00814731139689684 -->grad_value: 6.915161065990105e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.006580565590411425 -->grad_value: 6.915161065990105e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 3.108550299657509e-05 -->grad_value: -5.219902021735834e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00014825641119387 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.006496069952845573 -->grad_value: 2.8807144190068357e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0017450230661779642 -->grad_value: 2.8807144190068357e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0009584269719198346 -->grad_value: -0.0002842349058482796 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.05598116293549538 -->grad_value: 0.0367613285779953 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.007031091294872264

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0011465633288025856 -->grad_value: 0.00014726338849868625 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00010808162187458947 -->grad_value: 9.68049307381591e-10 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008135756943374872 -->grad_value: 1.2285762807096035e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.000699283613357693 -->grad_value: 1.2285762807096035e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0008365315734408796 -->grad_value: 0.00011428196739871055 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001154782366938889 -->grad_value: 9.819857149651057e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0030821473337709904 -->grad_value: 1.945962111449262e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0007174669881351292 -->grad_value: 1.945962111449262e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00011184947652509436 -->grad_value: -2.70321947937191e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0005988114280626178 -->grad_value: 9.067545079233241e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.022999783977866173 -->grad_value: 8.452462498098612e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.021433034911751747 -->grad_value: 8.452462498098612e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.505375495180488e-05 -->grad_value: -6.519645978642075e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00014825641119387 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.017921283841133118 -->grad_value: 4.229225669405423e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.013170236721634865 -->grad_value: 4.229225669405423e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0010100860381498933 -->grad_value: -0.0008916090591810644 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.07100629806518555 -->grad_value: -0.008383885025978088 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.006792519520968199

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0012734124902635813 -->grad_value: -8.156959665939212e-06 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012595673615578562 -->grad_value: -1.325391019157962e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00047111057210713625 -->grad_value: -2.038190416442376e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0010417490266263485 -->grad_value: -2.038190416442376e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0008926562150008976 -->grad_value: -7.625752004969399e-06 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00011459746747277677 -->grad_value: -1.4073452472840309e-11 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.003266784828156233 -->grad_value: -7.1600325668441656e-09 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0009021043661050498 -->grad_value: -7.1600325668441656e-09 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00011152085062349215 -->grad_value: -5.003047220952794e-08 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0009175310842692852 -->grad_value: -1.1332158322829855e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.02801503986120224 -->grad_value: -5.643995564241777e-07 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.026448294520378113 -->grad_value: -5.643995564241777e-07 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 1.364638956147246e-05 -->grad_value: -8.07639892741463e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00014825641119387 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.02119186706840992 -->grad_value: -2.5738549993548077e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.016440818086266518 -->grad_value: -2.5738549993548077e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000982189434580505 -->grad_value: -0.00014274894783739 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.07037066668272018 -->grad_value: -0.015568922273814678 

