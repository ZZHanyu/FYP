INFO:root:
 ======== Start Log Recording :04-17 11:27 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 9.74360137173663

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9984989166259766 -->grad_value: -0.01585078425705433 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight 0.004137757699936628 -->grad_value: -0.014675436541438103 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00032515375642105937 -->grad_value: -0.00030944510945118964 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -1.396754669258371e-06 -->grad_value: -1.6068588593043387e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.002072078175842762 -->grad_value: -0.0023038608487695456 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0037650023587048054 -->grad_value: -0.0023038608487695456 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0016250130720436573 -->grad_value: -0.00031067372765392065 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00011084951984230429 -->grad_value: -4.96611392009072e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0003424372698646039 -->grad_value: -0.0013503858353942633 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0021030509378761053 -->grad_value: -0.0013503858353942633 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0001973594626178965 -->grad_value: -1.6584308468736708e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018894660752266645 -->grad_value: -3.358624962856993e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.004168483428657055 -->grad_value: -0.004742036573588848 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.005306572653353214 -->grad_value: -0.004742036573588848 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0002108460757881403 -->grad_value: -3.800140575549449e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -3.298534647910856e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002708577550947666 -->grad_value: -0.0011040506651625037 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0006800642004236579 -->grad_value: -0.0011040506651625037 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0024950990919023752 -->grad_value: -0.013783168978989124 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.017762018367648125 -->grad_value: -2.9147095680236816 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.6884919541577498

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9979464411735535 -->grad_value: -0.0018698192434385419 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight 0.0045298198238015175 -->grad_value: 0.006974848918616772 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00034026900539174676 -->grad_value: -3.5891865991288796e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -1.4099787222221494e-06 -->grad_value: -5.327118515197071e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0020835830364376307 -->grad_value: 0.0011950454208999872 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.003776507917791605 -->grad_value: 0.0011950454208999872 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0016225330764427781 -->grad_value: -5.378058267524466e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00011444708798080683 -->grad_value: 1.7146460322692292e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0003754865610972047 -->grad_value: 0.0007938540074974298 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.002070001792162657 -->grad_value: 0.0007938540074974298 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00020132248755544424 -->grad_value: 4.346440618974157e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001928709534695372 -->grad_value: 1.9628938389359973e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.004204764496535063 -->grad_value: 0.002577822655439377 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.005342853255569935 -->grad_value: 0.002577822655439377 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.00021088948415126652 -->grad_value: 5.779411935691314e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -3.298534647910856e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0027073100209236145 -->grad_value: 0.0005693677812814713 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0006813318468630314 -->grad_value: 0.0005693677812814713 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0025466708466410637 -->grad_value: 0.0068244547583162785 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.017123229801654816 -->grad_value: 1.492385745048523 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.7037133002281188

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.998305082321167 -->grad_value: 0.001768993097357452 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight 0.004570577759295702 -->grad_value: -0.013734580017626286 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0003418399428483099 -->grad_value: 0.0001543177932035178 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -1.411393895978108e-06 -->grad_value: -8.043724051276513e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0020847793202847242 -->grad_value: -0.0024400027468800545 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0037777035031467676 -->grad_value: -0.0024400027468800545 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0016222756821662188 -->grad_value: 0.00011131283827126026 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00011482113040983677 -->grad_value: -3.1896436212264234e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.00037892229738645256 -->grad_value: -0.0015493042301386595 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0020665661431849003 -->grad_value: -0.0015493042301386595 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00020173451048322022 -->grad_value: -9.688850695965812e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001932788291014731 -->grad_value: -3.6357188946567476e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00420853728428483 -->grad_value: -0.00520112831145525 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.00534662464633584 -->grad_value: -0.00520112831145525 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.00021089400979690254 -->grad_value: -1.4141093060970888e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -3.298534647910856e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002707177773118019 -->grad_value: -0.0011272873962298036 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0006814636290073395 -->grad_value: -0.0011272873962298036 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0025520320050418377 -->grad_value: -0.013113442808389664 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.017056824639439583 -->grad_value: -2.934983491897583 

INFO:root:
 ======== Start Log Recording :04-17 11:27 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

