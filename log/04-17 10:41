INFO:root:
 ======== Start Log Recording :04-17 10:41 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 0.6762815117835999

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00021977978758513927 -->grad_value: -0.002864519599825144 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.1392974304035306e-05 -->grad_value: 1.7578545907781518e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0022787610068917274 -->grad_value: -1.5535083548456896e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0018111544195562601 -->grad_value: -1.5535083548456896e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0016202848637476563 -->grad_value: -0.009482390247285366 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -2.6457695639692247e-05 -->grad_value: -5.984960971261444e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.001348329707980156 -->grad_value: -2.1921890947851352e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0034335721284151077 -->grad_value: -2.1921890947851352e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -2.264838622068055e-05 -->grad_value: 4.141232238907833e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -2.6478377549210563e-05 -->grad_value: -2.346300971112214e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.002079468220472336 -->grad_value: -0.0010718896519392729 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0017389055574312806 -->grad_value: -0.0010718896519392729 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.00024942777235992253 -->grad_value: 6.14874079474248e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0006917384453117847 -->grad_value: -0.000469001242890954 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0035501262173056602 -->grad_value: -0.000469001242890954 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.004059375263750553 -->grad_value: -0.010562391020357609 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0017977961106225848 -->grad_value: -1.5685697793960571 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.6963096049924692

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00019218371016904712 -->grad_value: -0.002180923707783222 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.471980405971408e-05 -->grad_value: 1.392160555724331e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0023025614209473133 -->grad_value: -7.320677468669601e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0017873547039926052 -->grad_value: -7.320677468669601e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.00166642339900136 -->grad_value: -0.007710605394095182 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -2.9206792532932013e-05 -->grad_value: 7.255336242906196e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0014096539234742522 -->grad_value: -1.369333767797798e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0034948959946632385 -->grad_value: -1.369333767797798e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -3.2373645808547735e-06 -->grad_value: -0.0001796901924535632 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 2.334960299776867e-06 -->grad_value: 2.9779115720884874e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0021239875350147486 -->grad_value: 0.0028659121599048376 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0016943865921348333 -->grad_value: 0.0028659121599048376 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0002487337915226817 -->grad_value: -4.568898475554306e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0006116528529673815 -->grad_value: -6.459198630182073e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.003630212042480707 -->grad_value: -6.459198630182073e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.004131731577217579 -->grad_value: 0.014185133390128613 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.003609295003116131 -->grad_value: 0.7841699719429016 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.7579287374019623

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00016460439655929804 -->grad_value: 0.013192171230912209 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.777996996883303e-05 -->grad_value: 6.173445399326738e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0023197655100375414 -->grad_value: 4.740159511129605e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0017701499164104462 -->grad_value: 4.740159511129605e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0016842097975313663 -->grad_value: -0.03599517047405243 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.093875420745462e-05 -->grad_value: 5.297572158724506e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0014443083200603724 -->grad_value: -9.033065907715354e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0035295505076646805 -->grad_value: -9.033065907715354e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 4.611313488567248e-05 -->grad_value: -0.0003014171961694956 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -2.2548269043909386e-05 -->grad_value: 7.767212082399055e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011676143622025847 -->grad_value: 0.0072179147973656654 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0026507594157010317 -->grad_value: 0.0072179147973656654 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.00026316556613892317 -->grad_value: -6.906480848556384e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009821420535445213 -->grad_value: 0.0017141355201601982 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0032597235403954983 -->grad_value: 0.0017141355201601982 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.004071568604558706 -->grad_value: 0.03168229013681412 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0016823859186843038 -->grad_value: 4.151539325714111 

INFO:root:
 ** Round 3 : Batch size = 25 , avg loss = 0.7090253269672394

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00015762296970933676 -->grad_value: 0.0030630440451204777 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.935131487902254e-05 -->grad_value: 2.082710466311255e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0022918633185327053 -->grad_value: 2.1081523300381377e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0017980532720685005 -->grad_value: 2.1081523300381377e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017164740711450577 -->grad_value: -0.026774879544973373 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.1319075787905604e-05 -->grad_value: 2.9725544692382755e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0015228674747049809 -->grad_value: -1.4052329788682982e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.00360811036080122 -->grad_value: -1.4052329788682982e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 7.893006113590673e-05 -->grad_value: -0.00034893298288807273 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.590644236188382e-05 -->grad_value: 7.708494376856834e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00023195939138531685 -->grad_value: 0.008260753937065601 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0035864138044416904 -->grad_value: 0.008260753937065601 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0002704158832784742 -->grad_value: -6.683613173663616e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.001360921305604279 -->grad_value: 0.001557214418426156 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0028809437062591314 -->grad_value: 0.001557214418426156 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.004047303460538387 -->grad_value: 0.04092900827527046 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.0013402618933469057 -->grad_value: 2.2589945793151855 

INFO:root:
 ** Round 4 : Batch size = 24 , avg loss = 0.6960688183705012

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0001675670500844717 -->grad_value: 0.014055686071515083 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -3.0179406167007983e-05 -->grad_value: -9.692075764178298e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0022876581642776728 -->grad_value: 1.689481177891139e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0018022581934928894 -->grad_value: 1.689481177891139e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017283044289797544 -->grad_value: 0.05034484341740608 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.103899507550523e-05 -->grad_value: -1.5476381065582245e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0015461172442883253 -->grad_value: 2.8090429623262025e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.003631360363215208 -->grad_value: 2.8090429623262025e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00010223100252915174 -->grad_value: -3.538404416758567e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.34291024855338e-05 -->grad_value: 3.412371370359324e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0004389655077829957 -->grad_value: 0.000845467671751976 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.004257339518517256 -->grad_value: 0.000845467671751976 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.00028119655326008797 -->grad_value: -1.28595856949687e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0017293879063799977 -->grad_value: 0.00035186216700822115 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0025124773383140564 -->grad_value: 0.00035186216700822115 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.003987479489296675 -->grad_value: -0.009330106899142265 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.0015379037940874696 -->grad_value: -2.365337371826172 

INFO:root:
 ** Round 5 : Batch size = 25 , avg loss = 0.6666230189800263

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00022221484687179327 -->grad_value: 0.016852878034114838 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.7739632059819996e-05 -->grad_value: -1.0294205594618688e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.002239749999716878 -->grad_value: 1.8224480299977586e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0018501668237149715 -->grad_value: 1.8224480299977586e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017172966618090868 -->grad_value: 0.06033903732895851 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.049253427889198e-05 -->grad_value: -1.7349319136883423e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0015549511881545186 -->grad_value: 3.327142621856183e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.003640194423496723 -->grad_value: 3.327142621856183e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00011964531586272642 -->grad_value: 1.3265649613458663e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -6.257783388718963e-05 -->grad_value: -2.4615117126813857e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0010394877754151821 -->grad_value: -0.00019320566207170486 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.004857861902564764 -->grad_value: -0.00019320566207170486 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0002919238177128136 -->grad_value: 1.3974673493066803e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002030396368354559 -->grad_value: -0.0002217447035945952 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0022114692255854607 -->grad_value: -0.0002217447035945952 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.003981941379606724 -->grad_value: -0.036740973591804504 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 3.2177005778066814e-05 -->grad_value: -4.905750274658203 

INFO:root:
 ** Round 6 : Batch size = 24 , avg loss = 0.7046744922796885

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0002556105609983206 -->grad_value: -0.0017815222963690758 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.4342502001672983e-05 -->grad_value: 7.272354878296028e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0021889624185860157 -->grad_value: -1.2155017429904547e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0019009537063539028 -->grad_value: -1.2155017429904547e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.00170854979660362 -->grad_value: 0.0042781345546245575 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -2.9385089874267578e-05 -->grad_value: -6.766904903088289e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0015577450394630432 -->grad_value: -2.3796578716428485e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0036429886240512133 -->grad_value: -2.3796578716428485e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0001379566383548081 -->grad_value: -3.656426997622475e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -6.32427036180161e-05 -->grad_value: 9.872092050500214e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0012353963684290648 -->grad_value: -0.00034904302447102964 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005053769797086716 -->grad_value: -0.00034904302447102964 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0003078723675571382 -->grad_value: -4.240339421812678e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0021825404837727547 -->grad_value: -1.5864003216847777e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0020593246445059776 -->grad_value: -1.5864003216847777e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.003932208754122257 -->grad_value: 0.009357198141515255 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0011889386223629117 -->grad_value: -2.109475612640381 

INFO:root:
 ** Round 7 : Batch size = 24 , avg loss = 0.6630253183345

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00024480384308844805 -->grad_value: -0.12987948954105377 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.63522524619475e-05 -->grad_value: 1.7355701857013628e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0022028160747140646 -->grad_value: -0.00030951970256865025 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0018871002830564976 -->grad_value: -0.00030951970256865025 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017230630619451404 -->grad_value: 0.010069966316223145 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -2.770737773971632e-05 -->grad_value: -1.363355579542258e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0015652886359021068 -->grad_value: 5.491631782206241e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0036505323369055986 -->grad_value: 5.491631782206241e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.000155248970258981 -->grad_value: 3.038499562535435e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.465838280040771e-05 -->grad_value: 4.476087269722484e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0012403540313243866 -->grad_value: -0.002049327129498124 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005058727227151394 -->grad_value: -0.002049327129498124 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0003264483530074358 -->grad_value: 2.41138714045519e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002304693451151252 -->grad_value: -0.0006767589948140085 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0019371716771274805 -->grad_value: -0.0006767589948140085 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0038082306273281574 -->grad_value: 0.0031059077009558678 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0028053398709744215 -->grad_value: -4.2243499755859375 

INFO:root:
 ** Round 8 : Batch size = 25 , avg loss = 0.6790227150917053

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0002458037342876196 -->grad_value: -0.00934610702097416 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.709563705138862e-05 -->grad_value: 1.6403589597757673e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.002212547929957509 -->grad_value: -1.2343150046945084e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0018773684278130531 -->grad_value: -1.2343150046945084e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017390343127772212 -->grad_value: -0.006873984355479479 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -2.7070789656136185e-05 -->grad_value: 6.287218923262117e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0015798264648765326 -->grad_value: -5.984903509670403e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0036650702822953463 -->grad_value: -5.984903509670403e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00015274166071321815 -->grad_value: -2.7275851607555524e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -8.230294770328328e-05 -->grad_value: -4.662179890146945e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001118574640713632 -->grad_value: -0.0002853669866453856 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0049369484186172485 -->grad_value: -0.0002853669866453856 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.00032829539850354195 -->grad_value: 1.9995195543742739e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002283807611092925 -->grad_value: -0.00014279907918535173 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0019580572843551636 -->grad_value: -0.00014279907918535173 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.003737009596079588 -->grad_value: 0.011538049206137657 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0036356940399855375 -->grad_value: 0.4268816113471985 

INFO:root:
 ** Round 9 : Batch size = 25 , avg loss = 0.6666560781002044

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00022754567908123136 -->grad_value: 0.00751976715400815 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.8145703254267573e-05 -->grad_value: -4.1320208765682764e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0022539831697940826 -->grad_value: -2.29060879064491e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0018359336536377668 -->grad_value: -2.29060879064491e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017633787356317043 -->grad_value: -0.002643078099936247 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -2.8831811505369842e-05 -->grad_value: 1.345939324437495e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0015944645274430513 -->grad_value: 2.197855565100326e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0036797078792005777 -->grad_value: 2.197855565100326e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0001701584697002545 -->grad_value: 2.6707950382842682e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.02677498338744e-05 -->grad_value: -1.0485705388418864e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0011611972004175186 -->grad_value: -0.001492655137553811 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.004979570396244526 -->grad_value: -0.001492655137553811 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0003358727553859353 -->grad_value: 1.7888281945488416e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002298442181199789 -->grad_value: -0.00047041988000273705 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0019434227142482996 -->grad_value: -0.00047041988000273705 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0036853542551398277 -->grad_value: -0.004297653678804636 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0032474608160555363 -->grad_value: -0.4098317623138428 

INFO:root:
 ** Round 10 : Batch size = 24 , avg loss = 0.70319930712382

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0002222456387244165 -->grad_value: 0.004483496304601431 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.9939765227027237e-05 -->grad_value: -5.014207999920473e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0022748655173927546 -->grad_value: 1.0477345313120168e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0018150509567931294 -->grad_value: 1.0477345313120168e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017985145095735788 -->grad_value: -0.0044766925275325775 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.101816400885582e-05 -->grad_value: 2.1885480094852028e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0016438940074294806 -->grad_value: 1.3298231351654977e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0037291371263563633 -->grad_value: 1.3298231351654977e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00017150536586996168 -->grad_value: -3.436283441260457e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.439940964104608e-05 -->grad_value: 1.807125227060169e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001132833887822926 -->grad_value: 0.0012402955908328295 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0049512069672346115 -->grad_value: 0.0012402955908328295 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.00033955296385101974 -->grad_value: 3.676318556244951e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002281121676787734 -->grad_value: 8.249683742178604e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0019607432186603546 -->grad_value: 8.249683742178604e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0036623929627239704 -->grad_value: 0.008537315763533115 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.003089279867708683 -->grad_value: 1.9402154684066772 

INFO:root:
 ** Round 11 : Batch size = 25 , avg loss = 0.6977705836296082

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0002087823231704533 -->grad_value: 0.024192215874791145 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -3.630615537986159e-05 -->grad_value: -1.809564537325059e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0023350247647613287 -->grad_value: 2.9806642487528734e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.001754892524331808 -->grad_value: 2.9806642487528734e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0018824455328285694 -->grad_value: -0.013539625331759453 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.2573690987192094e-05 -->grad_value: 1.24735407780463e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0018338612280786037 -->grad_value: -2.1999483578838408e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0039191036485135555 -->grad_value: -2.1999483578838408e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0001712017401587218 -->grad_value: -0.00011538792023202404 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.703648589085788e-05 -->grad_value: 2.2571644876734354e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0013492857106029987 -->grad_value: 0.002901805331930518 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005167658906430006 -->grad_value: 0.002901805331930518 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 0.0003439459833316505 -->grad_value: 5.507481546374038e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00017573806690052152 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0023121782578527927 -->grad_value: 8.498074021190405e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0019296871032565832 -->grad_value: 8.498074021190405e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0036479257978498936 -->grad_value: 0.01662999391555786 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0017746923258528113 -->grad_value: 5.368324279785156 

