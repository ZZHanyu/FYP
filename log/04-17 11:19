INFO:root:
 ======== Start Log Recording :04-17 11:19 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 1.1112115211460902

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00031370684155263007 -->grad_value: 0.00043829178321175277 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00019669516768772155 -->grad_value: 1.9633484171777127e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00260426988825202 -->grad_value: 1.255888378182135e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009346497827209532 -->grad_value: 1.255888378182135e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00015827390598133206 -->grad_value: -0.0001600523537490517 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00020786207460332662 -->grad_value: -4.9156994030852275e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.003461657790467143 -->grad_value: -4.0167336123886344e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.003614536952227354 -->grad_value: -4.0167336123886344e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -8.029518357943743e-05 -->grad_value: -3.771659521589754e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00011441975948400795 -->grad_value: -5.05752359458711e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0004270481294952333 -->grad_value: -0.0015991490799933672 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0011886879801750183 -->grad_value: -0.0015991490799933672 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -3.999513137387112e-05 -->grad_value: -1.9933977455366403e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.001609591767191887 -->grad_value: -0.0002613467804621905 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003971044905483723 -->grad_value: -0.0002613467804621905 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0007923231460154057 -->grad_value: -4.841014742851257e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.04768647253513336 -->grad_value: -1.5038789510726929 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.7037978619337082

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0003331826301291585 -->grad_value: -0.0032243477180600166 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00020024029072374105 -->grad_value: 1.7730535262217018e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002624431625008583 -->grad_value: 4.324973360780859e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009548114612698555 -->grad_value: 4.324973360780859e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00010792806278914213 -->grad_value: 0.002256236504763365 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00020642284653149545 -->grad_value: -4.943602149865001e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0035181960556656122 -->grad_value: 5.491779120347928e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0035579989198595285 -->grad_value: 5.491779120347928e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -9.307172149419785e-05 -->grad_value: 1.386262511005043e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00014153795200400054 -->grad_value: 5.279080596665153e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -3.848629421554506e-05 -->grad_value: 0.0009208311093971133 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0016542230732738972 -->grad_value: 0.0009208311093971133 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.6102846681606025e-05 -->grad_value: 1.2045970834151376e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0018769361777231097 -->grad_value: 0.00038134047645144165 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.004238389432430267 -->grad_value: 0.00038134047645144165 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0007267026230692863 -->grad_value: 0.007853677496314049 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.04763200506567955 -->grad_value: 1.735032081604004 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.759506413936615

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0002908770111389458 -->grad_value: 0.003730478696525097 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0002023609122261405 -->grad_value: 2.577491997612924e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002607965376228094 -->grad_value: 5.2811742534686346e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009383457363583148 -->grad_value: 5.2811742534686346e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -9.118474554270506e-05 -->grad_value: -0.001589982071891427 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0002058540121652186 -->grad_value: -1.7648975614292794e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0035625367891043425 -->grad_value: -5.834394414705457e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0035136581864207983 -->grad_value: -5.834394414705457e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -9.770251926966012e-05 -->grad_value: 1.4883035873936024e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00013902790669817477 -->grad_value: -1.2935035556438379e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.00013988491264171898 -->grad_value: -0.001806102111004293 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0017556212842464447 -->grad_value: -0.001806102111004293 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.620998879545368e-05 -->grad_value: 7.559712003057939e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0019240628462284803 -->grad_value: -6.569239485543221e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0042855157516896725 -->grad_value: -6.569239485543221e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0007596397772431374 -->grad_value: -0.015381406992673874 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.04780031368136406 -->grad_value: -2.955655813217163 

INFO:root:
 ** Round 3 : Batch size = 25 , avg loss = 0.5974995803833008

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00024886816390790045 -->grad_value: 0.002062957501038909 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0002026517759077251 -->grad_value: 1.2868281551448035e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002585912123322487 -->grad_value: 2.2932385945750866e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009162926580756903 -->grad_value: 2.2932385945750866e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.599431460723281e-05 -->grad_value: -0.0008914693025872111 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00020811829017475247 -->grad_value: 7.618301367529057e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.003627547062933445 -->grad_value: -1.9282861103420146e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.003448647912591696 -->grad_value: -1.9282861103420146e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00011427319986978546 -->grad_value: 1.2465989129850641e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00012857055116910487 -->grad_value: -9.98577343125362e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.00015245506074279547 -->grad_value: -0.001293879235163331 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0017681904137134552 -->grad_value: -0.001293879235163331 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -5.798917118227109e-05 -->grad_value: 6.423902505048318e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0018096576677635312 -->grad_value: -0.0006124008214101195 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.004171110223978758 -->grad_value: -0.0006124008214101195 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0008293831488117576 -->grad_value: -0.008571139536798 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.04795815423130989 -->grad_value: -1.897812843322754 

INFO:root:
 ** Round 4 : Batch size = 24 , avg loss = 0.6027490769823393

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00017843877139966935 -->grad_value: -0.002364863408729434 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00020407223200891167 -->grad_value: -1.3301385770603247e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0025691259652376175 -->grad_value: -4.011537839687662e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008995069074444473 -->grad_value: -4.011537839687662e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 6.410293281078339e-06 -->grad_value: 0.001414435333572328 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0002145207836292684 -->grad_value: -2.8801018459034822e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0037708492018282413 -->grad_value: 2.588289589766646e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.003305344842374325 -->grad_value: 2.588289589766646e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00018165912479162216 -->grad_value: -1.5300707673304714e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00010065906099043787 -->grad_value: 7.062524787215807e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 3.85363819077611e-06 -->grad_value: 0.0016495827585458755 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.001611882820725441 -->grad_value: 0.0016495827585458755 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -9.839452104642987e-05 -->grad_value: -2.2697383883496514e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0015238616615533829 -->grad_value: -8.621777669759467e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003885314567014575 -->grad_value: -8.621777669759467e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0008587888441979885 -->grad_value: -0.0069923726841807365 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.04840750992298126 -->grad_value: 1.5882023572921753 

INFO:root:
 ** Round 5 : Batch size = 25 , avg loss = 0.6477512121200562

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00017991859931498766 -->grad_value: -0.005820190068334341 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00020935566863045096 -->grad_value: -4.879815662661713e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0026072708424180746 -->grad_value: -6.759806296940951e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.000937651377171278 -->grad_value: -6.759806296940951e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -1.5864206943660975e-05 -->grad_value: 0.00019574286125134677 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00021150236716493964 -->grad_value: 1.0728677501958828e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0037595960311591625 -->grad_value: -4.5611798782374535e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0033165989443659782 -->grad_value: -4.5611798782374535e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002234458370367065 -->grad_value: -5.6588160077808425e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00010888722317758948 -->grad_value: -1.7484682757640257e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.00017927741282619536 -->grad_value: -0.0013614788185805082 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0017950143665075302 -->grad_value: -0.0013614788185805082 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -9.045597835211083e-05 -->grad_value: -3.439108468228369e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0014931773766875267 -->grad_value: -0.0004401610349304974 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003854629583656788 -->grad_value: -0.0004401610349304974 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0008899656822904944 -->grad_value: -0.016272827982902527 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.048073362559080124 -->grad_value: -1.8695671558380127 

INFO:root:
 ** Round 6 : Batch size = 24 , avg loss = 5.047369698547603

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -1.7475453205406666e-05 -->grad_value: -0.0014562758151441813 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00019881142361555248 -->grad_value: -4.055182856177453e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0023584028240293264 -->grad_value: -1.6373153357562842e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0006887823692522943 -->grad_value: -1.6373153357562842e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00038154260255396366 -->grad_value: 0.0004939355421811342 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001873404544312507 -->grad_value: 2.1480953904529088e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.00320138456299901 -->grad_value: 1.4923613207429298e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0038748099468648434 -->grad_value: 1.4923613207429298e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001764268963597715 -->grad_value: -1.070243615686195e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00022249214816838503 -->grad_value: 4.7489607823081315e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.000624976004473865 -->grad_value: -0.0020933898631483316 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0022407122887670994 -->grad_value: -0.0020933898631483316 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -9.750045137479901e-05 -->grad_value: 2.5911305101544713e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0037970119155943394 -->grad_value: 4.520163929555565e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.006158463656902313 -->grad_value: 4.520163929555565e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0006241761147975922 -->grad_value: 0.001978101674467325 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.055723123252391815 -->grad_value: -1.1417083740234375 

INFO:root:
 ** Round 7 : Batch size = 24 , avg loss = 0.614639804388086

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -3.711228782776743e-05 -->grad_value: 0.0007448579417541623 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001857214665506035 -->grad_value: 2.298271262191065e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00248598656617105 -->grad_value: 8.43415421059035e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008163661113940179 -->grad_value: 8.43415421059035e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0005444248090498149 -->grad_value: 0.0008721373742446303 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00017518605454824865 -->grad_value: 8.285284680553673e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0027357160579413176 -->grad_value: 5.914321832278802e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004340479150414467 -->grad_value: 5.914321832278802e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00021507607016246766 -->grad_value: 8.478917152388021e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0005748990806750953 -->grad_value: 1.7775521428120555e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003397146239876747 -->grad_value: 0.0011709143873304129 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005012882873415947 -->grad_value: 0.0011709143873304129 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -8.78714126884006e-05 -->grad_value: -2.560592292866204e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005244053900241852 -->grad_value: -0.0003132054698653519 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007605505175888538 -->grad_value: -0.0003132054698653519 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00039573200047016144 -->grad_value: 0.008111091330647469 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05309232696890831 -->grad_value: 1.5228993892669678 

INFO:root:
 ** Round 8 : Batch size = 25 , avg loss = 0.7834261000156403

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -5.0497546908445656e-05 -->grad_value: -0.000363312428817153 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00018490951333660632 -->grad_value: -9.46349985042616e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00252773379907012 -->grad_value: 1.3486692296282854e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008581141009926796 -->grad_value: 1.3486692296282854e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0005860478850081563 -->grad_value: -0.007158857770264149 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00017582139116711915 -->grad_value: -1.5380169360312834e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.00262504443526268 -->grad_value: -1.9311746655148454e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004451150540262461 -->grad_value: -1.9311746655148454e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020643653988372535 -->grad_value: -1.704753958620131e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006602185312658548 -->grad_value: -1.2996681107324548e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004076010547578335 -->grad_value: -0.0021854545921087265 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005691748112440109 -->grad_value: -0.0021854545921087265 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -9.038113057613373e-05 -->grad_value: 7.3280762080685236e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005566609092056751 -->grad_value: 0.0009426870965398848 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007928060367703438 -->grad_value: 0.0009426870965398848 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00034319842234253883 -->grad_value: -0.03133434057235718 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05229642242193222 -->grad_value: -4.065706253051758 

INFO:root:
 ** Round 9 : Batch size = 25 , avg loss = 0.9575053864717483

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00011490708857309073 -->grad_value: 0.00032833212753757834 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00018524144252296537 -->grad_value: 4.132982667215401e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0026148983743041754 -->grad_value: 1.1863805866596522e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009452784433960915 -->grad_value: 1.1863805866596522e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0005298836622387171 -->grad_value: 0.00037668473669327796 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018116018327418715 -->grad_value: 5.506050726467038e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.00265125441364944 -->grad_value: 1.985231392609421e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004424940794706345 -->grad_value: 1.985231392609421e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020998134277760983 -->grad_value: 5.948533271293854e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006661002989858389 -->grad_value: 2.2689941943099257e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004122810438275337 -->grad_value: 0.0008252906845882535 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005738547071814537 -->grad_value: 0.0008252906845882535 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -7.211985939648002e-05 -->grad_value: -9.039403607857821e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.00558884534984827 -->grad_value: -0.0001309094950556755 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007950294762849808 -->grad_value: -0.0001309094950556755 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0003395767416805029 -->grad_value: 0.0022093765437602997 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.052241552621126175 -->grad_value: 1.4612534046173096 

INFO:root:
 ** Round 10 : Batch size = 24 , avg loss = 0.8551224110027155

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -5.2636489272117615e-05 -->grad_value: -0.00013723864685744047 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00018526430358178914 -->grad_value: -1.8026661052772397e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002540136221796274 -->grad_value: -4.747034552110563e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008705166401341558 -->grad_value: -4.747034552110563e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0004030106356367469 -->grad_value: -0.00752333365380764 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018287260900251567 -->grad_value: -4.408756382190404e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002751618856564164 -->grad_value: -1.8762098989100195e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004324575886130333 -->grad_value: -1.8762098989100195e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00021664540690835565 -->grad_value: -2.625186425575521e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665439577773213 -->grad_value: -1.533456270408351e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126342479139566 -->grad_value: -0.002347734523937106 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005742077715694904 -->grad_value: -0.002347734523937106 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.560304609593004e-05 -->grad_value: 1.1109064871561714e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590522661805153 -->grad_value: 0.0008880255627445877 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007951973006129265 -->grad_value: 0.0008880255627445877 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0003393031656742096 -->grad_value: -0.03165850043296814 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.052237413823604584 -->grad_value: -4.0619893074035645 

INFO:root:
 ** Round 11 : Batch size = 25 , avg loss = 0.6804111760854721

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 1.4217745047062635e-05 -->grad_value: -0.00012838600378017873 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001868333638412878 -->grad_value: -2.5466130537665777e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002454151399433613 -->grad_value: -3.381077817721234e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0007845318177714944 -->grad_value: -3.381077817721234e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0003577339230105281 -->grad_value: -0.012215284630656242 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001831999106798321 -->grad_value: 4.834809441689458e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0027949712239205837 -->grad_value: -1.8174805518356152e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004281221888959408 -->grad_value: -1.8174805518356152e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002146296901628375 -->grad_value: -6.809998012613505e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665817345492542 -->grad_value: -1.0728882443800103e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126640502363443 -->grad_value: -0.002121793804690242 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.005742376670241356 -->grad_value: -0.002121793804690242 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.917519203852862e-05 -->grad_value: 3.092256292802631e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0055906642228364944 -->grad_value: 0.0007995185442268848 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952114567160606 -->grad_value: 0.0007995185442268848 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0003392797661945224 -->grad_value: -0.030642377212643623 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223706364631653 -->grad_value: -3.8653831481933594 

INFO:root:
 ** Round 12 : Batch size = 24 , avg loss = 0.8335806926091512

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 8.836461347527802e-06 -->grad_value: -0.0004705123428720981 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00018818557146005332 -->grad_value: 1.959538309392883e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00249555055052042 -->grad_value: -7.356192099905456e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.000825931434519589 -->grad_value: -7.356192099905456e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00037289835745468736 -->grad_value: 0.001086999662220478 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018557804287411273 -->grad_value: 1.3603996151800857e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.00274517759680748 -->grad_value: 3.5968291740573477e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004331016447395086 -->grad_value: 3.5968291740573477e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00021715511684305966 -->grad_value: -1.150800017057918e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665837718173862 -->grad_value: 3.258439392084256e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: 0.0006394856609404087 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: 0.0006394856609404087 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -7.399068272206932e-05 -->grad_value: 4.849691322306171e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: -0.00024865532759577036 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: -0.00024865532759577036 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.003434433601796627 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: 1.3320506811141968 

INFO:root:
 ** Round 13 : Batch size = 24 , avg loss = 0.8837606683373451

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 2.6100067771039903e-05 -->grad_value: 0.002031451091170311 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001843420322984457 -->grad_value: 2.086651207378054e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002503525000065565 -->grad_value: 2.5548547455400694e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008339061168953776 -->grad_value: 2.5548547455400694e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.000409191008657217 -->grad_value: -0.006999167613685131 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018611869018059224 -->grad_value: -2.4188309133421626e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0026465030387043953 -->grad_value: -1.7341153579764068e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004429691471159458 -->grad_value: -1.7341153579764068e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00021848164033144712 -->grad_value: 3.788525646086782e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: -5.868365406058729e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: -0.001667645527049899 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: -0.001667645527049899 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.57928321743384e-05 -->grad_value: -8.971508577815257e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: 0.0003683776594698429 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: 0.0003683776594698429 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: -0.0076860226690769196 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: -3.4201066493988037 

INFO:root:
 ** Round 14 : Batch size = 23 , avg loss = 0.7785990873108739

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 1.8344580894336104e-05 -->grad_value: 0.0027372499462217093 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001858626346802339 -->grad_value: -9.769224362798923e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002518112538382411 -->grad_value: 9.468543794355355e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008484931895509362 -->grad_value: 9.468543794355355e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0004110606969334185 -->grad_value: 0.00414437847211957 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018815418297890574 -->grad_value: 1.515091696546733e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002641071332618594 -->grad_value: 1.7580232452019118e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004435122944414616 -->grad_value: 1.7580232452019118e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002176829002564773 -->grad_value: 8.657563739689067e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: 1.3709811810258543e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: 0.0008541986462660134 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: 0.0008541986462660134 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.25653556198813e-05 -->grad_value: -1.8062780782202026e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: -0.00017830371507443488 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: -0.00017830371507443488 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.007280291058123112 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: 1.4319294691085815 

INFO:root:
 ** Round 15 : Batch size = 25 , avg loss = 0.7769761383533478

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 3.5549193853512406e-05 -->grad_value: -0.0014415474142879248 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00018578863819129765 -->grad_value: 2.6044849832373984e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0024952630046755075 -->grad_value: 4.176974357505969e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008256437722593546 -->grad_value: 4.176974357505969e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00039826228749006987 -->grad_value: 0.0004409499524626881 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018911798542831093 -->grad_value: 1.2104216295938386e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0026405712123960257 -->grad_value: 3.231025402783416e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004435623064637184 -->grad_value: 3.231025402783416e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00021942889725323766 -->grad_value: -5.831348062201869e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: 1.5496768810407957e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: 0.0006739965174347162 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: 0.0006739965174347162 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -5.635332490783185e-05 -->grad_value: 1.9613642052718205e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: -0.00019282440189272165 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: -0.00019282440189272165 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.002127296756953001 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: 1.3778183460235596 

INFO:root:
 ** Round 16 : Batch size = 25 , avg loss = 0.919467738866806

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 2.3864995455369353e-05 -->grad_value: -0.004393520765006542 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00018388216267339885 -->grad_value: -3.9773766502548824e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002524217590689659 -->grad_value: -3.4799718378053512e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008545985911041498 -->grad_value: -3.4799718378053512e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0004130008746869862 -->grad_value: 0.004240428563207388 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018878307309933007 -->grad_value: 1.574618657684823e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002646846231073141 -->grad_value: 8.958857506513596e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004429347813129425 -->grad_value: 8.958857506513596e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00023410934954881668 -->grad_value: -5.6540657169534825e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: 4.5535120989370625e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: 0.0007304648170247674 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: 0.0007304648170247674 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.339683022815734e-05 -->grad_value: 1.3733942978433333e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: -0.00017626595217734575 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: -0.00017626595217734575 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.008486943319439888 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: 1.4492868185043335 

INFO:root:
 ** Round 17 : Batch size = 25 , avg loss = 0.7559477007389068

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 2.5313274818472564e-05 -->grad_value: -0.0009833610383793712 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001830875116866082 -->grad_value: 1.141532806059331e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0025181849487125874 -->grad_value: -1.4698715631311643e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.000848566007334739 -->grad_value: -1.4698715631311643e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.000437379814684391 -->grad_value: 0.0010141159873455763 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00019002251792699099 -->grad_value: 3.965518047266414e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0026000358629971743 -->grad_value: 3.3378937587258406e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0044761584140360355 -->grad_value: 3.3378937587258406e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00025573791936039925 -->grad_value: 2.250993566121906e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: 4.1096909626503475e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: 0.0008249134989455342 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: 0.0008249134989455342 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.228225538507104e-05 -->grad_value: -2.614936875033891e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: -9.618732292437926e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: -9.618732292437926e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.007045886479318142 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: 1.524802803993225 

INFO:root:
 ** Round 18 : Batch size = 25 , avg loss = 0.8559425294399261

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 6.327629671432078e-05 -->grad_value: -9.331019828096032e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00018353486666455865 -->grad_value: 7.677337876543788e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0024789394810795784 -->grad_value: -3.9764569237377145e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0008093207143247128 -->grad_value: -3.9764569237377145e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0004529086872935295 -->grad_value: -0.0033320176880806684 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00019134700414724648 -->grad_value: -5.327374452690492e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0025661299005150795 -->grad_value: -8.343571607838385e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004510065075010061 -->grad_value: -8.343571607838385e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00025446887593716383 -->grad_value: 2.06305139727192e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: -3.405073584872298e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: -0.0015809086617082357 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: -0.0015809086617082357 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.250606384128332e-05 -->grad_value: -3.107898578491586e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: 0.00010219027171842754 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: 0.00010219027171842754 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.0020226407796144485 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: -2.673650026321411 

INFO:root:
 ** Round 19 : Batch size = 25 , avg loss = 0.6133257675170899

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 8.289801189675927e-05 -->grad_value: 0.0018944485345855355 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001818857854232192 -->grad_value: 3.1768259134423715e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002453738357871771 -->grad_value: 2.8796289370802697e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.000784119765739888 -->grad_value: 2.8796289370802697e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00046954117715358734 -->grad_value: 0.0040869517251849174 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00019143926328979433 -->grad_value: 1.9178553856136205e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0025489297695457935 -->grad_value: 5.8392797654960304e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.00452726474031806 -->grad_value: 5.8392797654960304e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00024320505326613784 -->grad_value: -2.098665845551295e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: 3.095178271905752e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: 0.000797672604676336 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: 0.000797672604676336 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -5.934261207585223e-05 -->grad_value: 4.940386588714318e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: -0.00014476777869276702 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: -0.00014476777869276702 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.005610744468867779 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: 1.4095838069915771 

INFO:root:
 ** Round 20 : Batch size = 23 , avg loss = 0.7896203722642816

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.00011468940647318959 -->grad_value: -0.007953266613185406 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00017929849855136126 -->grad_value: 8.303217668981233e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002387797459959984 -->grad_value: -2.6393868211016525e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0007181792752817273 -->grad_value: -2.6393868211016525e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00047430582344532013 -->grad_value: 0.0006982179475016892 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00019259323016740382 -->grad_value: 3.884948185373105e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0025510843843221664 -->grad_value: 2.484418928361265e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004525110125541687 -->grad_value: 2.484418928361265e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002463539130985737 -->grad_value: 1.359309953841148e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0006665838300250471 -->grad_value: 4.9199829845747445e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.004126656800508499 -->grad_value: 0.0007580852834507823 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00574239157140255 -->grad_value: 0.0007580852834507823 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -5.158317071618512e-05 -->grad_value: -4.365416316431947e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 0.00030092368251644075 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.005590670742094517 -->grad_value: -0.00024934951215982437 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007952122017741203 -->grad_value: -0.00024934951215982437 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000339278019964695 -->grad_value: 0.011221693828701973 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.05223705247044563 -->grad_value: 1.3149731159210205 

INFO:root:TEST Processing --> pred = tensor([0.3221], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3213], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2495], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3356], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2969], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3469], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2855], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2964], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3847], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3305], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3137], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3117], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3710], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3164], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3351], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3125], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2755], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2566], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5121], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2549], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2463], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2334], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2967], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3689], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2846], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2807], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3245], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3686], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3151], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3481], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2848], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3498], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2691], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3278], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3136], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3457], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2850], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3072], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2590], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2440], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2954], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3373], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2307], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3169], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5172], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3443], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3354], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3911], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5945], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3376], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3074], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2798], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2941], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2647], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2643], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3019], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3520], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2684], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3297], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3949], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2845], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3374], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3748], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3422], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3181], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3105], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2876], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2898], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2950], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3267], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2971], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2994], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2668], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6025], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2792], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3284], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3069], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6390], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3056], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2507], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3176], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3163], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2927], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5741], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3155], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3146], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3445], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3375], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2837], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2386], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3063], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2950], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2877], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2811], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2574], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2843], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4607], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3271], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3497], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2558], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2600], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4678], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2838], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2934], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3714], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3250], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3003], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3228], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2854], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2863], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3538], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3419], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3244], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3059], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2966], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2952], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3236], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3870], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5977], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2590], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2666], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2979], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3553], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2546], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3042], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3460], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2811], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2216], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3051], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3137], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2954], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2898], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2723], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3413], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3015], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2720], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2883], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2777], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3676], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4418], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2826], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2828], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3185], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2812], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3296], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2992], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2734], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3348], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3257], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3204], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3642], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2674], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3356], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2304], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2337], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3023], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2706], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4769], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3169], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3420], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2717], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3284], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2851], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2601], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3278], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5829], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6337], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2917], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3072], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2901], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3240], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2557], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3768], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3321], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3131], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3177], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3289], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3506], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4176], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3216], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3942], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3394], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3056], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3528], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2923], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3727], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4605], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3277], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3912], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3703], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2659], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3613], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3294], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3003], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3053], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2889], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4989], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3002], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4893], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3158], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3675], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2892], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2682], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2436], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3780], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3424], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3840], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5304], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2726], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2997], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3762], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3834], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6204], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3219], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2728], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3634], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3100], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3365], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3174], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3036], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2693], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2749], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6329], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3233], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2813], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3202], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3170], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3276], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5735], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3165], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4910], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2847], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4506], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4111], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3307], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3397], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3108], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2695], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3375], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2791], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3096], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4107], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:
** TEST RESULT --> Accurary = 2.064141931081542% **

INFO:root:TEST Processing --> pred = tensor([0.3221], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3213], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2495], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3356], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2969], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3469], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2855], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2964], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3847], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3305], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3137], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3117], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3710], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3164], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3351], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3125], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2755], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2566], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5121], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2549], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2463], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2334], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2967], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3689], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2846], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2807], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3245], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3686], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3151], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3481], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2848], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3498], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2691], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3278], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3136], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3457], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2850], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3072], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2590], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2440], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2954], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3373], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2307], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3169], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5172], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3443], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3354], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3911], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5945], device='mps:0', grad_fn=<LinearBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.3376], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3074], device='mps:0', grad_fn=<LinearBackward0>) target = 0.0
