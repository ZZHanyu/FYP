INFO:root:
 ======== Start Log Recording :04-16 14:41 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 18 , avg loss = 0.18099422084600925

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011531154159456491 -->grad_value: -0.02696000598371029 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003242710081394762 -->grad_value: -4.0977465687319636e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.000933666480705142 -->grad_value: -1.3597533325082622e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009666054975241423 -->grad_value: -1.3597533325082622e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005746906972490251 -->grad_value: 0.004139456432312727 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013527125702239573 -->grad_value: -7.572906213226815e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008205087506212294 -->grad_value: -2.954835508717224e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004741284530609846 -->grad_value: -2.954835508717224e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.8563306336291134e-05 -->grad_value: -0.00012616801541298628 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034037360455840826 -->grad_value: 8.868571603670716e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00012003013398498297 -->grad_value: 0.008294546976685524 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007569899316877127 -->grad_value: 0.008294546976685524 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.1824601794360206e-05 -->grad_value: 7.948705751914531e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009468220523558557 -->grad_value: -0.003784510772675276 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003346043871715665 -->grad_value: -0.003784510772675276 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 4.390464164316654e-05 -->grad_value: -0.07454697042703629 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.017201513051986694 -->grad_value: -13.973138809204102 

INFO:root:
 ** Round 1 : Batch size = 20 , avg loss = 0.015590484970016406

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011479801032692194 -->grad_value: 0.3021417260169983 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003242923703510314 -->grad_value: -3.7756683468614938e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.000940381723921746 -->grad_value: 8.07194592198357e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009598900796845555 -->grad_value: 8.07194592198357e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.000574699486605823 -->grad_value: -0.022388160228729248 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013573213072959334 -->grad_value: 6.864843271614518e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008218321017920971 -->grad_value: -3.9229031244758517e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004739961586892605 -->grad_value: -3.9229031244758517e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.890311538474634e-05 -->grad_value: -0.00028413813561201096 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034097349271178246 -->grad_value: 0.0003049015940632671 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011278956662863493 -->grad_value: 0.028557702898979187 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007497493061237037 -->grad_value: 0.028557702898979187 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.234254083712585e-05 -->grad_value: 7.332942186621949e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009370505576953292 -->grad_value: -0.00834294967353344 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033362731337547302 -->grad_value: -0.00834294967353344 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 7.243233267217875e-05 -->grad_value: -0.0008711665868759155 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.017680658027529716 -->grad_value: -60.562828063964844 

INFO:root:
 ** Round 2 : Batch size = 19 , avg loss = 0.007072757874419422

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011361564975231886 -->grad_value: 0.3015359044075012 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003248067805543542 -->grad_value: -3.792247298406437e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009562779450789094 -->grad_value: 7.951231964398175e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009439940331503749 -->grad_value: 7.951231964398175e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005758879124186933 -->grad_value: -0.022815803065896034 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013649192987941206 -->grad_value: 6.70833856020181e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.000823929556645453 -->grad_value: -3.913369437213987e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0047378637827932835 -->grad_value: -3.913369437213987e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.92807557748165e-05 -->grad_value: -0.0002842394169420004 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003418991109356284 -->grad_value: 0.0003047521458938718 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011171746882610023 -->grad_value: 0.028573304414749146 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007486771210096776 -->grad_value: 0.028573304414749146 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.254400118952617e-05 -->grad_value: 7.492148142773658e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009298990480601788 -->grad_value: -0.00840633362531662 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003329121507704258 -->grad_value: -0.00840633362531662 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 9.925026097334921e-05 -->grad_value: -6.771087646484375e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01815418154001236 -->grad_value: -60.85508728027344 

INFO:root:
 ** Round 3 : Batch size = 20 , avg loss = 0.008740421594120562

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001134609687142074 -->grad_value: -6.5760817960836e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032488733995705843 -->grad_value: -3.167159690065091e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009586061933077872 -->grad_value: -1.166955144071835e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.000941665843129158 -->grad_value: -1.166955144071835e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005762726650573313 -->grad_value: -0.0005791612202301621 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013661314733326435 -->grad_value: 2.74575953085332e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008246208890341222 -->grad_value: -1.26924533105921e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0047371722757816315 -->grad_value: -1.26924533105921e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.937652556691319e-05 -->grad_value: 3.3549412137290346e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003419941058382392 -->grad_value: -1.7542379282531328e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011183158494532108 -->grad_value: -6.960205791983753e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007487914408557117 -->grad_value: -6.960205791983753e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2440435208845884e-05 -->grad_value: 2.72382635557733e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000929203990381211 -->grad_value: -0.00011093133798567578 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003328426741063595 -->grad_value: -0.00011093133798567578 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010158814257010818 -->grad_value: 0.0008384191896766424 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018195128068327904 -->grad_value: -0.3778783977031708 

INFO:root:
 ** Round 4 : Batch size = 20 , avg loss = 0.006629842589609325

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011337574105709791 -->grad_value: -0.0012709712609648705 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032490649027749896 -->grad_value: -6.25430303102803e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009591508423909545 -->grad_value: -2.831967776728561e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009411215432919562 -->grad_value: -2.831967776728561e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005779510247521102 -->grad_value: -0.0006077821017242968 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013673219655174762 -->grad_value: 2.8056307499468858e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008274451247416437 -->grad_value: -1.3324583960638847e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004734348505735397 -->grad_value: -1.3324583960638847e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.966183041688055e-05 -->grad_value: 5.647361831506714e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034204532857984304 -->grad_value: -6.386895279320015e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011242576874792576 -->grad_value: -0.00010654969810275361 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007493850425817072 -->grad_value: -0.00010654969810275361 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.228129182592966e-05 -->grad_value: 1.4589265902031912e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009288369910791516 -->grad_value: -0.00017724520876072347 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033280591014772654 -->grad_value: -0.00017724520876072347 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010192763875238597 -->grad_value: 0.0008112965151667595 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018201500177383423 -->grad_value: -0.5318648815155029 

INFO:root:
 ** Round 5 : Batch size = 19 , avg loss = 0.0075516646213241315

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001132084522396326 -->grad_value: -0.0019128525163978338 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.000324924971209839 -->grad_value: -7.503075494241784e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009599315235391259 -->grad_value: -3.7554636946879327e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009403404546901584 -->grad_value: -3.7554636946879327e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005800357321277261 -->grad_value: -0.0007998750661499798 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013692598440684378 -->grad_value: 3.4483992550349285e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008311655255965889 -->grad_value: -1.4025903283254593e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0047306278720498085 -->grad_value: -1.4025903283254593e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.992384492652491e-05 -->grad_value: 1.2651826182263903e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034211762249469757 -->grad_value: -7.427416903738049e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011352190631441772 -->grad_value: -0.00016794863040558994 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007504809182137251 -->grad_value: -0.00016794863040558994 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.211514169583097e-05 -->grad_value: 2.2717715637554647e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009282812825404108 -->grad_value: -0.00028106715762987733 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033275040332227945 -->grad_value: -0.00028106715762987733 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010207237210124731 -->grad_value: 0.0006750045577064157 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018203413113951683 -->grad_value: -0.7953812479972839 

INFO:root:
 ** Round 6 : Batch size = 20 , avg loss = 0.056548283388838175

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011318855686113238 -->grad_value: -0.0014451625756919384 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249343135394156 -->grad_value: -2.052824221721039e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009601071360521019 -->grad_value: -1.5209241155389464e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009401649585925043 -->grad_value: -1.5209241155389464e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005802275845780969 -->grad_value: 0.0005761016509495676 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013693521032109857 -->grad_value: 2.186094860689991e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008314010920003057 -->grad_value: 9.376811362926674e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004730392247438431 -->grad_value: 9.376811362926674e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.995532799512148e-05 -->grad_value: 2.517977293337026e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034212565515190363 -->grad_value: -1.1172675584703029e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011364906094968319 -->grad_value: -1.5103694749996066e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007506079855374992 -->grad_value: -1.5103694749996066e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2092218791367486e-05 -->grad_value: 6.249184707485256e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009282148093916476 -->grad_value: -4.6971221308922395e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033274374436587095 -->grad_value: -4.6971221308922395e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010208535240963101 -->grad_value: -0.000165068224305287 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820356771349907 -->grad_value: -0.13853460550308228 

INFO:root:
 ** Round 7 : Batch size = 20 , avg loss = 0.007488726556766778

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011316488962620497 -->grad_value: -0.0020091012120246887 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032493859180249274 -->grad_value: -5.689333804070884e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009603117941878736 -->grad_value: -3.075015229114797e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009399604168720543 -->grad_value: -3.075015229114797e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005805860855616629 -->grad_value: -0.0002332302974537015 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001369173260172829 -->grad_value: 9.906106157586692e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008316771127283573 -->grad_value: 6.522413400489313e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004730116575956345 -->grad_value: 6.522413400489313e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.996559437131509e-05 -->grad_value: 3.6748664911101514e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421336296014488 -->grad_value: -3.7959890164529497e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011374801397323608 -->grad_value: -5.9241509006824344e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007507064728997648 -->grad_value: -5.9241509006824344e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.204945435049012e-05 -->grad_value: 2.982314981636591e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000928152643609792 -->grad_value: -0.0001357683795504272 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327375277876854 -->grad_value: -0.0001357683795504272 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010209361789748073 -->grad_value: -0.001115138060413301 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018203701823949814 -->grad_value: -0.4300030469894409 

INFO:root:
 ** Round 8 : Batch size = 19 , avg loss = 0.05905588072307996

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00113138637971133 -->grad_value: -0.0020290124230086803 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249477595090866 -->grad_value: -6.346172654048132e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.000960388220846653 -->grad_value: -2.962188773381058e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009398838155902922 -->grad_value: -2.962188773381058e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005809229332953691 -->grad_value: -0.0006723764818161726 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368905941490084 -->grad_value: 1.293093987442262e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008317549363709986 -->grad_value: 7.890606070759532e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004730038344860077 -->grad_value: 7.890606070759532e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.996948700863868e-05 -->grad_value: 4.532836044290889e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421511792112142 -->grad_value: -4.5558243755294825e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011393130989745259 -->grad_value: -9.132004925049841e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007508891285397112 -->grad_value: -9.132004925049841e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2057406972162426e-05 -->grad_value: 1.1210327954813692e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009280542144551873 -->grad_value: -0.00018440571147948503 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033272760920226574 -->grad_value: -0.00018440571147948503 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010212627239525318 -->grad_value: -0.0009188865078613162 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018203923478722572 -->grad_value: -0.5575575828552246 

INFO:root:
 ** Round 9 : Batch size = 19 , avg loss = 0.007427727399197848

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001131267985329032 -->grad_value: -0.00052043137839064 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249516012147069 -->grad_value: -1.5901099104098648e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009604814113117754 -->grad_value: -8.409680845034018e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009397903922945261 -->grad_value: -8.409680845034018e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005810009897686541 -->grad_value: -0.0009051226661540568 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689202023670077 -->grad_value: 7.694341164210527e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008318133186548948 -->grad_value: -2.4641221330057306e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729979205876589 -->grad_value: -2.4641221330057306e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.997235009795986e-05 -->grad_value: -1.893850765100069e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034215362393297255 -->grad_value: -3.1322406357503496e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011395520414225757 -->grad_value: -3.670645673992112e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007509139250032604 -->grad_value: -3.670645673992112e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.206594894640148e-05 -->grad_value: -1.0272608506056713e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.00092804164160043 -->grad_value: -4.728140993393026e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033272637519985437 -->grad_value: -4.728140993393026e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213124915026128 -->grad_value: -2.1528336219489574e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018203958868980408 -->grad_value: -0.18484386801719666 

INFO:root:
 ** Round 10 : Batch size = 20 , avg loss = 0.007761803083121776

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011311857961118221 -->grad_value: -0.0017302284250035882 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032495398772880435 -->grad_value: -7.213294850316743e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.000960569130256772 -->grad_value: -2.896407977459603e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009397026151418686 -->grad_value: -2.896407977459603e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005810854490846395 -->grad_value: -0.0006854163366369903 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368951052427292 -->grad_value: 2.0112320697762698e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008318928885273635 -->grad_value: 4.020531463311272e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729899577796459 -->grad_value: 4.020531463311272e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.997515497962013e-05 -->grad_value: 4.330142076014454e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421568835619837 -->grad_value: -3.13142379582132e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011398218339309096 -->grad_value: -5.053857239545323e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007509409915655851 -->grad_value: -5.053857239545323e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207736856187694e-05 -->grad_value: -7.812994908817927e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009280271478928626 -->grad_value: -0.00013130257138982415 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033272486180067062 -->grad_value: -0.00013130257138982415 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213555651716888 -->grad_value: 0.0006461507291533053 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018203996121883392 -->grad_value: -0.43226996064186096 

INFO:root:
 ** Round 11 : Batch size = 20 , avg loss = 0.008002415776718407

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001131094410084188 -->grad_value: -0.0035501401871442795 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032495701452717185 -->grad_value: -1.3814010912938102e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009607002139091492 -->grad_value: -4.76040986541193e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009395716479048133 -->grad_value: -4.76040986541193e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811534356325865 -->grad_value: -0.0007742913439869881 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689717161469162 -->grad_value: 2.3304167484639038e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.000831926183309406 -->grad_value: -1.0214067458491627e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729866981506348 -->grad_value: -1.0214067458491627e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998483927920461e-05 -->grad_value: 4.551500580873835e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.000342161045409739 -->grad_value: -4.3439888486318523e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011403055395931005 -->grad_value: -9.105839126277715e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007509888964705169 -->grad_value: -9.105839126277715e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2074832890648395e-05 -->grad_value: -1.087931309484702e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279900114051998 -->grad_value: -0.00022903263743501157 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033272106666117907 -->grad_value: -0.00022903263743501157 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213401401415467 -->grad_value: 0.00038671866059303284 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018204061314463615 -->grad_value: -0.7227152585983276 

INFO:root:
 ** Round 12 : Batch size = 20 , avg loss = 0.008695432846434415

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011310660047456622 -->grad_value: -0.0008346231188625097 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032495788764208555 -->grad_value: -1.7494546256102694e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009607292013242841 -->grad_value: -1.356248958472861e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009395420784130692 -->grad_value: -1.356248958472861e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811552982777357 -->grad_value: -0.003095554420724511 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689667684957385 -->grad_value: 4.623051275132184e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319250773638487 -->grad_value: -1.54915073835582e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729868844151497 -->grad_value: -1.54915073835582e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.9985828809440136e-05 -->grad_value: 8.54869313116069e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421615401748568 -->grad_value: -2.983641422815708e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011403713142499328 -->grad_value: -8.356218313565478e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007509956485591829 -->grad_value: -8.356218313565478e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.20746291638352e-05 -->grad_value: -2.520374380310386e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279842488467693 -->grad_value: -0.0001499811769463122 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327205777168274 -->grad_value: -0.0001499811769463122 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213317000307143 -->grad_value: 9.422504808753729e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018204061314463615 -->grad_value: -0.5026230812072754 

INFO:root:
 ** Round 13 : Batch size = 19 , avg loss = 0.006800963322779066

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001131053315475583 -->grad_value: -0.001369018224067986 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032495937193743885 -->grad_value: -3.258010750073481e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009607698302716017 -->grad_value: -2.7016183139494387e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009395017987117171 -->grad_value: -2.7016183139494387e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811511073261499 -->grad_value: -0.0031791876535862684 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689606566913426 -->grad_value: 1.2624583156650715e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.000831933633890003 -->grad_value: -1.716002770990599e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729860462248325 -->grad_value: -1.716002770990599e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.9985741497948766e-05 -->grad_value: 1.345879354630597e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034216223866678774 -->grad_value: -4.5105826984581654e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0001140472013503313 -->grad_value: -0.00013514149759430438 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510069408454001 -->grad_value: -0.00013514149759430438 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207580423098989e-05 -->grad_value: 7.023575676612381e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279773803427815 -->grad_value: -0.00021086633205413818 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033271987922489643 -->grad_value: -0.00021086633205413818 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213215136900544 -->grad_value: -0.00019056722521781921 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.018204061314463615 -->grad_value: -0.7012884020805359 

INFO:root:
 ** Round 14 : Batch size = 20 , avg loss = 0.007146594079677016

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011310246773064137 -->grad_value: -0.001706878305412829 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032496178755536675 -->grad_value: -2.988787173308083e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.000960838922765106 -->grad_value: -2.7910209610126913e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009394322405569255 -->grad_value: -2.7910209610126913e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.000581147032789886 -->grad_value: -0.002601406304165721 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689594925381243 -->grad_value: 1.6343953745945328e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595945067704 -->grad_value: -1.090065097741899e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0047298334538936615 -->grad_value: -1.090065097741899e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998378790332936e-05 -->grad_value: 1.6002279608073877e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421631408855319 -->grad_value: -6.946278290342889e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0001140659733209759 -->grad_value: -0.00018241364159621298 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510266732424498 -->grad_value: -0.00018241364159621298 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207665188005194e-05 -->grad_value: 3.301969968561025e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279673104174435 -->grad_value: -0.0002476471127010882 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327187616378069 -->grad_value: -0.0002476471127010882 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213174391537905 -->grad_value: -0.00010789325460791588 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.8462944030761719 

INFO:root:
 ** Round 15 : Batch size = 19 , avg loss = 0.008255514879956058

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001131016993895173 -->grad_value: -0.007807889021933079 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249619039706886 -->grad_value: -5.1426521707753636e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608487598598003 -->grad_value: -1.571739971950592e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009394227527081966 -->grad_value: -1.571739971950592e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811461014673114 -->grad_value: -0.00023304375645238906 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689594925381243 -->grad_value: 7.804460189220208e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319609914906323 -->grad_value: 1.4107924073414324e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0047298320569098 -->grad_value: 1.4107924073414324e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998387521482073e-05 -->grad_value: -1.3810647942591459e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421632864046842 -->grad_value: 2.0650568330893293e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011406847625039518 -->grad_value: 0.0005434083286672831 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510290597565472 -->grad_value: 0.0005434083286672831 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207608799333684e-05 -->grad_value: 3.322050815768307e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279666701331735 -->grad_value: -0.000178122179931961 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0033271873835474253 -->grad_value: -0.000178122179931961 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213331552222371 -->grad_value: -0.0052733393386006355 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -1.306954264640808 

INFO:root:
 ** Round 16 : Batch size = 19 , avg loss = 0.008399080742444647

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011310094268992543 -->grad_value: -0.009231328964233398 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249619621783495 -->grad_value: -7.853124373013998e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.000960857723839581 -->grad_value: -3.5267858038423583e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.000939413730520755 -->grad_value: -3.5267858038423583e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811455775983632 -->grad_value: -0.00025024497881531715 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368957746308297 -->grad_value: 2.6965619071006586e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319590706378222 -->grad_value: -1.325904577242909e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729834385216236 -->grad_value: -1.325904577242909e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998385702492669e-05 -->grad_value: -1.2897527994937263e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00034216357744298875 -->grad_value: 1.960323061211966e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407147394493222 -->grad_value: 0.00047464563976973295 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510322029702365 -->grad_value: 0.00047464563976973295 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207556048640981e-05 -->grad_value: 4.1818188947218005e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279671357944608 -->grad_value: -0.00031047442462295294 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327186219394207 -->grad_value: -0.00031047442462295294 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213546920567751 -->grad_value: -0.00520689319819212 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -1.6851638555526733 

INFO:root:
 ** Round 17 : Batch size = 19 , avg loss = 0.008156252534765946

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011310004629194736 -->grad_value: -0.010202392935752869 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249621076975018 -->grad_value: -1.2375132030228997e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608700638636947 -->grad_value: -4.832351351069519e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009394018561579287 -->grad_value: -4.832351351069519e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811495939269662 -->grad_value: 3.3574178814888e-07 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689565821550786 -->grad_value: 4.075435100503455e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319602929987013 -->grad_value: 3.1176762149698334e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729832522571087 -->grad_value: 3.1176762149698334e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.9983842473011464e-05 -->grad_value: -1.3011353075853549e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: 2.2276067284110468e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407560668885708 -->grad_value: 0.0004259924462530762 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510369759984314 -->grad_value: 0.0004259924462530762 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075495002791286e-05 -->grad_value: 3.6799347071792e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279653895646334 -->grad_value: -0.00038937904173508286 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.00038937904173508286 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0001021375646814704 -->grad_value: -0.004698264412581921 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -1.9596376419067383 

INFO:root:
 ** Round 18 : Batch size = 19 , avg loss = 0.008110784178011511

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011309994151815772 -->grad_value: -0.001087229116819799 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249621076975018 -->grad_value: -2.5863409192083964e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608713444322348 -->grad_value: -1.6308567865053192e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009394008084200323 -->grad_value: -1.6308567865053192e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.000581149710342288 -->grad_value: 0.0003693926555570215 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689564366359264 -->grad_value: 1.1046378034507143e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319607004523277 -->grad_value: 9.385461225974723e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729832522571087 -->grad_value: 9.385461225974723e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.9983878852799535e-05 -->grad_value: 7.861951871745987e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421638975851238 -->grad_value: 2.3337591414929193e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407589772716165 -->grad_value: -2.2157153580337763e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510370342060924 -->grad_value: -2.2157153580337763e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075484088854864e-05 -->grad_value: 1.212283109452983e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279651567339897 -->grad_value: -0.00011573061783565208 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.00011573061783565208 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: 0.0005881425458937883 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.5113210678100586 

INFO:root:
 ** Round 19 : Batch size = 20 , avg loss = 0.008149228384718299

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011309976689517498 -->grad_value: -0.0014110530028119683 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00032496213680133224 -->grad_value: -4.102550477114164e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.000960873905569315 -->grad_value: -2.2201188585313503e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393985383212566 -->grad_value: -2.2201188585313503e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811491864733398 -->grad_value: 6.926283094799146e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689568731933832 -->grad_value: 2.1307714703766578e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319597109220922 -->grad_value: 3.435557118791621e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729832988232374 -->grad_value: 3.435557118791621e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998388612875715e-05 -->grad_value: 1.3005653727304889e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: -1.0503758574031963e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407583951950073 -->grad_value: -4.6043103793635964e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510371506214142 -->grad_value: -4.6043103793635964e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075469536939636e-05 -->grad_value: -7.553353498224169e-10 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279650403186679 -->grad_value: -0.0002059958642348647 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.0002059958642348647 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: 0.0008898896630853415 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.8391640782356262 

INFO:root:
 ** Round 20 : Batch size = 20 , avg loss = 0.00810292863752693

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011309958063066006 -->grad_value: -0.0033319457434117794 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -9.510056031558634e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608769905753434 -->grad_value: -5.30689339939272e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -5.30689339939272e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: 0.041531339287757874 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956727674231 -->grad_value: 8.317798716461766e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: 2.338361355214147e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: 2.338361355214147e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.9983929784502834e-05 -->grad_value: -4.68788857688196e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: -3.6881371556773956e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: 0.00013285940804053098 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: 0.00013285940804053098 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207542951917276e-05 -->grad_value: 6.175405360409059e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -0.0004234235384501517 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.0004234235384501517 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213773930445313 -->grad_value: 7.740070577710867e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -1.6608507633209229 

INFO:root:
 ** Round 21 : Batch size = 20 , avg loss = 0.007103595265652985

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011309958063066006 -->grad_value: -0.000704831094481051 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -2.752148020590539e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608769905753434 -->grad_value: -1.327912627857586e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -1.327912627857586e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: -0.000626026710961014 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689568731933832 -->grad_value: 6.105254968247209e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319594198837876 -->grad_value: -5.736211505791289e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: -5.736211505791289e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.9983929784502834e-05 -->grad_value: 1.5617528958955518e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: -7.325778028643981e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -3.423163798288442e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -3.423163798288442e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207541496725753e-05 -->grad_value: 7.177334282459924e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -6.482782191596925e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -6.482782191596925e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213773930445313 -->grad_value: 0.000429659296059981 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.21434466540813446 

INFO:root:
 ** Round 22 : Batch size = 20 , avg loss = 0.007897278922609986

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0011309956898912787 -->grad_value: -0.0013237700331956148 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -4.587494828456329e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771069906652 -->grad_value: -2.7415735530667007e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -2.7415735530667007e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: -0.00041004002559930086 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00013689565821550786 -->grad_value: 1.3184094704854488e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319594780914485 -->grad_value: -6.59173338135588e-09 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0047298334538936615 -->grad_value: -6.59173338135588e-09 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.9983929784502834e-05 -->grad_value: 5.792198862764053e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: -1.857335547583716e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -7.836386794224381e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -7.836386794224381e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.207541496725753e-05 -->grad_value: 1.2235536814841907e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -0.00013420231698546559 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.00013420231698546559 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213773930445313 -->grad_value: 0.0002580482396297157 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.4283238649368286 

INFO:root:
 ** Round 23 : Batch size = 20 , avg loss = 0.007592347031459212

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: -0.0016192514449357986 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -5.8360051014005876e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -3.4669533306441735e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -3.4669533306441735e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: -0.00127878924831748 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: 1.3213447225268737e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: -4.634643460121879e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: -4.634643460121879e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998391887056641e-05 -->grad_value: 1.4217864645615919e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: -1.3645066587741894e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -0.00014089296746533364 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -0.00014089296746533364 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075418605236337e-05 -->grad_value: 2.2477256607089657e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -0.0002166993508581072 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.0002166993508581072 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: 0.0007578389486297965 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.6681696176528931 

INFO:root:
 ** Round 24 : Batch size = 20 , avg loss = 0.00666087802965194

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: 0.00024559497251175344 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -6.185544521031261e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -1.2532001392173697e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -1.2532001392173697e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: -4.683919178205542e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: 4.750460580460469e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: 3.8526451362486114e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: 3.8526451362486114e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998391887056641e-05 -->grad_value: -1.5602516612034378e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: 1.0195417132763396e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: 1.004534169624094e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: 1.004534169624094e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075418605236337e-05 -->grad_value: 3.086200308644038e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -4.103163064428372e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -4.103163064428372e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: -5.001259705750272e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: 0.0008940901607275009 

INFO:root:
 ** Round 25 : Batch size = 18 , avg loss = 0.0060464068729844354

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: -0.00040863692993298173 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -3.0224878599938165e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -1.0942275139314006e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -1.0942275139314006e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: -3.395347448531538e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: 6.296119625659458e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: -2.7447214279163745e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: -2.7447214279163745e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.998391887056641e-05 -->grad_value: 1.6504688460372563e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: 1.7651578332333884e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -1.8037357222056016e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -1.8037357222056016e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075418605236337e-05 -->grad_value: 5.00477540299471e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -4.8585658078081906e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -4.8585658078081906e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: -2.5858753360807896e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.12401098012924194 

INFO:root:
 ** Round 26 : Batch size = 20 , avg loss = 0.0073776730801910165

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: -0.00048206327483057976 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -2.605712623449108e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -1.5153804042711272e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -1.5153804042711272e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: -6.541877155541442e-06 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: 4.284312904445642e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: 2.938704142252391e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: 2.938704142252391e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.99839115946088e-05 -->grad_value: 3.750496944121551e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: -3.9032620691159536e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -3.558659955160692e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -3.558659955160692e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075422243215144e-05 -->grad_value: 3.9427658293789136e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -8.036326471483335e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -8.036326471483335e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: -7.923226803541183e-06 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.22257877886295319 

INFO:root:
 ** Round 27 : Batch size = 19 , avg loss = 0.0072227402982351025

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: -0.000371866044588387 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -5.553163262561611e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -1.075156319529924e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -1.075156319529924e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: 0.00017274207493755966 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: -3.815843196974811e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: 1.5959935240061895e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: 1.5959935240061895e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.99839115946088e-05 -->grad_value: -6.972368282731622e-08 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: 2.0067761852260446e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -2.2571675799554214e-06 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -2.2571675799554214e-06 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075422243215144e-05 -->grad_value: -8.135104963002959e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -3.0010152840986848e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -3.0010152840986848e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: 0.0007088351994752884 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.13447555899620056 

INFO:root:
 ** Round 28 : Batch size = 20 , avg loss = 0.008258448611013592

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: -0.001101445290260017 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -3.9178758015623316e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -9.401589977642288e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -9.401589977642288e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: 6.523501360788941e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: -1.0309152642662411e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: -1.497778043813014e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: -1.497778043813014e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.99839115946088e-05 -->grad_value: 3.279878910689149e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: 1.3228324746705766e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -4.851395351579413e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -4.851395351579413e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075422243215144e-05 -->grad_value: -2.126018898707116e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -0.00012406689347699285 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.00012406689347699285 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: 0.0018074591644108295 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.46785295009613037 

INFO:root:
 ** Round 29 : Batch size = 20 , avg loss = 0.0069529051193967465

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: -0.0016727866604924202 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -4.6287723876048403e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -1.9617248199210735e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -1.9617248199210735e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: 5.764368688687682e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: -1.2713226915650466e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: -1.5906081785033166e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: -1.5906081785033166e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.99839115946088e-05 -->grad_value: 7.990463473106502e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: 4.181083568255417e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -0.00010317869600839913 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -0.00010317869600839913 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075422243215144e-05 -->grad_value: -1.5766678416184732e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -0.00017634165124036372 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -0.00017634165124036372 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: 0.0017483296105638146 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.6329305768013 

INFO:root:
 ** Round 30 : Batch size = 20 , avg loss = 0.007821442605927587

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001130995573475957 -->grad_value: -0.0013180527603253722 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0003249622241128236 -->grad_value: -3.595939190859099e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0009608771651983261 -->grad_value: -1.8856692349800142e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0009393960935994983 -->grad_value: -1.8856692349800142e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0005811490118503571 -->grad_value: -0.00010141387610929087 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001368956291116774 -->grad_value: 6.321831058642147e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0008319595362991095 -->grad_value: -7.212108243948023e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.004729833919554949 -->grad_value: -7.212108243948023e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -4.99839115946088e-05 -->grad_value: 7.978119356266689e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003421639557927847 -->grad_value: 5.59232802288534e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00011407578131183982 -->grad_value: -6.570030382135883e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0007510374416597188 -->grad_value: -6.570030382135883e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.2075422243215144e-05 -->grad_value: 9.77924855760648e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002818976645357907 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009279648656956851 -->grad_value: -9.808830509427935e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.003327183658257127 -->grad_value: -9.808830509427935e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.00010213779751211405 -->grad_value: 0.0006781722186133265 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.01820409670472145 -->grad_value: -0.322882741689682 

INFO:root:
TEST Batch No. 31 --> accurary = 0.0%

INFO:root:
TEST Batch No. 32 --> accurary = 0.0%

INFO:root:
TEST Batch No. 33 --> accurary = 0.0%

INFO:root:
TEST Batch No. 34 --> accurary = 0.0%

INFO:root:
TEST Batch No. 35 --> accurary = 0.0%

INFO:root:
TEST Batch No. 36 --> accurary = 0.0%

INFO:root:
TEST Batch No. 37 --> accurary = 0.0%

INFO:root:
TEST Batch No. 38 --> accurary = 0.0%

INFO:root:
TEST Batch No. 39 --> accurary = 0.0%

INFO:root:
TEST Batch No. 40 --> accurary = 0.0%

