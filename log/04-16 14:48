INFO:root:
 ======== Start Log Recording :04-16 14:48 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 18 , avg loss = 0.010573904786724597

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015969949308782816 -->grad_value: -0.0013129181461408734 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 3.160320920869708e-05 -->grad_value: 3.821031668849173e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007743305177427828 -->grad_value: -3.090723907916981e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00016850035171955824 -->grad_value: -3.090723907916981e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -4.794460255652666e-05 -->grad_value: -0.0010212704073637724 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010884124640142545 -->grad_value: 6.834522991994163e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.001386512303724885 -->grad_value: -2.6265199721819954e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002708537969738245 -->grad_value: -2.6265199721819954e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00013143863179720938 -->grad_value: 4.887864633928984e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 3.327312879264355e-05 -->grad_value: -9.84999587672064e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0019306957256048918 -->grad_value: -0.00030394765781238675 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.003093413542956114 -->grad_value: -0.00030394765781238675 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001710033684503287 -->grad_value: -5.88683906244114e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0006221329094842076 -->grad_value: 0.0001891144784167409 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0025618027430027723 -->grad_value: 0.0001891144784167409 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0022956482134759426 -->grad_value: -0.016884207725524902 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06227443367242813 -->grad_value: -1.0279990434646606 

INFO:root:
 ** Round 1 : Batch size = 20 , avg loss = 0.009191060764715075

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001570434309542179 -->grad_value: 0.0016334573738276958 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 3.1017494620755315e-05 -->grad_value: 3.6228065880550275e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007520992076024413 -->grad_value: 5.262498234515078e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0001462689251638949 -->grad_value: 5.262498234515078e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -4.22330922447145e-05 -->grad_value: 0.002391867572441697 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010829257371369749 -->grad_value: -1.7189547918405879e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0013920144410803914 -->grad_value: 3.4914476145786466e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0027030359487980604 -->grad_value: 3.4914476145786466e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00012836101814173162 -->grad_value: -2.487595338607207e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 3.2570751500315964e-05 -->grad_value: 4.0566159441368654e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001940972520969808 -->grad_value: 0.0013315491378307343 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0031036899890750647 -->grad_value: 0.0013315491378307343 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016672536730766296 -->grad_value: -5.992299065837869e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0005063144490122795 -->grad_value: 0.0001948237477336079 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0024459848646074533 -->grad_value: 0.0001948237477336079 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002192213200032711 -->grad_value: -0.0011913338676095009 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0632428526878357 -->grad_value: 0.0215789545327425 

INFO:root:
 ** Round 2 : Batch size = 19 , avg loss = 0.011948146606109253

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015757865039631724 -->grad_value: 0.005362352356314659 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 3.1292744097299874e-05 -->grad_value: 3.136541337767085e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007948954589664936 -->grad_value: 1.2610551493708044e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018906575860455632 -->grad_value: 1.2610551493708044e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.0885417042300105e-05 -->grad_value: 0.007857915945351124 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010958053462672979 -->grad_value: -3.6885165854982915e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014388876734301448 -->grad_value: 1.1733685823855922e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026561631821095943 -->grad_value: 1.1733685823855922e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010845495853573084 -->grad_value: -7.227875175885856e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -4.8013309424277395e-05 -->grad_value: 0.00011511649063322693 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0013061568606644869 -->grad_value: 0.004023982211947441 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024688742123544216 -->grad_value: 0.004023982211947441 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00015977122529875487 -->grad_value: -6.117501470725983e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0002821316011250019 -->grad_value: 0.0002379095967626199 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002221801783889532 -->grad_value: 0.0002379095967626199 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002159568015486002 -->grad_value: 0.02531293034553528 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06277782469987869 -->grad_value: 1.8400108814239502 

INFO:root:
 ** Round 3 : Batch size = 20 , avg loss = 0.0066563889617100355

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001578749273903668 -->grad_value: 0.00015100072778295726 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 3.1049028621055186e-05 -->grad_value: 7.1161085912763156e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008068731985986233 -->grad_value: 1.1981843783814838e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00020104332361370325 -->grad_value: 1.1981843783814838e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.755124195478857e-05 -->grad_value: 0.000670523033477366 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010991928138537332 -->grad_value: -6.216398062974804e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014520275872200727 -->grad_value: 2.0670663047894777e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026430231519043446 -->grad_value: 2.0670663047894777e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010226769518340006 -->grad_value: 9.364489415020216e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -6.746192229911685e-05 -->grad_value: -5.833945806443808e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011484954738989472 -->grad_value: -3.366592136444524e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002311212942004204 -->grad_value: -3.366592136444524e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001582345721544698 -->grad_value: -6.360235715874296e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023776362650096416 -->grad_value: 4.166792223259108e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021774338092654943 -->grad_value: 4.166792223259108e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002163924043998122 -->grad_value: -0.0003652471350505948 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0625360831618309 -->grad_value: -0.04222036153078079 

INFO:root:
 ** Round 4 : Batch size = 20 , avg loss = 0.0067194881150498985

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015762618277221918 -->grad_value: 0.00026495588826946914 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 3.0500435968860984e-05 -->grad_value: -8.784994953714431e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008087773458100855 -->grad_value: 2.550120541400247e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00020294712157920003 -->grad_value: 2.550120541400247e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.7583576310426e-05 -->grad_value: 0.0006711902096867561 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010972892050631344 -->grad_value: -2.3016017980381775e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014524438884109259 -->grad_value: 2.1562379970418988e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026426073163747787 -->grad_value: 2.1562379970418988e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010244990698993206 -->grad_value: 9.821350204219925e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.055266905808821e-05 -->grad_value: -1.302949499404349e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011319656623527408 -->grad_value: -5.955069718766026e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002294683363288641 -->grad_value: -5.955069718766026e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001584056590218097 -->grad_value: 2.55721488429117e-09 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023544533178210258 -->grad_value: 6.228499387361808e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002175114816054702 -->grad_value: 6.228499387361808e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002165397396311164 -->grad_value: -0.0010640228865668178 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06251950562000275 -->grad_value: -0.07691095024347305 

INFO:root:
 ** Round 5 : Batch size = 19 , avg loss = 0.006970798327146392

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015775017673149705 -->grad_value: 7.950176950544119e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 3.0041468562558293e-05 -->grad_value: -5.8699152205576866e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008110406342893839 -->grad_value: 2.9512818855437217e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00020521035185083747 -->grad_value: 2.9512818855437217e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.60190125927329e-05 -->grad_value: 0.00044549000449478626 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010963319800794125 -->grad_value: -1.2123225756610623e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.001452832599170506 -->grad_value: 1.549132377931528e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002642218256369233 -->grad_value: 1.549132377931528e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010282053699484095 -->grad_value: 3.6352719234855613e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.122461101971567e-05 -->grad_value: -4.776491550728679e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011376958573237062 -->grad_value: -0.0001778056612238288 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023004126269370317 -->grad_value: -0.0001778056612238288 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00015886727487668395 -->grad_value: -3.341040155646624e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023311586119234562 -->grad_value: 2.2060816263547167e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002172785112634301 -->grad_value: 2.2060816263547167e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002164699137210846 -->grad_value: -0.0036873696371912956 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0625724121928215 -->grad_value: -0.23765484988689423 

INFO:root:
 ** Round 6 : Batch size = 20 , avg loss = 0.006457701174076647

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001579917035996914 -->grad_value: -0.00048789283027872443 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.989223867189139e-05 -->grad_value: 7.355872355674364e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008118601981550455 -->grad_value: 4.835375477796333e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00020602968288585544 -->grad_value: 4.835375477796333e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.599590415135026e-05 -->grad_value: 8.94328550202772e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010964346438413486 -->grad_value: -6.813641650893487e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014515313087031245 -->grad_value: 1.0495080005057389e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.00264351861551404 -->grad_value: 1.0495080005057389e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010278472473146394 -->grad_value: -6.196151502990688e-08 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.14624475222081e-05 -->grad_value: 5.206652531342115e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011394410394132137 -->grad_value: 1.991382487176452e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023021583911031485 -->grad_value: 1.991382487176452e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00015906502085272223 -->grad_value: 7.761796183558545e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023269187659025192 -->grad_value: -5.037552000430878e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002172362059354782 -->grad_value: -5.037552000430878e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021648637484759092 -->grad_value: 0.00027181266341358423 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06258455663919449 -->grad_value: 0.015682099387049675 

INFO:root:
 ** Round 7 : Batch size = 20 , avg loss = 0.006587026314809919

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015795259969308972 -->grad_value: -0.0007426129304803908 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.956157550215721e-05 -->grad_value: 6.762061133258612e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008065995061770082 -->grad_value: 4.2348361262156686e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00020076887449249625 -->grad_value: 4.2348361262156686e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.824787124060094e-05 -->grad_value: 0.00015328818699344993 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010980993101838976 -->grad_value: -1.40948195337387e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.001451306277886033 -->grad_value: 2.626592845444975e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026437435299158096 -->grad_value: 2.626592845444975e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010212502093054354 -->grad_value: 3.0008422413629887e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.138200453482568e-05 -->grad_value: -1.340585868092603e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011405965778976679 -->grad_value: -5.701449845219031e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002303313696756959 -->grad_value: -5.701449845219031e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00015951733803376555 -->grad_value: 2.2378853259397147e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.000234267208725214 -->grad_value: 7.757127605145797e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021739366929978132 -->grad_value: 7.757127605145797e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021661592181771994 -->grad_value: -0.0008197661372832954 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06258668005466461 -->grad_value: -0.07349960505962372 

INFO:root:
 ** Round 8 : Batch size = 19 , avg loss = 0.006613737437874079

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015788959572091699 -->grad_value: -0.0007240675622597337 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.931778726633638e-05 -->grad_value: 1.280716421803163e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007990815211087465 -->grad_value: -5.289359705784591e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00019325106404721737 -->grad_value: -5.289359705784591e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.99884258210659e-05 -->grad_value: 0.00015310660819523036 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010978001955663785 -->grad_value: -1.5441932177395756e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014515614602714777 -->grad_value: 3.388745994925557e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026434885803610086 -->grad_value: 3.388745994925557e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010005265357904136 -->grad_value: -2.850290741207573e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.087368430802599e-05 -->grad_value: -1.9587832866818644e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011442976538091898 -->grad_value: -8.274371066363528e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.00230701407417655 -->grad_value: -8.274371066363528e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016057149332482368 -->grad_value: 4.6501935457854415e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0002351566217839718 -->grad_value: 1.0689240298233926e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002174826106056571 -->grad_value: 1.0689240298233926e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021681939251720905 -->grad_value: -0.0012420949060469866 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06260621547698975 -->grad_value: -0.10494577139616013 

INFO:root:
 ** Round 9 : Batch size = 19 , avg loss = 0.006962505218229796

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015790502075105906 -->grad_value: -3.080742317251861e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9288057703524828e-05 -->grad_value: 1.850891107046948e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007971799350343645 -->grad_value: 2.1289258711476577e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00019134889589622617 -->grad_value: 2.1289258711476577e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.874394603073597e-05 -->grad_value: -5.4676231229677796e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010961336374748498 -->grad_value: -6.070910885114245e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014494461938738823 -->grad_value: 2.983020692681748e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026456033810973167 -->grad_value: 2.983020692681748e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -9.978650632547215e-05 -->grad_value: -2.0311820208007703e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.074636232573539e-05 -->grad_value: 1.4867814570607152e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011456223437562585 -->grad_value: 2.2074900698498823e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023083386477082968 -->grad_value: 2.2074900698498823e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016106665134429932 -->grad_value: 5.580981792263628e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023466278798878193 -->grad_value: -2.1509042653633514e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021743327379226685 -->grad_value: -2.1509042653633514e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021696279291063547 -->grad_value: 0.001435497310012579 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06261251121759415 -->grad_value: 0.027478741481900215 

INFO:root:
 ** Round 10 : Batch size = 20 , avg loss = 0.007225825451314449

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015794220380485058 -->grad_value: -0.0002425786224193871 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9303861083462834e-05 -->grad_value: 1.7662982187971465e-10 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007973277242854238 -->grad_value: 4.312305179610121e-09 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00019149674335494637 -->grad_value: 4.312305179610121e-09 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.879455759190023e-05 -->grad_value: -6.174280861159787e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010951163130812347 -->grad_value: -1.0600736288779444e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014500573743134737 -->grad_value: 1.2968294527127e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002644992433488369 -->grad_value: 1.2968294527127e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -9.98901086859405e-05 -->grad_value: -1.6880795783436042e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.080845534801483e-05 -->grad_value: 1.0532143051023013e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001146813970990479 -->grad_value: 3.7466079447767697e-06 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002309530507773161 -->grad_value: 3.7466079447767697e-06 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016162951942533255 -->grad_value: 6.047820306775975e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023488211445510387 -->grad_value: 7.776634447509423e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021745518315583467 -->grad_value: 7.776634447509423e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021727001294493675 -->grad_value: 0.0009032113594003022 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0626116394996643 -->grad_value: -0.0028807856142520905 

INFO:root:
 ** Round 11 : Batch size = 20 , avg loss = 0.05630045954603702

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015782028203830123 -->grad_value: 0.00018993312551174313 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9307760996744037e-05 -->grad_value: -6.977469269031644e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007957588532008231 -->grad_value: 6.095144300388711e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0001899278722703457 -->grad_value: 6.095144300388711e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.930920062586665e-05 -->grad_value: 1.3419710739981383e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001092399179469794 -->grad_value: -1.531325644066328e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014499275712296367 -->grad_value: 3.317472874186933e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002645123051479459 -->grad_value: 3.317472874186933e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010076490434585139 -->grad_value: -1.1391396128601627e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.09540763637051e-05 -->grad_value: 4.06487345117057e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001148692797869444 -->grad_value: -2.6733323466032743e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023114087525755167 -->grad_value: -2.6733323466032743e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001620152615942061 -->grad_value: 3.658555556285137e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023482250981032848 -->grad_value: 1.783830339263659e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002174493158236146 -->grad_value: 1.783830339263659e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021760312374681234 -->grad_value: 0.00010473317524883896 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06261425465345383 -->grad_value: -0.05039287358522415 

INFO:root:
 ** Round 12 : Batch size = 20 , avg loss = 0.056640134239569304

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015780437970533967 -->grad_value: -0.00022982027439866215 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9328890377655625e-05 -->grad_value: -8.235037540771373e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007954450557008386 -->grad_value: -2.7553548420655716e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018961378373205662 -->grad_value: -2.7553548420655716e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.879601278342307e-05 -->grad_value: -0.00020410741853993386 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001091713784262538 -->grad_value: -3.6956970816959256e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.001448943978175521 -->grad_value: -2.045288454155525e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026461060624569654 -->grad_value: -2.045288454155525e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010102013766299933 -->grad_value: 1.5563184661004925e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.08472216501832e-05 -->grad_value: -3.7650954709533835e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001150108058936894 -->grad_value: -0.00012007645273115486 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002312824595719576 -->grad_value: -0.00012007645273115486 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016208297165576369 -->grad_value: -1.895032255561091e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0002347608096897602 -->grad_value: 1.682760012045037e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021744314581155777 -->grad_value: 1.682760012045037e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021754764020442963 -->grad_value: -0.0020339791662991047 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06262169033288956 -->grad_value: -0.13221785426139832 

INFO:root:
 ** Round 13 : Batch size = 19 , avg loss = 0.007019127621070335

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015775306383147836 -->grad_value: 0.0005496880621649325 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.938132092822343e-05 -->grad_value: -9.148482860155127e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007943017408251762 -->grad_value: -1.4016350746715034e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018847058527171612 -->grad_value: -1.4016350746715034e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.7280197981745e-05 -->grad_value: -2.5557606932125054e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010898822802118957 -->grad_value: 7.716336458685191e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014452493051066995 -->grad_value: -4.0442813542540534e-09 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026498008519411087 -->grad_value: -4.0442813542540534e-09 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010109966387972236 -->grad_value: 6.728092785124318e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.05536876921542e-05 -->grad_value: -1.8186332226832747e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001152431359514594 -->grad_value: -7.480038038920611e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023151468485593796 -->grad_value: -7.480038038920611e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016206617874559015 -->grad_value: -1.4742316523097543e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023511121980845928 -->grad_value: 1.4404456123884302e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021747818682342768 -->grad_value: 1.4404456123884302e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021728472784161568 -->grad_value: -0.0014263701159507036 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06263536214828491 -->grad_value: -0.09270568192005157 

INFO:root:
 ** Round 14 : Batch size = 20 , avg loss = 0.05660346215590835

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015786030562594533 -->grad_value: 0.0005952558713033795 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9419330530799925e-05 -->grad_value: -3.1230094066359015e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007930444553494453 -->grad_value: 1.8821087621745392e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.000187214114703238 -->grad_value: 1.8821087621745392e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.589799886569381e-05 -->grad_value: 0.00015262105443980545 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010860105976462364 -->grad_value: -8.301166865010146e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014395907055586576 -->grad_value: 3.3658389497759345e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002655459102243185 -->grad_value: 3.3658389497759345e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.000100639634183608 -->grad_value: -1.2100147159799235e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.044926314847544e-05 -->grad_value: -5.315320663612511e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011538928374648094 -->grad_value: -3.929144440917298e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023166085593402386 -->grad_value: -3.929144440917298e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001618169917492196 -->grad_value: 2.0411562218214385e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023466162383556366 -->grad_value: 7.805549103068188e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002174331806600094 -->grad_value: 7.805549103068188e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002170856576412916 -->grad_value: -0.00040842333692125976 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06264590471982956 -->grad_value: -0.04309592768549919 

INFO:root:
 ** Round 15 : Batch size = 19 , avg loss = 0.00763203453664717

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015784800052642822 -->grad_value: 0.00016903493087738752 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.939594560302794e-05 -->grad_value: 6.2806622125322065e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007925666286610067 -->grad_value: -2.6861542323786125e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018673657905310392 -->grad_value: -2.6861542323786125e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.490189116448164e-05 -->grad_value: -0.0004140754172112793 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010853000276256353 -->grad_value: -6.65991439774416e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014386128168553114 -->grad_value: -1.277800691923403e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026564376894384623 -->grad_value: -1.277800691923403e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010046025272458792 -->grad_value: -1.6852868611749727e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.047450344543904e-05 -->grad_value: 9.960656370822107e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011540327686816454 -->grad_value: 2.7759433578466997e-06 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002316748723387718 -->grad_value: 2.7759433578466997e-06 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001617315865587443 -->grad_value: -3.88467924494762e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023424322716891766 -->grad_value: 2.0149902411503717e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002173913409933448 -->grad_value: 2.0149902411503717e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002171736676245928 -->grad_value: 0.0010314726969227195 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06264945864677429 -->grad_value: -0.10977070778608322 

INFO:root:
 ** Round 16 : Batch size = 19 , avg loss = 0.007494151665780105

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015767489094287157 -->grad_value: -6.349570321617648e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9353192076086998e-05 -->grad_value: 1.3109768381980302e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007910004933364689 -->grad_value: -6.755329877705663e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018516997806727886 -->grad_value: -6.755329877705663e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.298779044300318e-05 -->grad_value: -0.0008383950334973633 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010849755199160427 -->grad_value: 5.188311558157466e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.001438164385035634 -->grad_value: -7.862831807869952e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002656885888427496 -->grad_value: -7.862831807869952e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010025480878539383 -->grad_value: -1.1592047144404205e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.045968959573656e-05 -->grad_value: -2.1839234705112176e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011541220592334867 -->grad_value: -0.0001187972811749205 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023168381303548813 -->grad_value: -0.0001187972811749205 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016157457139343023 -->grad_value: -3.64213946113523e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023258943110704422 -->grad_value: 4.0089027606882155e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002172259846702218 -->grad_value: 4.0089027606882155e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021735364571213722 -->grad_value: -0.001134177902713418 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06265875697135925 -->grad_value: -0.2797252833843231 

INFO:root:
 ** Round 17 : Batch size = 19 , avg loss = 0.05910800669440314

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015740765957161784 -->grad_value: -0.00024233067233581096 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9298156732693315e-05 -->grad_value: 7.914223942862009e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007885544328019023 -->grad_value: -8.073274102571304e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018272362649440765 -->grad_value: -8.073274102571304e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -6.0348043916746974e-05 -->grad_value: -0.0008006173302419484 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010845326323760673 -->grad_value: 4.212586723895129e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014368402771651745 -->grad_value: -7.276236146935844e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002658209763467312 -->grad_value: -7.276236146935844e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010008402750827372 -->grad_value: 9.145230706053553e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.040795753709972e-05 -->grad_value: -3.065094460907858e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011548928450793028 -->grad_value: -0.00015755901404190809 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002317609265446663 -->grad_value: -0.00015755901404190809 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001613943895790726 -->grad_value: -5.319628257893783e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023024738766252995 -->grad_value: 4.59816656075418e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021699173375964165 -->grad_value: 4.59816656075418e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00217499234713614 -->grad_value: -0.0017207302153110504 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06267523020505905 -->grad_value: -0.31941306591033936 

INFO:root:
 ** Round 18 : Batch size = 19 , avg loss = 0.006942669223797948

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015736076747998595 -->grad_value: -0.00021569689852185547 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9285583877936006e-05 -->grad_value: 1.8269392665359874e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007880282355472445 -->grad_value: 6.187472223473378e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018219620687887073 -->grad_value: 6.187472223473378e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.975819658488035e-05 -->grad_value: 2.362880877626594e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010844749340321869 -->grad_value: -5.386127099882287e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014365802053362131 -->grad_value: -1.3900177009418258e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026584696024656296 -->grad_value: -1.3900177009418258e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010008430399466306 -->grad_value: 3.5625322425403283e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.040073251118883e-05 -->grad_value: -1.0947526334348368e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011551789939403534 -->grad_value: -4.977781281922944e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002317895647138357 -->grad_value: -4.977781281922944e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016136393242049962 -->grad_value: 8.485605462738022e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0002298196777701378 -->grad_value: 5.454401616589166e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021694893948733807 -->grad_value: 5.454401616589166e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021752307657152414 -->grad_value: -0.0007486081449314952 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06267903000116348 -->grad_value: -0.057261399924755096 

INFO:root:
 ** Round 19 : Batch size = 20 , avg loss = 0.006684902217239141

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015735954511910677 -->grad_value: -0.0004691150097642094 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.927922469098121e-05 -->grad_value: -2.619526373592862e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007877394091337919 -->grad_value: -9.064716266493633e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018190720584243536 -->grad_value: -9.064716266493633e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.923063145019114e-05 -->grad_value: -0.0001458923943573609 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010843807831406593 -->grad_value: -1.1692140589047995e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.00143626076169312 -->grad_value: -2.2318749870464671e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026587885804474354 -->grad_value: -2.2318749870464671e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010018164903158322 -->grad_value: 1.3473110129780252e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.040283526293933e-05 -->grad_value: -2.075961219816236e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001155745703727007 -->grad_value: -9.565310028847307e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023184623569250107 -->grad_value: -9.565310028847307e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016137369675561786 -->grad_value: 4.040148837702873e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00022986321710050106 -->grad_value: 7.62471609050408e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002169532934203744 -->grad_value: 7.62471609050408e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021750677842646837 -->grad_value: -0.001497819321230054 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06268182396888733 -->grad_value: -0.10200478136539459 

INFO:root:
 ** Round 20 : Batch size = 20 , avg loss = 0.056793392659164964

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015740870730951428 -->grad_value: -0.00034076429437845945 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.931173366960138e-05 -->grad_value: -9.019007762844922e-12 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007876401650719345 -->grad_value: -7.263988663908094e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018180767074227333 -->grad_value: -7.263988663908094e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.8729463489726186e-05 -->grad_value: -0.00012053041427861899 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001084270334104076 -->grad_value: -5.022659621545245e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014356239698827267 -->grad_value: -2.643756715769996e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026594253722578287 -->grad_value: -2.643756715769996e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010035785817308351 -->grad_value: 7.293175485756365e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.041310891509056e-05 -->grad_value: -4.005667051387718e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011567119508981705 -->grad_value: -0.00018186584929935634 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002319428138434887 -->grad_value: -0.00018186584929935634 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016139949730131775 -->grad_value: 3.1901114994070667e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023008394055068493 -->grad_value: 1.6095757018774748e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021697538904845715 -->grad_value: 1.6095757018774748e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021749362349510193 -->grad_value: -0.0025052109267562628 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0626865029335022 -->grad_value: -0.23821721971035004 

INFO:root:
 ** Round 21 : Batch size = 20 , avg loss = 0.007274970388971269

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015742034884169698 -->grad_value: -9.629151463741437e-06 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9313639970496297e-05 -->grad_value: 4.933849773181009e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007875589653849602 -->grad_value: 3.424830197218398e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018172647105529904 -->grad_value: 3.424830197218398e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.8653007727116346e-05 -->grad_value: 0.00032942136749625206 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010843002382898703 -->grad_value: -9.433899883504182e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014355763560160995 -->grad_value: 3.2030067131927353e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002659473568201065 -->grad_value: 3.2030067131927353e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010040236520580947 -->grad_value: -4.97947212352301e-08 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.03900441294536e-05 -->grad_value: -1.3976894024381181e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011570585193112493 -->grad_value: -3.582975477911532e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002319774590432644 -->grad_value: -3.582975477911532e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016142145614139736 -->grad_value: 2.351908960918081e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023005856201052666 -->grad_value: 1.9485138182062656e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002169728511944413 -->grad_value: 1.9485138182062656e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021749890875071287 -->grad_value: -0.0002909898466896266 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06268838047981262 -->grad_value: -0.04509264975786209 

INFO:root:
 ** Round 22 : Batch size = 20 , avg loss = 0.006679169530980289

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015743453986942768 -->grad_value: -6.106319779064506e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.930602931883186e-05 -->grad_value: 1.2135842553107068e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007875391165725887 -->grad_value: 1.6090311305561045e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0001817072625271976 -->grad_value: 1.6090311305561045e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.867081927135587e-05 -->grad_value: 0.0002541412250138819 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010842955089174211 -->grad_value: -1.6078663733765097e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014356209430843592 -->grad_value: 2.3664074433327187e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026594288647174835 -->grad_value: 2.3664074433327187e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010041322093456984 -->grad_value: 2.466308330895117e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.034082227619365e-05 -->grad_value: -2.4352466425625607e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011573715601116419 -->grad_value: -8.071640331763774e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023200875148177147 -->grad_value: -8.071640331763774e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016144617984537035 -->grad_value: 2.692038094664895e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023003225214779377 -->grad_value: 2.3911714379210025e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002169703133404255 -->grad_value: 2.3911714379210025e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021750801242887974 -->grad_value: -0.0010209460742771626 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0626896396279335 -->grad_value: -0.09676465392112732 

INFO:root:
 ** Round 23 : Batch size = 20 , avg loss = 0.006506060145329684

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001574561814777553 -->grad_value: 8.008662553038448e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9295566491782665e-05 -->grad_value: 2.085194594769746e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007876140298321843 -->grad_value: 2.441293531774136e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018178147729486227 -->grad_value: 2.441293531774136e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.869823507964611e-05 -->grad_value: 1.4173652743920684e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010842938354471698 -->grad_value: -1.0209010525841222e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014356507454067469 -->grad_value: -1.2795267423371115e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002659399760887027 -->grad_value: -1.2795267423371115e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010044343798654154 -->grad_value: 1.248589001079381e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.027237734291703e-05 -->grad_value: -4.379001438792329e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011578737758100033 -->grad_value: -0.00013916645548306406 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023205901961773634 -->grad_value: -0.00013916645548306406 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0001614732900634408 -->grad_value: 2.3834842011183355e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00022996589541435242 -->grad_value: 3.117552478215657e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.00216963654384017 -->grad_value: 3.117552478215657e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021750624291598797 -->grad_value: -0.0024877111427485943 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06269211322069168 -->grad_value: -0.1710248440504074 

INFO:root:
 ** Round 24 : Batch size = 20 , avg loss = 0.0067001769319176676

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015745863784104586 -->grad_value: 0.00039693276630714536 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9292874387465417e-05 -->grad_value: 1.4344477605732209e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.000787633762229234 -->grad_value: 6.332313660095679e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018180161714553833 -->grad_value: 6.332313660095679e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.867099389433861e-05 -->grad_value: -3.13239979732316e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010842766641872004 -->grad_value: -1.1114783760035607e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.00143561908043921 -->grad_value: 2.0802252720386605e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026594309601932764 -->grad_value: 2.0802252720386605e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010045412636827677 -->grad_value: -1.5474781775992597e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.02600518707186e-05 -->grad_value: 2.518911969673354e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011579828569665551 -->grad_value: 7.4700903496705e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002320699393749237 -->grad_value: 7.4700903496705e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016148100257851183 -->grad_value: 2.8415152542038413e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0002299705520272255 -->grad_value: -1.37728620757116e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021696416661143303 -->grad_value: -1.37728620757116e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021750726737082005 -->grad_value: 0.0018725243862718344 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0626925677061081 -->grad_value: 0.09842569380998611 

INFO:root:
 ** Round 25 : Batch size = 18 , avg loss = 0.006267652639912235

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015745663549751043 -->grad_value: 0.0007327653584070504 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9296483262442052e-05 -->grad_value: 6.988324141588009e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007876422023400664 -->grad_value: 1.1219901807635324e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018180959159508348 -->grad_value: 1.1219901807635324e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.866910214535892e-05 -->grad_value: 0.00013641166151501238 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010842819028766826 -->grad_value: -1.079933920067333e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.001435647951439023 -->grad_value: 4.368053225789481e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002659401623532176 -->grad_value: 4.368053225789481e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010045093222288415 -->grad_value: -3.0500011689582607e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.027524407021701e-05 -->grad_value: 3.3086953408201225e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001157937222160399 -->grad_value: 0.00010978223872371018 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023206539917737246 -->grad_value: 0.00010978223872371018 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016148379654623568 -->grad_value: 2.1596974875137676e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023002643138170242 -->grad_value: -1.583896482770797e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021696961484849453 -->grad_value: -1.583896482770797e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021751481108367443 -->grad_value: 0.0020689917728304863 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06269189715385437 -->grad_value: 0.12336643040180206 

INFO:root:
 ** Round 26 : Batch size = 20 , avg loss = 0.0067464872263371944

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015746348071843386 -->grad_value: 0.0011367989936843514 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.93062039418146e-05 -->grad_value: 2.1834605234971605e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007878182223066688 -->grad_value: 1.8554931102698902e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0001819855533540249 -->grad_value: 1.8554931102698902e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.8804929722100496e-05 -->grad_value: 0.0002670185931492597 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010842497431440279 -->grad_value: -2.3713504049283074e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014358264161273837 -->grad_value: 7.348019153141649e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002659223508089781 -->grad_value: 7.348019153141649e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010043590737041086 -->grad_value: -3.7261456782289315e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.031174027360976e-05 -->grad_value: 3.823421593551757e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011577799450606108 -->grad_value: 0.0001263495796592906 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002320496831089258 -->grad_value: 0.0001263495796592906 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016147081623785198 -->grad_value: 3.779878170462325e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023004203103482723 -->grad_value: -1.79661965375999e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021697119809687138 -->grad_value: -1.79661965375999e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021753069013357162 -->grad_value: 0.0027410397306084633 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06269064545631409 -->grad_value: 0.149003267288208 

INFO:root:
 ** Round 27 : Batch size = 19 , avg loss = 0.00688312609532946

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015746494755148888 -->grad_value: -0.0002247855591122061 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.93083576252684e-05 -->grad_value: 9.383981591781776e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007878445903770626 -->grad_value: -7.753428121759498e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018201174680143595 -->grad_value: -7.753428121759498e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.883030826225877e-05 -->grad_value: 0.00017254165140911937 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001084234900190495 -->grad_value: -1.651614311981575e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.00143586122430861 -->grad_value: 5.640978884002834e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002659188350662589 -->grad_value: 5.640978884002834e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001004319274215959 -->grad_value: -1.3881252698411117e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.032103167148307e-05 -->grad_value: 1.9216736291127745e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011577511904761195 -->grad_value: 5.992143996991217e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023204681929200888 -->grad_value: 5.992143996991217e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016146840061992407 -->grad_value: 2.400318521722511e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023006275296211243 -->grad_value: -1.0308329365216196e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021697331685572863 -->grad_value: -1.0308329365216196e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002175350673496723 -->grad_value: 0.0014335907762870193 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06269029527902603 -->grad_value: 0.07840074598789215 

INFO:root:
 ** Round 28 : Batch size = 20 , avg loss = 0.006687021907418966

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001574649359099567 -->grad_value: 2.9619564884342253e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9308823286555707e-05 -->grad_value: 1.0251364201963042e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007878219475969672 -->grad_value: 2.608507259083126e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018198869656771421 -->grad_value: 2.608507259083126e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.8824371080845594e-05 -->grad_value: 0.00020168388437014073 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010842064511962235 -->grad_value: -2.506967433646423e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014358445769175887 -->grad_value: 6.091667614782637e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002659205812960863 -->grad_value: 6.091667614782637e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001004311052383855 -->grad_value: -2.2650929167866707e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.032326539047062e-05 -->grad_value: 2.013605353567982e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011577638797461987 -->grad_value: 4.944000829709694e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0023204805329442024 -->grad_value: 4.944000829709694e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016147055430337787 -->grad_value: 5.49431433682912e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023010699078440666 -->grad_value: -1.2536860594991595e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021697774063795805 -->grad_value: -1.2536860594991595e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002175374189391732 -->grad_value: 0.0016816266579553485 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06269003450870514 -->grad_value: 0.0796397253870964 

INFO:root:
 ** Round 29 : Batch size = 20 , avg loss = 0.05649034797679633

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.001574676833115518 -->grad_value: 0.00033032160717993975 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.930844493675977e-05 -->grad_value: 2.1300589736483744e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007878228789195418 -->grad_value: 8.660715025143872e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0001819890458136797 -->grad_value: 8.660715025143872e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.881744436919689e-05 -->grad_value: 0.00026958470698446035 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010841445327969268 -->grad_value: -3.457774511161915e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0014357789186760783 -->grad_value: 9.357983685731597e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002659271704033017 -->grad_value: 9.357983685731597e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010042709618574008 -->grad_value: -2.8216445571160875e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.032687426544726e-05 -->grad_value: 2.6248537778883474e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0011578021803870797 -->grad_value: 6.707931606797501e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002320517785847187 -->grad_value: 6.707931606797501e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016147500718943775 -->grad_value: 8.578492156630091e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00023020128719508648 -->grad_value: -2.0926938304910436e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021698710042983294 -->grad_value: -2.0926938304910436e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.002175420057028532 -->grad_value: 0.0024472144432365894 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06268961727619171 -->grad_value: 0.1089877039194107 

INFO:root:
 ** Round 30 : Batch size = 20 , avg loss = 0.00678932158043608

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015746968565508723 -->grad_value: 0.000536271370947361 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 2.9308241209946573e-05 -->grad_value: 1.2398899684740172e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007878388278186321 -->grad_value: -3.2900339874686324e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00018200534395873547 -->grad_value: -3.2900339874686324e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -5.88179100304842e-05 -->grad_value: -7.05228594597429e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010841372568393126 -->grad_value: 6.580798128652532e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.001435767626389861 -->grad_value: -3.6462736829889764e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026592821814119816 -->grad_value: -3.6462736829889764e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010042414942290634 -->grad_value: 1.457672510696284e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -7.032468420220539e-05 -->grad_value: -2.935233624157263e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.001157824182882905 -->grad_value: -0.00010001983173424378 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002320540603250265 -->grad_value: -0.00010001983173424378 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00016147656424436718 -->grad_value: 1.2483098998927744e-09 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.497860547620803e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0002302213106304407 -->grad_value: 1.7754990039975382e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021698912605643272 -->grad_value: 1.7754990039975382e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0021754298359155655 -->grad_value: -0.0015546944923698902 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.06268959492444992 -->grad_value: -0.1213187500834465 

INFO:root:
TEST Batch No. 31 --> pred = tensor([0.4043], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 47.368421052631575%

INFO:root:
TEST Batch No. 32 --> pred = tensor([0.3425], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 75.0%

INFO:root:
TEST Batch No. 33 --> pred = tensor([0.3733], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 47.05882352941176%

INFO:root:
TEST Batch No. 34 --> pred = tensor([0.4041], device='mps:0', grad_fn=<SelectBackward0>) target = 1.0 --> Accurary = 36.84210526315789%

INFO:root:
TEST Batch No. 35 --> pred = tensor([0.4362], device='mps:0', grad_fn=<SelectBackward0>) target = 1.0 --> Accurary = 42.10526315789473%

INFO:root:
TEST Batch No. 36 --> pred = tensor([0.2787], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 25.0%

INFO:root:
TEST Batch No. 37 --> pred = tensor([0.4310], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 57.89473684210527%

INFO:root:
TEST Batch No. 38 --> pred = tensor([0.3523], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 40.0%

INFO:root:
TEST Batch No. 39 --> pred = tensor([0.2583], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 60.0%

INFO:root:
TEST Batch No. 40 --> pred = tensor([0.3834], device='mps:0', grad_fn=<SelectBackward0>) target = 0.0 --> Accurary = 35.0%

