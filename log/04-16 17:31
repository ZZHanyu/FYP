INFO:root:
 ======== Start Log Recording :04-16 17:31 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 0.1850741323432885

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00043761124834418297 -->grad_value: 760789248.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 8.56768456287682e-05 -->grad_value: -253264.546875 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00039012706838548183 -->grad_value: -1621600.0 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019135340116918087 -->grad_value: -1621600.0 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0012245307443663478 -->grad_value: -1825911552.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00011025226558558643 -->grad_value: 168195.984375 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0032422556541860104 -->grad_value: -3758617.5 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.00030784099362790585 -->grad_value: -3758617.5 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00011986649769823998 -->grad_value: -41903104.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00026233404059894383 -->grad_value: 20037900.0 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0010633580386638641 -->grad_value: 1409314048.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0010180373210459948 -->grad_value: 1409314048.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -2.4357272195629776e-05 -->grad_value: 539924.0 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0009627286926843226 -->grad_value: 54747776.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0001495350297773257 -->grad_value: 54747776.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001188342459499836 -->grad_value: -61914566656.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005004496779292822 -->grad_value: -4656658382848.0 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.009112086160409186

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000412443041568622 -->grad_value: 760782976.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 8.686965156812221e-05 -->grad_value: -253264.25 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00036517134867608547 -->grad_value: -1621616.5 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019384886836633086 -->grad_value: -1621616.5 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0012198560871183872 -->grad_value: -1825971840.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00010650735930539668 -->grad_value: 168196.84375 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.003261259291321039 -->grad_value: -3758657.75 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0002888370072469115 -->grad_value: -3758657.75 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0001273244124604389 -->grad_value: -41902600.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0002833448234014213 -->grad_value: 20037794.0 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0009574980358593166 -->grad_value: 1409301760.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.001123897498473525 -->grad_value: 1409301760.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -3.178662882419303e-05 -->grad_value: 540088.0 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0010910634882748127 -->grad_value: 54743616.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.00027787016006186604 -->grad_value: 54743616.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.000926383538171649 -->grad_value: -61914701824.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.0027678741607815027 -->grad_value: -4656667295744.0 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.1691096273167932

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0004886194947175682 -->grad_value: 14813997056.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.260408114641905e-05 -->grad_value: -178673.375 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0005281964549794793 -->grad_value: 33517530.0 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001775464159436524 -->grad_value: 33517530.0 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0013660637196153402 -->grad_value: 11531258880.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00012477574637159705 -->grad_value: -667841.6875 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0030596437864005566 -->grad_value: 25890516.0 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0004904525703750551 -->grad_value: 25890516.0 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00016165533452294767 -->grad_value: -216952544.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00030775039340369403 -->grad_value: 52738496.0 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0001431617420166731 -->grad_value: 6940649472.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.002224557101726532 -->grad_value: 6940649472.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -8.933180652093142e-06 -->grad_value: -67296952.0 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.00038697768468409777 -->grad_value: 2198355456.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0004262158181518316 -->grad_value: 2198355456.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0009551658295094967 -->grad_value: 59974483968.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.0032975669018924236 -->grad_value: 4736550436864.0 

INFO:root:
 ** Round 3 : Batch size = 25 , avg loss = 0.007540505612269044

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005698162131011486 -->grad_value: 14813997056.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.798843530006707e-05 -->grad_value: -178673.375 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007060874486342072 -->grad_value: 33517530.0 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015975735150277615 -->grad_value: 33517530.0 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0015355334617197514 -->grad_value: 11531258880.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001475154422223568 -->grad_value: -667841.6875 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0028360416181385517 -->grad_value: 25890516.0 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0007140545058064163 -->grad_value: 25890516.0 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0001961487578228116 -->grad_value: -216952544.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003245508414693177 -->grad_value: 52738496.0 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0013565937988460064 -->grad_value: 6940649472.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0034379889257252216 -->grad_value: 6940649472.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 2.0441337255761027e-05 -->grad_value: -67296952.0 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0004939003847539425 -->grad_value: 2198355456.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0013070935383439064 -->grad_value: 2198355456.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0010779493022710085 -->grad_value: 59974483968.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005300465971231461 -->grad_value: 4736550436864.0 

INFO:root:
 ** Round 4 : Batch size = 24 , avg loss = 0.012142655742839755

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005972872604615986 -->grad_value: -0.00019208691082894802 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.939330630004406e-05 -->grad_value: -1.6461601859418806e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007586006540805101 -->grad_value: -6.280611728470831e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015450603095814586 -->grad_value: -6.280611728470831e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0015918712597340345 -->grad_value: -0.0027987873181700706 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.000154373818077147 -->grad_value: 2.2995397586100808e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0027637372259050608 -->grad_value: -5.40603480203572e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0007863588398322463 -->grad_value: -5.40603480203572e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00020580942509695888 -->grad_value: 3.7734434954472817e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003291324828751385 -->grad_value: -8.252385441664956e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0017116765957325697 -->grad_value: -0.0001886989630293101 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003793071722611785 -->grad_value: -0.0001886989630293101 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 2.7638081519398838e-05 -->grad_value: 2.8457334337872453e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0007541647646576166 -->grad_value: -0.00013017139281146228 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015673579182475805 -->grad_value: -0.00013017139281146228 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011149279307574034 -->grad_value: -0.02037733979523182 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005946754943579435 -->grad_value: -2.327971935272217 

INFO:root:
 ** Round 5 : Batch size = 25 , avg loss = 0.012327045511920005

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006184100639075041 -->grad_value: -0.0006633898592554033 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.853214578470215e-05 -->grad_value: -4.5257063874259984e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007754312828183174 -->grad_value: -9.128747819886485e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001528230495750904 -->grad_value: -9.128747819886485e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001606898964382708 -->grad_value: 0.0005243401974439621 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00015482403978239745 -->grad_value: 2.0919781462680476e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0027329684235155582 -->grad_value: 4.284168426238466e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.000817127525806427 -->grad_value: 4.284168426238466e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002080485428450629 -->grad_value: 4.998059011995792e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00032954386551864445 -->grad_value: -1.343137455478427e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0017435617046430707 -->grad_value: -0.0002919909020420164 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0038249571807682514 -->grad_value: -0.0002919909020420164 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 3.1032293918542564e-05 -->grad_value: 5.7516590459272265e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0007775351405143738 -->grad_value: -0.000230193545576185 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015907289925962687 -->grad_value: -0.000230193545576185 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011182483285665512 -->grad_value: -0.04612913727760315 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006004788912832737 -->grad_value: -5.236809730529785 

INFO:root:
 ** Round 6 : Batch size = 24 , avg loss = 0.013736200945762297

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006337434751912951 -->grad_value: 0.002534559229388833 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.817045065574348e-05 -->grad_value: -2.0805483558206106e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007861289195716381 -->grad_value: 1.0252462743665092e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001517532393336296 -->grad_value: 1.0252462743665092e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001601297641173005 -->grad_value: -0.004641042090952396 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00015433234511874616 -->grad_value: -3.765848646253289e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0027295206673443317 -->grad_value: 1.062562660081312e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0008205760968849063 -->grad_value: 1.062562660081312e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002087005414068699 -->grad_value: -9.238807251676917e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00032957279472611845 -->grad_value: 6.163762009236962e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0017458060756325722 -->grad_value: 0.00041431491263210773 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003827202133834362 -->grad_value: 0.00041431491263210773 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 3.217475750716403e-05 -->grad_value: -1.922380761243403e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0007791806128807366 -->grad_value: -7.334980182349682e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015923742903396487 -->grad_value: -7.334980182349682e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001118481857702136 -->grad_value: -0.28939998149871826 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006008874624967575 -->grad_value: -24.499645233154297 

INFO:root:
 ** Round 7 : Batch size = 24 , avg loss = 0.012145908902008765

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000626507680863142 -->grad_value: 0.007735333871096373 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.725101699586958e-05 -->grad_value: 1.1974294977790123e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007793098920956254 -->grad_value: 1.2321970643824898e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015243516536429524 -->grad_value: 1.2321970643824898e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0015937513671815395 -->grad_value: -0.007785793859511614 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001532608876004815 -->grad_value: -4.003542528607795e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0027250489220023155 -->grad_value: -5.969532139715739e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0008250480750575662 -->grad_value: -5.969532139715739e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002079292171401903 -->grad_value: -6.792888598283753e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295752976555377 -->grad_value: 6.191628926899284e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0017460008384659886 -->grad_value: 0.0004539960063993931 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0038273967802524567 -->grad_value: 0.0004539960063993931 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 3.332157211843878e-05 -->grad_value: 2.3694592528045177e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0007793229888193309 -->grad_value: -0.00014526676386594772 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.001592516666278243 -->grad_value: -0.00014526676386594772 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185023467987776 -->grad_value: -0.32533055543899536 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009227596223354 -->grad_value: -28.684524536132812 

INFO:root:
 ** Round 8 : Batch size = 25 , avg loss = 0.010998873859061859

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000616947072558105 -->grad_value: -0.0008965195738710463 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.641055657994002e-05 -->grad_value: 8.213160818115739e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007755919359624386 -->grad_value: -2.330337792955106e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015280696097761393 -->grad_value: -2.330337792955106e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0015912416856735945 -->grad_value: -0.0014464894775301218 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00015296840865630656 -->grad_value: -1.7892489267978817e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0027205459773540497 -->grad_value: 1.0251544608763652e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0008295511943288147 -->grad_value: 1.0251544608763652e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00020826069521717727 -->grad_value: 1.2493019312387332e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -5.369777227315353e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0017460105009377003 -->grad_value: -0.0001251257781405002 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.0001251257781405002 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 3.930479579139501e-05 -->grad_value: 2.222623152192682e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -3.5030796425417066e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925237676128745 -->grad_value: -3.5030796425417066e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.02319398894906044 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -2.8048741817474365 

INFO:root:
 ** Round 9 : Batch size = 25 , avg loss = 0.014925555898807943

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006206220714375377 -->grad_value: 0.001094544306397438 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.578639583196491e-05 -->grad_value: -1.2897155343694067e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.000786436372436583 -->grad_value: -2.890402356570121e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015172247076407075 -->grad_value: -2.890402356570121e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0015972459223121405 -->grad_value: -0.0010114827891811728 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00015424707089550793 -->grad_value: -5.790928625515335e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002701657358556986 -->grad_value: 2.784018533930066e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0008484395802952349 -->grad_value: 2.784018533930066e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021048664348199964 -->grad_value: 3.065915734623559e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -1.0842218216566835e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00025896253646351397 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00025896253646351397 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.512139614438638e-05 -->grad_value: 3.712701072799973e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -0.00017049943562597036 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -0.00017049943562597036 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.056346770375967026 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -6.531365871429443 

INFO:root:
 ** Round 10 : Batch size = 24 , avg loss = 0.013034858471655753

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006200810894370079 -->grad_value: 0.41537290811538696 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.586443775333464e-05 -->grad_value: 9.19637983542998e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007887582760304213 -->grad_value: 8.938613609643653e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015149025712162256 -->grad_value: 8.938613609643653e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016098319320008159 -->grad_value: -0.00863547995686531 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00015532245743088424 -->grad_value: -8.21538534978572e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002685101702809334 -->grad_value: -5.989979854348348e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0008649956434965134 -->grad_value: -5.989979854348348e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021086950437165797 -->grad_value: 6.020933597028488e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -2.0123770809732378e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00047899651690386236 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00047899651690386236 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.9981452068313956e-05 -->grad_value: -5.430374585557729e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: 0.0002309170668013394 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: 0.0002309170668013394 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.058020394295454025 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -7.3226189613342285 

INFO:root:
 ** Round 11 : Batch size = 25 , avg loss = 0.009871038743294775

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006281954701989889 -->grad_value: 0.41544631123542786 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.623695950722322e-05 -->grad_value: 8.599117506946641e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008078352548182011 -->grad_value: 8.995413372758776e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0014958257088437676 -->grad_value: 8.995413372758776e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001654469408094883 -->grad_value: -0.007544026244431734 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001606689183972776 -->grad_value: -6.284682285695453e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0025943745858967304 -->grad_value: 1.5441800087501178e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0009557227604091167 -->grad_value: 1.5441800087501178e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021100632147863507 -->grad_value: 7.860372534196358e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -2.531769041524967e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.0005467787268571556 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.0005467787268571556 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.944151780568063e-05 -->grad_value: 1.9535509636625648e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: 0.00014572800137102604 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: 0.00014572800137102604 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.07869191467761993 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -9.608154296875 

INFO:root:
 ** Round 12 : Batch size = 24 , avg loss = 0.012752490406758929

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000622033083345741 -->grad_value: 0.0001752368116285652 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.684725955594331e-05 -->grad_value: -1.2933924153912812e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008167516207322478 -->grad_value: 6.598519917133672e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0014869089936837554 -->grad_value: 6.598519917133672e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016576185589656234 -->grad_value: -0.01124570518732071 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016284918820019811 -->grad_value: -8.929930572776357e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002549472264945507 -->grad_value: 5.574454462475842e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010006254306063056 -->grad_value: 5.574454462475842e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021204215590842068 -->grad_value: 1.285969801756437e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -1.4797976746194763e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.0001593185297679156 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.0001593185297679156 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.0891521570738405e-05 -->grad_value: 2.49202912527835e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -9.91248816717416e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -9.91248816717416e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.030369868502020836 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -3.153991460800171 

INFO:root:
 ** Round 13 : Batch size = 24 , avg loss = 0.014452495245980876

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006123501225374639 -->grad_value: -0.0013479706831276417 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.81760022114031e-05 -->grad_value: -1.9117507576993376e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008200248703360558 -->grad_value: -2.6253956093569286e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0014836357440799475 -->grad_value: -2.6253956093569286e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016573074972257018 -->grad_value: -0.010933531448245049 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016437075100839138 -->grad_value: -5.996541574404546e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002502844436094165 -->grad_value: 7.746239134576172e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010472526773810387 -->grad_value: 7.746239134576172e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021370593458414078 -->grad_value: 3.935209861083422e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -2.0292809495003894e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.0003280168166384101 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.0003280168166384101 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.424518505809829e-05 -->grad_value: 3.859728167299181e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -0.00023795070592314005 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -0.00023795070592314005 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.05920586735010147 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -6.867321491241455 

INFO:root:
 ** Round 14 : Batch size = 23 , avg loss = 0.012731760285374627

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006049273069947958 -->grad_value: -0.0005589096690528095 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.851178037934005e-05 -->grad_value: -6.287029918894405e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.000818140571936965 -->grad_value: -2.4405642307101516e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0014855203917250037 -->grad_value: -2.4405642307101516e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016620506066828966 -->grad_value: 0.0011955590452998877 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016476557357236743 -->grad_value: 1.756982292988596e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002488161902874708 -->grad_value: 2.1628686681651743e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.001061934744939208 -->grad_value: 2.1628686681651743e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021347840083763003 -->grad_value: 1.7764918993634637e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -5.539536687138025e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00010442225902806967 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00010442225902806967 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.430565554182976e-05 -->grad_value: 2.6647121558198705e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -7.775926496833563e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -7.775926496833563e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.027049114927649498 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -3.2446258068084717 

INFO:root:
 ** Round 15 : Batch size = 25 , avg loss = 0.013645989855285734

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005925814621150494 -->grad_value: -0.0025957864709198475 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.867738117463887e-05 -->grad_value: -8.175138788146796e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0008058114908635616 -->grad_value: -4.357054876891198e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0014978490071371198 -->grad_value: -4.357054876891198e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016625444404780865 -->grad_value: 0.001437665894627571 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001644105650484562 -->grad_value: 4.236561323978094e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002496920060366392 -->grad_value: 2.7059973035648e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.001053176703862846 -->grad_value: 2.7059973035648e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021135085262358189 -->grad_value: 3.691308847919572e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -1.1782212823163718e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.000249779608566314 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.000249779608566314 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.0089281760156155e-05 -->grad_value: 5.20088906341698e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -0.0001258833217434585 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -0.0001258833217434585 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.066512830555439 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -7.241603374481201 

INFO:root:
 ** Round 16 : Batch size = 25 , avg loss = 0.015535896408837289

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005764018860645592 -->grad_value: -0.00016619072994217277 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.831832721829414e-05 -->grad_value: 5.756751164653906e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.000792914885096252 -->grad_value: -1.184500888484763e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015107457293197513 -->grad_value: -1.184500888484763e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016646492294967175 -->grad_value: -0.0007364574121311307 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016481077182106674 -->grad_value: 2.194296300217502e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0024936660192906857 -->grad_value: 8.245274329965468e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010564308613538742 -->grad_value: 8.245274329965468e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002101863210555166 -->grad_value: 1.3704629964195192e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -5.369475957195391e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.0001537665375508368 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.0001537665375508368 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.486072041094303e-05 -->grad_value: 3.0000373953953385e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -9.097286965698004e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -9.097286965698004e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.03361931070685387 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -4.042724609375 

INFO:root:
 ** Round 17 : Batch size = 25 , avg loss = 0.011846641870215535

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005383288953453302 -->grad_value: -0.003639018628746271 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.747917647473514e-05 -->grad_value: 3.187212271882345e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007702272851020098 -->grad_value: -6.044462679710705e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015334332128986716 -->grad_value: -6.044462679710705e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001661169808357954 -->grad_value: 0.0003772911732085049 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016473321011289954 -->grad_value: -6.705924704419886e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0024865109007805586 -->grad_value: 2.524139290471794e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010635857470333576 -->grad_value: 2.524139290471794e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021155347349122167 -->grad_value: 3.0563287509721704e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -1.0536691661400255e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00026570932823233306 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00026570932823233306 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.425008566817269e-05 -->grad_value: 5.371122824726626e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -0.00016367551870644093 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -0.00016367551870644093 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.06068781390786171 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -6.964977741241455 

INFO:root:
 ** Round 18 : Batch size = 25 , avg loss = 0.015046168800909072

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005204832414165139 -->grad_value: -0.008242502808570862 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.728164877742529e-05 -->grad_value: 3.2656927828611515e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007569952867925167 -->grad_value: -5.28884629602544e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015466654440388083 -->grad_value: -5.28884629602544e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016590077430009842 -->grad_value: -0.0033503787126392126 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001648769248276949 -->grad_value: 1.9883081847638095e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0024833043571561575 -->grad_value: -2.1505329641513526e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010667922906577587 -->grad_value: -2.1505329641513526e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021196581656113267 -->grad_value: 2.532574399083387e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -9.422036555406521e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00019926831009797752 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00019926831009797752 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.402563692769036e-05 -->grad_value: 2.572051016613841e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -3.364047734066844e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -3.364047734066844e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.03954324871301651 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -4.420478343963623 

INFO:root:
 ** Round 19 : Batch size = 25 , avg loss = 0.00778023743070662

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005190419033169746 -->grad_value: -0.0093430420383811 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.735775529406965e-05 -->grad_value: 3.808269255500818e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007516155019402504 -->grad_value: -7.852233466110192e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015520455781370401 -->grad_value: -7.852233466110192e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016532146837562323 -->grad_value: -0.003662579460069537 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016518693882972002 -->grad_value: 1.1717402159661106e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002480544615536928 -->grad_value: -1.5331333997892216e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.001069552032276988 -->grad_value: -1.5331333997892216e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021165587531868368 -->grad_value: 4.282366262486903e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -1.057700046658283e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.0002728893596213311 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.0002728893596213311 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.337798211257905e-05 -->grad_value: 3.7484642234630883e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -8.805195102468133e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -8.805195102468133e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.05525634437799454 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -6.235072612762451 

INFO:root:
 ** Round 20 : Batch size = 23 , avg loss = 0.01089950184509887

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005178698338568211 -->grad_value: -0.0002715438895393163 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.745942952577025e-05 -->grad_value: -4.218091476104746e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007536322809755802 -->grad_value: -1.5519271983066574e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015500289155170321 -->grad_value: -1.5519271983066574e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016504590166732669 -->grad_value: 0.001983966678380966 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001653666258789599 -->grad_value: -1.2779207914093149e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.00247338879853487 -->grad_value: 2.028984681601287e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010767079656943679 -->grad_value: 2.028984681601287e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002116701944032684 -->grad_value: 1.278285708394833e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -3.907867949237698e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -9.537783626001328e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -9.537783626001328e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.4387914133258164e-05 -->grad_value: 5.36159859620966e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -1.942864037118852e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -1.942864037118852e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.025824610143899918 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -2.7668609619140625 

INFO:root:
 ** Round 21 : Batch size = 25 , avg loss = 0.010376724780071527

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005143893067725003 -->grad_value: -0.00291234627366066 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.735776984598488e-05 -->grad_value: -1.1016020806664528e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007598665542900562 -->grad_value: -5.178688752494054e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015437949914485216 -->grad_value: -5.178688752494054e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001658300287090242 -->grad_value: 0.0022143227979540825 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016582617536187172 -->grad_value: -2.0900447594840443e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002456855960190296 -->grad_value: 3.7274164697009837e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010932408040389419 -->grad_value: 3.7274164697009837e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021216239838395268 -->grad_value: 2.254173978144536e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -8.013726073841099e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00019204142154194415 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00019204142154194415 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.744330701418221e-05 -->grad_value: 2.406755811534822e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -6.744085112586617e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -6.744085112586617e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.04802607372403145 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -5.517902851104736 

INFO:root:
 ** Round 22 : Batch size = 24 , avg loss = 0.011602467430445055

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005147655610926449 -->grad_value: 0.0007817714940756559 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.712186147226021e-05 -->grad_value: -1.230048241041004e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007616155780851841 -->grad_value: -6.15293572536757e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015420462004840374 -->grad_value: -6.15293572536757e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001659920671954751 -->grad_value: 0.0011640350567176938 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016603384574409574 -->grad_value: 1.993332787719737e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0024518738500773907 -->grad_value: 2.5017013740580296e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0010982226813212037 -->grad_value: 2.5017013740580296e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002123266167473048 -->grad_value: 2.0839440821873723e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -7.05907268638839e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00014247422222979367 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00014247422222979367 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.836554919369519e-05 -->grad_value: 3.942983312299475e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -0.00010132257011719048 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -0.00010132257011719048 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.021412547677755356 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -2.4616572856903076 

INFO:root:
 ** Round 23 : Batch size = 25 , avg loss = 0.009913649312220513

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000517160864546895 -->grad_value: -0.0017246126662939787 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.673541353549808e-05 -->grad_value: -7.630276144254822e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007672728970646858 -->grad_value: -4.310062195145292e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015363885322585702 -->grad_value: -4.310062195145292e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016694983933120966 -->grad_value: 0.0024925745092332363 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016655233048368245 -->grad_value: 4.446651047373962e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002442006953060627 -->grad_value: 4.981326583219925e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011080896947532892 -->grad_value: 4.981326583219925e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021234163432382047 -->grad_value: 3.4699487514444627e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -1.4460874808719382e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.000286116759525612 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.000286116759525612 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.8503515901975334e-05 -->grad_value: 4.346367859398015e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -0.0001720633590593934 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -0.0001720633590593934 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.04582536965608597 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -5.405669212341309 

INFO:root:
 ** Round 24 : Batch size = 25 , avg loss = 0.014478411772288383

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005198474391363561 -->grad_value: -0.0007601157994940877 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.647750994190574e-05 -->grad_value: 2.810701005273586e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007714228704571724 -->grad_value: -1.2912435067846673e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015322384424507618 -->grad_value: -1.2912435067846673e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016726257745176554 -->grad_value: 0.00037787272594869137 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016696353850420564 -->grad_value: 3.0640961767858244e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002439009491354227 -->grad_value: 1.3879599691790645e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011110870400443673 -->grad_value: 1.3879599691790645e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021208965335972607 -->grad_value: 6.080531420593616e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -2.908777787524741e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00011442280083429068 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00011442280083429068 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 5.859672091901302e-05 -->grad_value: 1.433450961485505e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -9.650830179452896e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -9.650830179452896e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.03220756724476814 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -4.033979892730713 

INFO:root:
 ** Round 25 : Batch size = 24 , avg loss = 0.00878311389775869

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005291388370096684 -->grad_value: 0.0006232562009245157 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.598610631655902e-05 -->grad_value: 1.2201725851923584e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007792472606524825 -->grad_value: 8.296706255350728e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015244139358401299 -->grad_value: 8.296706255350728e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016744752647355199 -->grad_value: 0.0005029049934819341 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016715787933208048 -->grad_value: 2.654404518409592e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0024362506810575724 -->grad_value: 1.7084923911170335e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011138457339257002 -->grad_value: 1.7084923911170335e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021188669779803604 -->grad_value: 1.8416999409964774e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003295755013823509 -->grad_value: -4.782241376233287e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001746010733768344 -->grad_value: -0.00017843983368948102 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.00382740655913949 -->grad_value: -0.00017843983368948102 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.000501161906868e-05 -->grad_value: 1.9934977899538353e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000779330322984606 -->grad_value: -0.00012594618601724505 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015925238840281963 -->grad_value: -0.00012594618601724505 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011185042094439268 -->grad_value: -0.050180405378341675 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.006009255535900593 -->grad_value: -6.192665100097656 

INFO:root:
 ** Round 26 : Batch size = 23 , avg loss = 0.05457483638968805

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000532774836756289 -->grad_value: -26180853760.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.57870070124045e-05 -->grad_value: 175878.0 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007828642847016454 -->grad_value: -4737049.5 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001520796911790967 -->grad_value: -4737049.5 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016803124453872442 -->grad_value: -40627676.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00016788439825177193 -->grad_value: 8613.2509765625 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0024264384992420673 -->grad_value: -170459.390625 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011236586142331362 -->grad_value: -170459.390625 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002119582350132987 -->grad_value: 3267204.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003306317375972867 -->grad_value: -1131323.75 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0017527132295072079 -->grad_value: -106867008.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0038341095205396414 -->grad_value: -106867008.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.091943214414641e-05 -->grad_value: -936055.5 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0007840147591196001 -->grad_value: 61680208.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0015972083201631904 -->grad_value: 61680208.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011180731235072017 -->grad_value: -10323005440.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005969801917672157 -->grad_value: -1133229113344.0 

INFO:root:
 ** Round 27 : Batch size = 23 , avg loss = 0.010710535431786886

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005375084583647549 -->grad_value: -26180853760.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.610460256226361e-05 -->grad_value: 175878.0 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007858010940253735 -->grad_value: -4737049.5 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015178602188825607 -->grad_value: -4737049.5 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017063543200492859 -->grad_value: -40627676.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017031977768056095 -->grad_value: 8613.2509765625 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002394414506852627 -->grad_value: -170459.390625 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011556822573766112 -->grad_value: -170459.390625 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002123243029927835 -->grad_value: 3267204.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003376721288077533 -->grad_value: -1131323.75 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0017969826003536582 -->grad_value: -106867008.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0038783785421401262 -->grad_value: -106867008.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.182066863402724e-05 -->grad_value: -936055.5 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008155152900144458 -->grad_value: 61680208.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016287085600197315 -->grad_value: 61680208.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011090731713920832 -->grad_value: -10323005440.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005641018971800804 -->grad_value: -1133229113344.0 

INFO:root:
 ** Round 28 : Batch size = 24 , avg loss = 0.01160788119401938

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000543744710739702 -->grad_value: -0.00028211285825818777 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.612568828742951e-05 -->grad_value: -1.113701575405912e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007885706145316362 -->grad_value: -1.5095955632205005e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015150908147916198 -->grad_value: -1.5095955632205005e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017070162575691938 -->grad_value: 0.00029540061950683594 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017092411871999502 -->grad_value: 1.836403207278181e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023878999054431915 -->grad_value: -1.12833333787421e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011621969752013683 -->grad_value: -1.12833333787421e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021299732907209545 -->grad_value: 3.208827138223569e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003400927525945008 -->grad_value: -1.1363179055479122e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018122366163879633 -->grad_value: -0.00024904977180995047 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003893633373081684 -->grad_value: -0.00024904977180995047 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.382660649251193e-05 -->grad_value: 1.1089705367339775e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008261550101451576 -->grad_value: -5.299097392708063e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016393482219427824 -->grad_value: -5.299097392708063e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011048177257180214 -->grad_value: -0.020450260490179062 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005516460631042719 -->grad_value: -2.115507125854492 

INFO:root:
 ** Round 29 : Batch size = 24 , avg loss = 0.012756732239116294

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000537595187779516 -->grad_value: 0.0019518729532137513 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.575052536092699e-05 -->grad_value: 8.865695733106804e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007855081930756569 -->grad_value: -1.0364065019530244e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015181531198322773 -->grad_value: -1.0364065019530244e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016881481278687716 -->grad_value: 0.00036624964559450746 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017067547014448792 -->grad_value: 1.8184746153337983e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023989921901375055 -->grad_value: -3.499072818158311e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011511046905070543 -->grad_value: -3.499072818158311e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021417453535832465 -->grad_value: 8.095829798548948e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00034029054222628474 -->grad_value: -2.8281983759370632e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018134828424081206 -->grad_value: -0.0005267856176942587 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003894879249855876 -->grad_value: -0.0005267856176942587 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.504169141408056e-05 -->grad_value: 3.1897416192805395e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008270238758996129 -->grad_value: -0.00014545611338689923 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016402171459048986 -->grad_value: -0.00014545611338689923 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011044698767364025 -->grad_value: -0.04239634424448013 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005506286397576332 -->grad_value: -4.2956013679504395 

INFO:root:
 ** Round 30 : Batch size = 25 , avg loss = 0.01146166643826291

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005331885768100619 -->grad_value: -0.0017029540613293648 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.547550143906847e-05 -->grad_value: 5.851988049698775e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007793494733050466 -->grad_value: -3.1302429306379054e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015243117231875658 -->grad_value: -3.1302429306379054e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016890214756131172 -->grad_value: -0.0025152009911835194 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017101733828894794 -->grad_value: 2.840464041753421e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023925057612359524 -->grad_value: -2.7466521714814007e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011575911194086075 -->grad_value: -2.7466521714814007e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021445882157422602 -->grad_value: 4.39005179941887e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403051814530045 -->grad_value: -1.1566502280402347e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018135744612663984 -->grad_value: -0.00023774198780301958 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003894970752298832 -->grad_value: -0.00023774198780301958 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.515601126011461e-05 -->grad_value: 1.4471997928922065e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008270879625342786 -->grad_value: -6.192357977852225e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016402812907472253 -->grad_value: -6.192357977852225e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001104443916119635 -->grad_value: -0.020221814513206482 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005505532491952181 -->grad_value: -2.0817346572875977 

INFO:root:
 ** Round 31 : Batch size = 25 , avg loss = 0.04816372666973621

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005294900620356202 -->grad_value: 101196.2734375 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.495839185547084e-05 -->grad_value: 4.666705422096129e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007725798059254885 -->grad_value: 24.057832717895508 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015310810413211584 -->grad_value: 24.057832717895508 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016951062716543674 -->grad_value: -19680776192.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001714122190605849 -->grad_value: 3.964031947134572e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002381707541644573 -->grad_value: -4678797.5 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.001168389804661274 -->grad_value: -4678797.5 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002145249309251085 -->grad_value: 725033.9375 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00034030628739856184 -->grad_value: -2.1642265437549213e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018136721337214112 -->grad_value: 54201648.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0038950685411691666 -->grad_value: 54201648.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.499017035821453e-05 -->grad_value: 1283164.5 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008301168563775718 -->grad_value: 95926048.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.001643310533836484 -->grad_value: 95926048.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011043255217373371 -->grad_value: -4518035968.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.0054850392043590546 -->grad_value: -1147299168256.0 

INFO:root:
 ** Round 32 : Batch size = 25 , avg loss = 0.01296384923160076

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000527484284248203 -->grad_value: -0.0023522102274000645 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.480307198828086e-05 -->grad_value: -2.2872368887760786e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007696637185290456 -->grad_value: -3.2164580261451192e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015339977107942104 -->grad_value: -3.2164580261451192e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0016992767341434956 -->grad_value: 0.0041661676950752735 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017175434913951904 -->grad_value: 2.6048228463082523e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002373370109125972 -->grad_value: 5.5491300372523256e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011767266551032662 -->grad_value: 5.5491300372523256e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021446964819915593 -->grad_value: 4.187700142210815e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.793665433069691e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018138918094336987 -->grad_value: -0.00027397327357903123 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0038952885661274195 -->grad_value: -0.00027397327357903123 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.484547338914126e-05 -->grad_value: 1.8620658011059277e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008370434516109526 -->grad_value: -0.00010529864812269807 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016502372454851866 -->grad_value: -0.00010529864812269807 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00110406125895679 -->grad_value: -0.025623062625527382 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.00543678505346179 -->grad_value: -2.498664617538452 

INFO:root:
 ** Round 33 : Batch size = 25 , avg loss = 0.009151363205164671

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000524037575814873 -->grad_value: -0.004028861410915852 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.474824037170038e-05 -->grad_value: 2.5667130643114433e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007659472757950425 -->grad_value: -4.8479232646059245e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015377140371128917 -->grad_value: -4.8479232646059245e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017006427515298128 -->grad_value: 0.0005509084439836442 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017216353444382548 -->grad_value: 3.832147754678772e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002363106468692422 -->grad_value: 4.606734364642762e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011869902955368161 -->grad_value: 4.606734364642762e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021450201165862381 -->grad_value: 7.411044862237759e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -2.5575177460268606e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139081075787544 -->grad_value: -0.0004374071431811899 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0038953041657805443 -->grad_value: -0.0004374071431811899 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.466372724389657e-05 -->grad_value: 3.374432708369568e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375515462830663 -->grad_value: -0.00017464507254771888 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507459804415703 -->grad_value: -0.00017464507254771888 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040425160899758 -->grad_value: -0.03916854411363602 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005433240905404091 -->grad_value: -4.00632905960083 

INFO:root:
 ** Round 34 : Batch size = 25 , avg loss = 0.009323772159405053

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005218838341534138 -->grad_value: -0.0008423143881373107 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.469783981330693e-05 -->grad_value: -7.27184423787719e-10 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007638393435627222 -->grad_value: -1.4855606877972605e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001539821969345212 -->grad_value: -1.4855606877972605e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017063077539205551 -->grad_value: -0.0005698747700080276 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017235623090527952 -->grad_value: 1.866365373359713e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023574642837047577 -->grad_value: -1.5780946682752983e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011926325969398022 -->grad_value: -1.5780946682752983e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021543962066061795 -->grad_value: 3.479109864201746e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.0417728617539979e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139098538085818 -->grad_value: -0.00019701388373505324 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305562764406 -->grad_value: -0.00019701388373505324 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.496987771242857e-05 -->grad_value: 2.173986558773322e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375848410651088 -->grad_value: -9.811986819840968e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507797408849 -->grad_value: -9.811986819840968e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001104040420614183 -->grad_value: -0.015116866677999496 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005433008074760437 -->grad_value: -1.6326223611831665 

INFO:root:
 ** Round 35 : Batch size = 24 , avg loss = 0.00912968406434326

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005190508672967553 -->grad_value: -0.0011414280161261559 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.463953756494448e-05 -->grad_value: -2.6213520243345556e-10 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007616363000124693 -->grad_value: -3.6251032042855513e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001542025012895465 -->grad_value: -3.6251032042855513e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017154933884739876 -->grad_value: 0.0009898245334625244 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017237760766875 -->grad_value: 1.8337564355874747e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023533820640295744 -->grad_value: 3.755994839593768e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0011967152822762728 -->grad_value: 3.755994839593768e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021704952814616263 -->grad_value: 6.801914423704147e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -2.0573729671014007e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00036985837505199015 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00036985837505199015 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.545581709360704e-05 -->grad_value: 4.139861630392261e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375871693715453 -->grad_value: -0.0001601667609065771 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.0001601667609065771 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.029262268915772438 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -3.0998435020446777 

INFO:root:
 ** Round 36 : Batch size = 24 , avg loss = 0.052362535359861795

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005174163961783051 -->grad_value: -0.0006499179289676249 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.453523671254516e-05 -->grad_value: -1.1242717867787633e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007601018296554685 -->grad_value: -1.4533306966768578e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015435591340065002 -->grad_value: -1.4533306966768578e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017216987907886505 -->grad_value: -0.00166728172916919 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017233641119673848 -->grad_value: 1.020149209551846e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002349743153899908 -->grad_value: -1.8230263094665133e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012003538431599736 -->grad_value: -1.8230263094665133e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021761507377959788 -->grad_value: 4.1892162698786706e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -9.739396773511544e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.0002372279850533232 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.0002372279850533232 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.541005859617144e-05 -->grad_value: 1.791286649677204e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -8.895958308130503e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -8.895958308130503e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.016767030581831932 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -1.7233763933181763 

INFO:root:
 ** Round 37 : Batch size = 25 , avg loss = 0.011013409954030067

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.000510555284563452 -->grad_value: -0.0007905295351520181 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.462444722885266e-05 -->grad_value: -6.5338126020719756e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007428247481584549 -->grad_value: -2.0227619188517565e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001560836099088192 -->grad_value: -2.0227619188517565e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017235343111678958 -->grad_value: -0.002139194868505001 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001720818690955639 -->grad_value: 4.6926352581522224e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002348269335925579 -->grad_value: -1.6117812720040092e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012018277775496244 -->grad_value: -1.6117812720040092e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002182555035687983 -->grad_value: 7.404749794659438e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.7061557855413412e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.0004548602446448058 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.0004548602446448058 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.567691161762923e-05 -->grad_value: 3.7922300180071034e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.0001781121245585382 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.0001781121245585382 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.03597994148731232 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -3.7513198852539062 

INFO:root:
 ** Round 38 : Batch size = 25 , avg loss = 0.008437444483861327

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005084769800305367 -->grad_value: -4.6618006308563054e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.467893687542528e-05 -->grad_value: -8.230838233203031e-10 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007360801100730896 -->grad_value: -8.041614307785494e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015675801550969481 -->grad_value: -8.041614307785494e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001723483670502901 -->grad_value: -4.0880884625948966e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017217104323208332 -->grad_value: 2.2549384581793674e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023462704848498106 -->grad_value: 5.100905582366977e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012038269778713584 -->grad_value: 5.100905582366977e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021853057842236012 -->grad_value: 3.850021130347159e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -5.37197990979621e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00016310482169501483 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00016310482169501483 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.580048648174852e-05 -->grad_value: 2.469811988703441e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -9.326139115728438e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -9.326139115728438e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.01036971528083086 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -1.3314685821533203 

INFO:root:
 ** Round 39 : Batch size = 25 , avg loss = 0.009939547383692116

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005060626426711679 -->grad_value: -0.0005022180266678333 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.468086500419304e-05 -->grad_value: -2.2050112846727643e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.000735121313482523 -->grad_value: -3.0746600714337546e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015685393009334803 -->grad_value: -3.0746600714337546e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017281717155128717 -->grad_value: -0.0005924823926761746 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017258740263059735 -->grad_value: 2.14389217489952e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023375465534627438 -->grad_value: -9.658140243118396e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012125509092584252 -->grad_value: -9.658140243118396e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002186580386478454 -->grad_value: 7.335862392210402e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.6450643443022273e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.0003857015399262309 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.0003857015399262309 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.548783858306706e-05 -->grad_value: 3.4616468838066794e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.00014665891649201512 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.00014665891649201512 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.028476934880018234 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -3.279278516769409 

INFO:root:
 ** Round 40 : Batch size = 24 , avg loss = 0.008331858759144476

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005046373698860407 -->grad_value: -0.0003209528513252735 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.462308662477881e-05 -->grad_value: 1.1004253508417605e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007338735740631819 -->grad_value: -7.604595566590433e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001569787273183465 -->grad_value: -7.604595566590433e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017299444880336523 -->grad_value: -0.0011634421534836292 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001727415801724419 -->grad_value: 3.15757864299826e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023343295324593782 -->grad_value: -4.798825443685928e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.001215767813846469 -->grad_value: -4.798825443685928e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021869577176403254 -->grad_value: 3.0667636110592866e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -6.398192908818601e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00016847993538249284 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00016847993538249284 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.524242053274065e-05 -->grad_value: 1.714516656647902e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -7.939642819110304e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -7.939642819110304e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.011842790991067886 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -1.3928459882736206 

INFO:root:
 ** Round 41 : Batch size = 24 , avg loss = 0.008082200273444565

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005022748955525458 -->grad_value: -0.000733297667466104 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.461319132242352e-05 -->grad_value: -1.2369997248740106e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007294097449630499 -->grad_value: -1.4166164419293636e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015742509858682752 -->grad_value: -1.4166164419293636e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017299590399488807 -->grad_value: -0.0008373275632038713 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017299049068242311 -->grad_value: 1.0457090304782923e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002332025906071067 -->grad_value: 9.690513707028003e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012180712074041367 -->grad_value: 9.690513707028003e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021866720635443926 -->grad_value: 6.0171514633111656e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.5983646335371304e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00033105339389294386 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00033105339389294386 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.429679342545569e-05 -->grad_value: 2.9608736440422945e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.00011878524674102664 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.00011878524674102664 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.025043319910764694 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -2.738818407058716 

INFO:root:
 ** Round 42 : Batch size = 25 , avg loss = 0.01093866812530905

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005004567210562527 -->grad_value: -0.0005475051584653556 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.463981405133381e-05 -->grad_value: -4.054358626603971e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007272445363923907 -->grad_value: -1.8760707689580158e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001576416427269578 -->grad_value: -1.8760707689580158e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017295903526246548 -->grad_value: -3.0447943572653458e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017307547386735678 -->grad_value: 2.7679117664547448e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023314140271395445 -->grad_value: 7.015802339083166e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.001218683086335659 -->grad_value: 7.015802339083166e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021867136820219457 -->grad_value: 4.696667019743472e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.0437721584821702e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00022379745496436954 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00022379745496436954 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.395942182280123e-05 -->grad_value: 2.732608663791325e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.00010563511750660837 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.00010563511750660837 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.01785772666335106 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -1.957958459854126 

INFO:root:
 ** Round 43 : Batch size = 24 , avg loss = 0.010979963539284654

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0004982720711268485 -->grad_value: -0.0014714645221829414 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.459460125071928e-05 -->grad_value: 5.048867990353756e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007255370728671551 -->grad_value: -3.623746351877344e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015781237743794918 -->grad_value: -3.623746351877344e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017285505309700966 -->grad_value: -0.00034835172118619084 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017313918215222657 -->grad_value: 4.523562324720842e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002330804243683815 -->grad_value: 4.263909545443312e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012192928697913885 -->grad_value: 4.263909545443312e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002186558849643916 -->grad_value: 9.135508662438951e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.952388629433699e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00042241212213411927 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00042241212213411927 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.358119571814314e-05 -->grad_value: 6.990137990214862e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.0002522455179132521 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.0002522455179132521 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.032338470220565796 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -3.6044557094573975 

INFO:root:
 ** Round 44 : Batch size = 25 , avg loss = 0.010805139373987914

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00049934460548684 -->grad_value: -0.0017178487032651901 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.454710379941389e-05 -->grad_value: -4.8124675799954275e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007248863112181425 -->grad_value: -1.9214139683754183e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015787751181051135 -->grad_value: -1.9214139683754183e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017295836005359888 -->grad_value: 0.00018920651928056031 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017315888544544578 -->grad_value: 1.9639568193952073e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002330012619495392 -->grad_value: 1.136550395131053e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012200843775644898 -->grad_value: 1.136550395131053e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021907406335230917 -->grad_value: 4.178643848717911e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.1332256235618843e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.0002162062155548483 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.0002162062155548483 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.387560279108584e-05 -->grad_value: 2.5492545319139026e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -8.677584992256016e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -8.677584992256016e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.017277056351304054 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -1.8407689332962036 

INFO:root:
 ** Round 45 : Batch size = 23 , avg loss = 0.009567118485194995

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005039264797233045 -->grad_value: -0.0013653140049427748 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.464070899412036e-05 -->grad_value: -5.36690976105092e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007275419775396585 -->grad_value: -2.4660587314428994e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015761186368763447 -->grad_value: -2.4660587314428994e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017349505797028542 -->grad_value: 0.0029355809092521667 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017335187294520438 -->grad_value: -5.3434732194546086e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002327453810721636 -->grad_value: 2.634528982525808e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012226436519995332 -->grad_value: 2.634528982525808e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021965961786918342 -->grad_value: 6.96795541443862e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -2.2451342829299392e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.000401550205424428 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.000401550205424428 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.386340101016685e-05 -->grad_value: 4.149023880017921e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.00017026643035933375 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.00017026643035933375 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.03175310790538788 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -3.3473236560821533 

INFO:root:
 ** Round 46 : Batch size = 25 , avg loss = 0.011638497416861356

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005055204965174198 -->grad_value: -0.005337574519217014 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.453717211727053e-05 -->grad_value: 9.079074914097873e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007296826224774122 -->grad_value: -2.2654971871816088e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015739777591079473 -->grad_value: -2.2654971871816088e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017344560474157333 -->grad_value: 0.0006594137521460652 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017341428610961884 -->grad_value: -4.155359434321326e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023282498586922884 -->grad_value: 4.957994974574831e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012218474876135588 -->grad_value: 4.957994974574831e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021988882508594543 -->grad_value: 4.353140411694767e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -9.84354414867994e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00023958986275829375 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00023958986275829375 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.434164970414713e-05 -->grad_value: 3.322027168906061e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.00013471966667566448 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.00013471966667566448 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.018008526414632797 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -1.9632030725479126 

INFO:root:
 ** Round 47 : Batch size = 25 , avg loss = 0.010722798244096339

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005049475003033876 -->grad_value: -0.006993208080530167 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.409680205862969e-05 -->grad_value: 6.183432788020582e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007304608589038253 -->grad_value: -5.569021595874801e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015731998719274998 -->grad_value: -5.569021595874801e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017338455654680729 -->grad_value: 0.0011926343431696296 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017360640049446374 -->grad_value: -3.134591608500159e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023294473066926003 -->grad_value: 2.042789219558472e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012206501560285687 -->grad_value: 2.042789219558472e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00021996692521497607 -->grad_value: 8.032987352635246e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.8824453036359046e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00047514791367575526 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00047514791367575526 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.430783832911402e-05 -->grad_value: 4.949981303070672e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.0001910006394609809 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.0001910006394609809 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.03607805073261261 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -3.8600401878356934 

INFO:root:
 ** Round 48 : Batch size = 25 , avg loss = 0.012177933659404516

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005042249686084688 -->grad_value: -0.0005362075171433389 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.383766155224293e-05 -->grad_value: 8.240421678351595e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.000730069587007165 -->grad_value: -2.2244876163313165e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015735909109935164 -->grad_value: -2.2244876163313165e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001733655808493495 -->grad_value: -0.0025366214103996754 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017380155622959137 -->grad_value: -1.433786867011122e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002329025650396943 -->grad_value: 3.176497500589903e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012210719287395477 -->grad_value: 3.176497500589903e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00022005331993568689 -->grad_value: 4.632679974747589e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -1.6309484180965228e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.00029617169639095664 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.00029617169639095664 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.42472441541031e-05 -->grad_value: 1.7256452338187955e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.00010069715790450573 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.00010069715790450573 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.02010066993534565 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -2.172672986984253 

INFO:root:
 ** Round 49 : Batch size = 24 , avg loss = 0.010941785406127261

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005027423612773418 -->grad_value: -0.0023887946736067533 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.355164365842938e-05 -->grad_value: 3.6566079053557132e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007295799441635609 -->grad_value: -2.912425088652526e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015740804374217987 -->grad_value: -2.912425088652526e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017347268294543028 -->grad_value: -0.002465520752593875 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00017402187222614884 -->grad_value: 5.738831188040194e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0023279583547264338 -->grad_value: 1.29063960230269e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012221389915794134 -->grad_value: 1.29063960230269e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.0002202846808359027 -->grad_value: 9.032634807226714e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -2.8381998617987847e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.0005152857629582286 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.0005152857629582286 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.420164572773501e-05 -->grad_value: 4.592149707605131e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -0.00019906082889065146 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -0.00019906082889065146 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.035939451307058334 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -3.956969976425171 

INFO:root:
 ** Round 50 : Batch size = 24 , avg loss = 0.007749368727672845

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0005019716336391866 -->grad_value: -0.000115379792987369 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 9.348970343125984e-05 -->grad_value: 3.5843479295749603e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007296608528122306 -->grad_value: -6.293107901456096e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0015739996451884508 -->grad_value: -6.293107901456096e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017333384603261948 -->grad_value: -0.0004428534011822194 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0001740048173815012 -->grad_value: 8.962881103968812e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.002329177688807249 -->grad_value: -4.837028200199711e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0012209198903292418 -->grad_value: -4.837028200199711e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00022033380810171366 -->grad_value: 2.956689513666788e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.0003403062582947314 -->grad_value: -4.904658794657735e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0018139092717319727 -->grad_value: -0.0001379941386403516 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003895305097103119 -->grad_value: -0.0001379941386403516 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.420930731110275e-05 -->grad_value: 1.4946317605790682e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.0002368031709920615 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0008375875186175108 -->grad_value: -4.72314131911844e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016507817199453712 -->grad_value: -4.72314131911844e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0011040405370295048 -->grad_value: -0.011533346027135849 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.005432990845292807 -->grad_value: -1.2476638555526733 

