INFO:root:
 ======== Start Log Recording :04-20 11:56 ========

INFO:root:
 Model Initialization = LSTM(300, 128, num_layers=2, dropout=0.2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(300, 128, num_layers=2, dropout=0.2, bidirectional=True)>

INFO:root:Loading models from gensim, name: fasttext-wiki-news-subwords-300 ....

INFO:gensim.models.keyedvectors:loading projection weights from /Users/taotao/gensim-data/fasttext-wiki-news-subwords-300/fasttext-wiki-news-subwords-300.gz
INFO:gensim.utils:KeyedVectors lifecycle event {'msg': 'loaded (999999, 300) matrix of type float32 from /Users/taotao/gensim-data/fasttext-wiki-news-subwords-300/fasttext-wiki-news-subwords-300.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2024-04-20T11:58:19.044713', 'gensim': '4.3.0', 'python': '3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]', 'platform': 'macOS-14.4.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}
INFO:root:** Load Successfully!

INFO:root:--> No.0 --> embedding vectors = 
	tensor([[ 0.0017, -0.0771,  0.0875,  ..., -0.0405, -0.0306, -0.0182],
        [ 0.0011, -0.0914,  0.0349,  ..., -0.0046, -0.0671, -0.0597],
        [-0.0127, -0.0420,  0.0161,  ..., -0.0926,  0.0262,  0.0033],
        ...,
        [-0.0271, -0.0727,  0.0535,  ...,  0.0019,  0.0521,  0.0005],
        [ 0.0778, -0.0871, -0.0458,  ...,  0.0109, -0.0178, -0.0448],
        [ 0.0552, -0.0946,  0.0274,  ..., -0.0082,  0.0793,  0.0230]])

INFO:root:--> No.13 --> embedding vectors = 
	tensor([[-0.0315, -0.1033, -0.0577,  ...,  0.0050,  0.0998, -0.0082],
        [-0.1004, -0.0347,  0.0322,  ...,  0.0457,  0.0285, -0.0344],
        [-0.0269, -0.0237,  0.0534,  ..., -0.0789, -0.0302,  0.0116],
        ...,
        [-0.0244,  0.0203,  0.0220,  ..., -0.0305,  0.0325,  0.0419],
        [ 0.0028, -0.0046, -0.0086,  ..., -0.0003,  0.0047, -0.0261],
        [-0.0223,  0.0216,  0.0849,  ..., -0.0077, -0.0339, -0.0516]])

INFO:root:--> No.26 --> embedding vectors = 
	tensor([[-0.0187, -0.1394,  0.0103,  ...,  0.0449, -0.0326,  0.0564],
        [-0.0386, -0.1065,  0.0536,  ...,  0.0285,  0.0464,  0.0196],
        [-0.0359, -0.0186, -0.0409,  ...,  0.0271,  0.0133, -0.0091],
        ...,
        [ 0.0065,  0.0095,  0.0278,  ..., -0.0240,  0.0039,  0.0093],
        [-0.0042, -0.0501,  0.0164,  ..., -0.0044, -0.0352,  0.0134],
        [ 0.0004,  0.0496, -0.0157,  ..., -0.0401, -0.0656, -0.0159]])

INFO:root:--> No.39 --> embedding vectors = 
	tensor([[ 0.0793, -0.0652, -0.0460,  ..., -0.0052, -0.0207,  0.0485],
        [ 0.0665, -0.0463, -0.0009,  ..., -0.0188, -0.0474, -0.0100],
        [ 0.0251,  0.0798,  0.0153,  ..., -0.0274,  0.0626, -0.0019],
        ...,
        [ 0.0157, -0.0433, -0.0017,  ..., -0.0238, -0.0472, -0.0309],
        [-0.0388,  0.0134,  0.0613,  ...,  0.0011,  0.0458, -0.0213],
        [-0.0383,  0.0162,  0.0714,  ..., -0.0513,  0.0315,  0.0436]])

INFO:root:--> No.52 --> embedding vectors = 
	tensor([[ 0.0065,  0.0095,  0.0278,  ..., -0.0240,  0.0039,  0.0093],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0198, -0.0170, -0.0720,  ...,  0.0255,  0.0047, -0.0128],
        ...,
        [ 0.0053,  0.0746, -0.0032,  ..., -0.0605, -0.0280,  0.0314],
        [-0.0314,  0.0707,  0.0034,  ...,  0.0129, -0.0208, -0.0307],
        [ 0.0576,  0.0008,  0.0652,  ...,  0.1043, -0.0573, -0.0109]])

INFO:root:*** 	 batch model = True 
