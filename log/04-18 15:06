INFO:root:
 ======== Start Log Recording :04-18 15:06 ========

INFO:root:
 Model Initialization = LSTM(8, 256, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 256, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 18 , Accurary = 61.111111111111114%

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0011310577392578 -->grad_value: 0.0006304645212367177 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.001458961283788085 -->grad_value: 0.003013869747519493 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 4.452910798136145e-05 -->grad_value: 4.70559189125197e-06 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -2.3225678887683898e-05 -->grad_value: -2.2431938972999887e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.004989388398826122 -->grad_value: -3.6335350159788504e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.004409324377775192 -->grad_value: -3.6335350159788504e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.00015494060062337667 -->grad_value: 4.205906407150906e-06 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -1.5236902981996536e-05 -->grad_value: -2.5022961480658523e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.007281052879989147 -->grad_value: 1.1629295840975828e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0002543481532484293 -->grad_value: 1.1629295840975828e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 5.2117384257144295e-06 -->grad_value: -2.3930186721088376e-09 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 2.380356818321161e-05 -->grad_value: 1.6344280595603777e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.005612725391983986 -->grad_value: -5.851597961736843e-07 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.004716184921562672 -->grad_value: -5.851597961736843e-07 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.600214874197263e-06 -->grad_value: -6.553099396455764e-09 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.1143528253305703e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0016844561323523521 -->grad_value: -8.949575203587301e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0017792554572224617 -->grad_value: -8.949575203587301e-06 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -1.540972152724862e-05 -->grad_value: -4.257248292560689e-06 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.001485392451286316 -->grad_value: 0.004992705769836903 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.0018415778176859021 -->grad_value: 0.008251549676060677 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.059440936893224716 -->grad_value: 0.21634899079799652 

INFO:root:
 ** Round 1 : Batch size = 20 , Accurary = 35.0%

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9983583688735962 -->grad_value: 0.001086581265553832 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.015085795894265175 -->grad_value: -0.0006177028408274055 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0015445065218955278 -->grad_value: 2.3432516172761098e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00015466584591194987 -->grad_value: 8.130112405524414e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.013476847670972347 -->grad_value: 7.41960175218992e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.012896783649921417 -->grad_value: 7.41960175218992e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.002418023534119129 -->grad_value: 5.195746780373156e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0001426259841537103 -->grad_value: -1.751028477769978e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.015378199517726898 -->grad_value: 3.366671080584638e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.008351493626832962 -->grad_value: 3.366671080584638e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00010370623203925788 -->grad_value: 1.556644519951078e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 3.1377079722005874e-05 -->grad_value: -2.177073099574045e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.015872396528720856 -->grad_value: 0.0001105214687413536 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.014975856058299541 -->grad_value: 0.0001105214687413536 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.982984394999221e-05 -->grad_value: 1.723066134218243e-11 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.1143528253305703e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.006818799301981926 -->grad_value: -1.4237927643989678e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.006913598161190748 -->grad_value: -1.4237927643989678e-05 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 1.4964258298277855e-05 -->grad_value: -7.492842541978462e-06 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.008600222878158092 -->grad_value: 0.006228071637451649 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.001761648803949356 -->grad_value: -0.0009636128670535982 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.05320844426751137 -->grad_value: 0.4266985058784485 

