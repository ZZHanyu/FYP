INFO:root:
 ======== Start Log Recording :04-17 11:04 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 0.7209313388751901

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0005768554983660579 -->grad_value: 8.088851609500125e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.000299958570394665 -->grad_value: -3.0345892465533097e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0006504924967885017 -->grad_value: -4.652239482538789e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0031984192319214344 -->grad_value: -4.652239482538789e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0002577951527200639 -->grad_value: -5.060359853814589e-06 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00026217621052637696 -->grad_value: -1.1458426568689006e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.002282150788232684 -->grad_value: -6.798940077601401e-09 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0027295267209410667 -->grad_value: -6.798940077601401e-09 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00011363967496436089 -->grad_value: -3.209562419215217e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0002726385719142854 -->grad_value: 1.0829700840986334e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0009838106343522668 -->grad_value: -0.00042684702202677727 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0002971894573420286 -->grad_value: -0.00042684702202677727 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00023180191055871546 -->grad_value: -2.6948614504362922e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0009384761797264218 -->grad_value: -2.5599596483516507e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.004172338638454676 -->grad_value: -2.5599596483516507e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0005557758267968893 -->grad_value: 0.003226405708119273 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.010044327937066555 -->grad_value: -0.3431187868118286 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.7480922676622868

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0006071922834962606 -->grad_value: 0.003587151877582073 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0002985066967085004 -->grad_value: 8.228335701687683e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0006156819872558117 -->grad_value: 1.4262036529544275e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0032332297414541245 -->grad_value: 1.4262036529544275e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0002099342382280156 -->grad_value: 0.0012095854617655277 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0002609985531307757 -->grad_value: 1.701203067305812e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.002350226975977421 -->grad_value: 5.545632120629307e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026614503003656864 -->grad_value: 5.545632120629307e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00014475203352048993 -->grad_value: 1.5897213643256691e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.000358087127096951 -->grad_value: -1.8616212855704362e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.00018935539992526174 -->grad_value: 8.013969636522233e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0014703556662425399 -->grad_value: 8.013969636522233e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00026251154486089945 -->grad_value: -2.434503358017537e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0014170794747769833 -->grad_value: -0.00013072915317025036 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.004650941584259272 -->grad_value: -0.00013072915317025036 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00038379256147891283 -->grad_value: -0.004104529973119497 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.006193831562995911 -->grad_value: 0.4955499470233917 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.707412897348404

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0005764273810200393 -->grad_value: 0.0007542918319813907 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.000282768887700513 -->grad_value: 2.1178725262416265e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007466021925210953 -->grad_value: 2.124651700796676e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.003102309536188841 -->grad_value: 2.124651700796676e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0002972109359689057 -->grad_value: 1.0919539818132762e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0002637806464917958 -->grad_value: 2.1808463368522268e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0024774109479039907 -->grad_value: 4.539406717185557e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.00253426656126976 -->grad_value: 4.539406717185557e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00022377172717824578 -->grad_value: -3.45695343639818e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00042098687845282257 -->grad_value: 6.948617397029011e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0008712926646694541 -->grad_value: -5.81249114475213e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.002152292290702462 -->grad_value: -5.81249114475213e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0003448601346462965 -->grad_value: 1.5353978596976958e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0015920065343379974 -->grad_value: 0.0002494990185368806 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0048258681781589985 -->grad_value: 0.0002494990185368806 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0002488249447196722 -->grad_value: -2.7591479010879993e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.005597463808953762 -->grad_value: -0.562450647354126 

INFO:root:
 ** Round 3 : Batch size = 25 , avg loss = 0.6824989628791809

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0005499365506693721 -->grad_value: -0.00011507226008689031 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00027418069657869637 -->grad_value: -1.726128928680737e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007435237057507038 -->grad_value: -2.159360406039923e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.003105387557297945 -->grad_value: -2.159360406039923e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00038131471956148744 -->grad_value: 0.00019949466513935477 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.000264777714619413 -->grad_value: -1.3548365762616754e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0025320330169051886 -->grad_value: 3.34970962967418e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0024796451907604933 -->grad_value: 3.34970962967418e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00024067766207735986 -->grad_value: -3.0550133942597313e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004437898169271648 -->grad_value: 7.161631287999626e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0010981556260958314 -->grad_value: -8.397026977036148e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.002379156183451414 -->grad_value: -8.397026977036148e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.000338571349857375 -->grad_value: 7.017863481451059e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.001445277826860547 -->grad_value: 0.00019989516295026988 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.004679139703512192 -->grad_value: 0.00019989516295026988 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0002059037797152996 -->grad_value: 0.0018543945625424385 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.006161347962915897 -->grad_value: -0.5375202298164368 

INFO:root:
 ** Round 4 : Batch size = 24 , avg loss = 0.699500617881616

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0006045891204848886 -->grad_value: 0.00029900987283326685 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00028551192372106016 -->grad_value: 7.31259106601101e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0006171698914840817 -->grad_value: 7.141061360016465e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0032317410223186016 -->grad_value: 7.141061360016465e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.000302635133266449 -->grad_value: 0.00015263438399415463 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0002671124238986522 -->grad_value: -4.022312261042771e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.00243416172452271 -->grad_value: 4.2133896727136744e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0025775153189897537 -->grad_value: 4.2133896727136744e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001917405752465129 -->grad_value: 1.9111936126137152e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00043045642087236047 -->grad_value: -1.8639537984199706e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0008441703394055367 -->grad_value: 0.000512640574015677 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.002125171246007085 -->grad_value: 0.000512640574015677 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.000372354406863451 -->grad_value: -3.3902376799233025e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0021925270557403564 -->grad_value: -9.721936658024788e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0054263886995613575 -->grad_value: -9.721936658024788e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00010270602069795132 -->grad_value: 0.000297407153993845 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0100707383826375 -->grad_value: 0.5702032446861267 

INFO:root:
 ** Round 5 : Batch size = 25 , avg loss = 0.6741735577583313

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0004908856353722513 -->grad_value: -1.7158156140339997e-07 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0002723991055972874 -->grad_value: -2.651658337349261e-10 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007367880316451192 -->grad_value: -2.657520647986189e-09 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0031121233478188515 -->grad_value: -2.657520647986189e-09 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00026004062965512276 -->grad_value: -0.0009148179087787867 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00027494048117659986 -->grad_value: -8.005958396228863e-11 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.002419792814180255 -->grad_value: -4.019235007035604e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002591884694993496 -->grad_value: -4.019235007035604e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00017498341912869364 -->grad_value: -1.0868876415770501e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004123420803807676 -->grad_value: 1.2234438599989517e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.00178339215926826 -->grad_value: -0.00023104266438167542 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0030643921345472336 -->grad_value: -0.00023104266438167542 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0003554379800334573 -->grad_value: -7.12529981683474e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.002349979244172573 -->grad_value: -1.545572013128549e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0055838413536548615 -->grad_value: -1.545572013128549e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00018023711163550615 -->grad_value: 0.0003113558632321656 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.007681018207222223 -->grad_value: -0.4268891215324402 

INFO:root:
 ** Round 6 : Batch size = 24 , avg loss = 0.6642360091209412

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.00048586545744910836 -->grad_value: -1.0584190931695048e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00026906724087893963 -->grad_value: -9.94307480794987e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0007248340407386422 -->grad_value: -1.0664111727010095e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0031240773387253284 -->grad_value: -1.0664111727010095e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00023036199854686856 -->grad_value: 4.9267313443124294e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0002770409337244928 -->grad_value: 2.6609897618712353e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0023549413308501244 -->grad_value: 7.327246009936061e-08 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0026567354798316956 -->grad_value: 7.327246009936061e-08 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00015427474863827229 -->grad_value: -1.130046985053923e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00040727705345489085 -->grad_value: 7.924206784082344e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001903622061945498 -->grad_value: -0.00023155267990659922 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.003184623084962368 -->grad_value: -0.00023155267990659922 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0003144586517009884 -->grad_value: -4.4809075916418806e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0018545438069850206 -->grad_value: -8.963380241766572e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.005088405217975378 -->grad_value: -8.963380241766572e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00029268290381878614 -->grad_value: 0.0005399241927079856 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.006464794278144836 -->grad_value: -0.39608246088027954 

INFO:root:
 ** Round 7 : Batch size = 24 , avg loss = 0.6406990786393484

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0005269684479571879 -->grad_value: 0.000444541044998914 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00027664389926940203 -->grad_value: 7.864974094218269e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.000590460142120719 -->grad_value: 7.660040068913077e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0032584506552666426 -->grad_value: 7.660040068913077e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00012834853259846568 -->grad_value: 0.00037589529529213905 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0002740178315434605 -->grad_value: -1.407127525610008e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0022524730302393436 -->grad_value: 9.162670266960049e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002759204711765051 -->grad_value: 9.162670266960049e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00013830159150529653 -->grad_value: 5.893214165553218e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003937747678719461 -->grad_value: -6.597318247258954e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001444163965061307 -->grad_value: 0.00014418482896871865 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.002725165104493499 -->grad_value: 0.00014418482896871865 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0002833238977473229 -->grad_value: -5.962360773992259e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0011477090884000063 -->grad_value: -0.00017635819676797837 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.004381571896374226 -->grad_value: -0.00017635819676797837 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.00044494355097413063 -->grad_value: -0.00027468829648569226 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.006336781661957502 -->grad_value: 0.462359756231308 

INFO:root:
 ** Round 8 : Batch size = 25 , avg loss = 0.7302646172046662

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0005504107102751732 -->grad_value: -0.00035788078093901277 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00028340527205727994 -->grad_value: -9.332396899708328e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0004996903007850051 -->grad_value: -1.024284301820444e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.003349220845848322 -->grad_value: -1.024284301820444e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -8.437350334133953e-05 -->grad_value: -0.00014168307825457305 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00027448293985798955 -->grad_value: -1.7271836738608215e-11 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0022405062336474657 -->grad_value: -3.9625433601031546e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002771170809864998 -->grad_value: -3.9625433601031546e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00013835971185471863 -->grad_value: -9.696350389276631e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004036528698634356 -->grad_value: 8.522532652932568e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.001617607893422246 -->grad_value: -0.00025122766965068877 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.002898608800023794 -->grad_value: -0.00025122766965068877 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0003298620868008584 -->grad_value: 1.7341076272714417e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -5.510472692549229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.001671676291152835 -->grad_value: 4.683341830968857e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0049055395647883415 -->grad_value: 4.683341830968857e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0003375621745362878 -->grad_value: -2.9665417969226837e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.007206498179584742 -->grad_value: -0.4601636528968811 

