INFO:root:
 ======== Start Log Recording :04-16 14:30 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 18 , avg loss = 0.012053794502410002

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0006934667471796274 -->grad_value: -0.004727729596197605 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001262728765141219 -->grad_value: -1.1094377860842997e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021973121911287308 -->grad_value: -6.866274361527758e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001979876309633255 -->grad_value: -6.866274361527758e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011576168471947312 -->grad_value: 0.0010742717422544956 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -9.231351577909663e-05 -->grad_value: -4.258692598568814e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003716428764164448 -->grad_value: 1.8153295968659222e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0019916738383471966 -->grad_value: 1.8153295968659222e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002031872427323833 -->grad_value: 2.5446888685110025e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001865700469352305 -->grad_value: 3.595050657168031e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032629964407533407 -->grad_value: -6.26222463324666e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024165562354028225 -->grad_value: -6.26222463324666e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.4115877244621515e-05 -->grad_value: 1.8515447663958184e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0033490636851638556 -->grad_value: -1.3102908269502223e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0020103706046938896 -->grad_value: -1.3102908269502223e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001543483231216669 -->grad_value: -0.0012686369009315968 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00286122877150774 -->grad_value: -1.8242722749710083 

INFO:root:
 ** Round 1 : Batch size = 20 , avg loss = 0.008866839506663383

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007077178452163935 -->grad_value: -0.005020336713641882 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631282152142376 -->grad_value: 3.790111335888469e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002185183111578226 -->grad_value: -6.740491699019913e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019920056220144033 -->grad_value: -6.740491699019913e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011672698892652988 -->grad_value: 0.0007846985827200115 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -9.138870518654585e-05 -->grad_value: -6.081133818724993e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003702843561768532 -->grad_value: 1.666214075157768e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020052592735737562 -->grad_value: 1.666214075157768e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020278444571886212 -->grad_value: -2.738379407674074e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018703947716858238 -->grad_value: -2.278161446156446e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032368702813982964 -->grad_value: -0.00021945626940578222 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024426814634352922 -->grad_value: -0.00021945626940578222 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.251945938449353e-05 -->grad_value: -1.4390298019861802e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003295464674010873 -->grad_value: -3.947583900298923e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0020639696158468723 -->grad_value: -3.947583900298923e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015324766281992197 -->grad_value: -0.0013966304250061512 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0033250106498599052 -->grad_value: -2.44209885597229 

INFO:root:
 ** Round 2 : Batch size = 19 , avg loss = 0.007123376438884358

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007192589109763503 -->grad_value: -0.004090235102921724 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012623186921700835 -->grad_value: 9.393927413725578e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021798708476126194 -->grad_value: -5.6330618463107385e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997317187488079 -->grad_value: -5.6330618463107385e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011835531331598759 -->grad_value: 0.001106370473280549 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -9.029282227857038e-05 -->grad_value: -5.812759695800196e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036838690284639597 -->grad_value: 2.352107458136743e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020242345053702593 -->grad_value: 2.352107458136743e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020178462727926672 -->grad_value: -1.7021611711243168e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018681600340642035 -->grad_value: -9.472228157392237e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003205666085705161 -->grad_value: -0.00016703427536413074 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002473886124789715 -->grad_value: -0.00016703427536413074 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.054621240356937e-05 -->grad_value: 2.4538167053833604e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003243079874664545 -->grad_value: -2.080378180835396e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021163541823625565 -->grad_value: -2.080378180835396e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015254928730428219 -->grad_value: -0.0012279804795980453 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0037688608281314373 -->grad_value: -2.3745553493499756 

INFO:root:
 ** Round 3 : Batch size = 20 , avg loss = 0.006700401101261378

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007200752734206617 -->grad_value: -0.0002893469645641744 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012623000657185912 -->grad_value: 9.065972861321825e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179110422730446 -->grad_value: -2.576778115326306e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019980778452008963 -->grad_value: -2.576778115326306e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011856358032673597 -->grad_value: -0.00027367143775336444 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -9.013976523419842e-05 -->grad_value: -5.7068221259726215e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036814631894230843 -->grad_value: -1.871715511470029e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020266398787498474 -->grad_value: -1.871715511470029e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020160054555162787 -->grad_value: -1.8656250233561877e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018670488498173654 -->grad_value: 7.104088126652641e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032028094865381718 -->grad_value: -2.4936139197961893e-06 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024767436552792788 -->grad_value: -2.4936139197961893e-06 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.033178265672177e-05 -->grad_value: 2.7232283628109144e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032386723905801773 -->grad_value: 1.2340236935415305e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021207614336162806 -->grad_value: 1.2340236935415305e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015255045145750046 -->grad_value: 0.0004868173855356872 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.003807749832049012 -->grad_value: -0.023280810564756393 

INFO:root:
 ** Round 4 : Batch size = 20 , avg loss = 0.006593186350073665

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007206277223303914 -->grad_value: 0.00027742344536818564 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012627767864614725 -->grad_value: 1.8829332759651152e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021781856194138527 -->grad_value: 2.5091020461331937e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019990019500255585 -->grad_value: 2.5091020461331937e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011858056532219052 -->grad_value: -0.00018859922420233488 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -9.006792970467359e-05 -->grad_value: -2.743103522107049e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003680239664390683 -->grad_value: 6.697109711240046e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002027863636612892 -->grad_value: 6.697109711240046e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020206741464789957 -->grad_value: 2.746287009358639e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001863524958025664 -->grad_value: 5.338698088053206e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032043938990682364 -->grad_value: 9.617907198844478e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002475159941241145 -->grad_value: 9.617907198844478e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.032297874800861e-05 -->grad_value: 6.287731366683147e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032391995191574097 -->grad_value: 2.0223480532877147e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002120235003530979 -->grad_value: 2.0223480532877147e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015273104654625058 -->grad_value: 0.00017746593221090734 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038119114469736814 -->grad_value: 0.09606222808361053 

INFO:root:
 ** Round 5 : Batch size = 19 , avg loss = 0.0063419554284528685

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007190247997641563 -->grad_value: 0.0014483758714050055 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263287413166836 -->grad_value: 1.7442710387172156e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179281320422888 -->grad_value: 6.265418619477714e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997906481847167 -->grad_value: 6.265418619477714e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.001186863868497312 -->grad_value: 3.820511847152375e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -9.000843419926241e-05 -->grad_value: 1.8212542585160918e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036788275465369225 -->grad_value: 1.3420251434581587e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020292759872972965 -->grad_value: 1.3420251434581587e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020276158466003835 -->grad_value: 2.8671329346252605e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018605319201014936 -->grad_value: 4.4774020580007345e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032099848613142967 -->grad_value: 9.852599760051817e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024695685133337975 -->grad_value: 9.852599760051817e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.023882502224296e-05 -->grad_value: 6.382092010426277e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032414852175861597 -->grad_value: 1.580673961143475e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021179490722715855 -->grad_value: 1.580673961143475e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015292856842279434 -->grad_value: 0.00042914971709251404 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.003807674627751112 -->grad_value: 0.09203092008829117 

INFO:root:
 ** Round 6 : Batch size = 20 , avg loss = 0.0066257593221962455

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188774179667234 -->grad_value: -0.0007147356518544257 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.000126336031826213 -->grad_value: 7.845936345063365e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179383300244808 -->grad_value: -8.853006079334591e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019978045020252466 -->grad_value: -8.853006079334591e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011871767928823829 -->grad_value: 6.584121729247272e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -9.000864520203322e-05 -->grad_value: 3.2733460386680235e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003678809152916074 -->grad_value: 8.758503895478498e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020292941480875015 -->grad_value: 8.758503895478498e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020280950411688536 -->grad_value: 1.5752045783301583e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001859979092841968 -->grad_value: 3.3605013527449046e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032111413311213255 -->grad_value: 9.113385021919385e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024684122763574123 -->grad_value: 9.113385021919385e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.021541099064052e-05 -->grad_value: 4.4612366423280037e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032419697381556034 -->grad_value: 1.870732376119122e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002117464318871498 -->grad_value: 1.870732376119122e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015295639168471098 -->grad_value: 0.00014396605547517538 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038066019769757986 -->grad_value: 0.11488223075866699 

INFO:root:
 ** Round 7 : Batch size = 20 , avg loss = 0.00658011861378327

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007189109455794096 -->grad_value: -0.00040992628782987595 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012633635196834803 -->grad_value: 6.655082707140991e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021793623454868793 -->grad_value: -1.1302521443212754e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997825689613819 -->grad_value: -1.1302521443212754e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011876145144924521 -->grad_value: 0.0002322303771506995 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.99957594810985e-05 -->grad_value: 7.365859033825473e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036788806319236755 -->grad_value: 1.7738457245286554e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020292229019105434 -->grad_value: 1.7738457245286554e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020285203936509788 -->grad_value: 2.4234354896179866e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018596803420223296 -->grad_value: 7.016001291049179e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003212621435523033 -->grad_value: 0.000155287139932625 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024669317062944174 -->grad_value: 0.000155287139932625 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.022327630082145e-05 -->grad_value: 6.553809157594515e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032426840625703335 -->grad_value: 2.8392478270689026e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002116749994456768 -->grad_value: 2.8392478270689026e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015297767240554094 -->grad_value: 0.00040614971658214927 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.003804999403655529 -->grad_value: 0.18495891988277435 

INFO:root:
 ** Round 8 : Batch size = 19 , avg loss = 0.006431253994569967

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718703493475914 -->grad_value: 0.00030575846903957427 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012633134610950947 -->grad_value: 9.005517220828096e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179435919970274 -->grad_value: -3.7879169667576207e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997752580791712 -->grad_value: -3.7879169667576207e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011879985686391592 -->grad_value: 0.0005889338790439069 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.996187534648925e-05 -->grad_value: 6.208749958602766e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679088782519102 -->grad_value: 2.33718060371757e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002029015216976404 -->grad_value: 2.33718060371757e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294709247536957 -->grad_value: 4.429959517437965e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018594227731227875 -->grad_value: 1.1727331639121985e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003214877564460039 -->grad_value: 0.00022692547645419836 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024646767415106297 -->grad_value: 0.00022692547645419836 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.027636896353215e-05 -->grad_value: 1.0959632845697342e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003243788378313184 -->grad_value: 3.6662186175817624e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021156452130526304 -->grad_value: 3.6662186175817624e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015299977967515588 -->grad_value: 0.0007679199334233999 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038024962414056063 -->grad_value: 0.2600661814212799 

INFO:root:
 ** Round 9 : Batch size = 19 , avg loss = 0.007741828056934632

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718702794983983 -->grad_value: 0.0001704505120869726 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012632999278139323 -->grad_value: 4.850645218823502e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021794314961880445 -->grad_value: -4.055041245010216e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019977563060820103 -->grad_value: -4.055041245010216e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880048550665379 -->grad_value: -0.0002739178598858416 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995762618724257e-05 -->grad_value: -9.979314263830474e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679141867905855 -->grad_value: -3.618235098201694e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002028961665928364 -->grad_value: -3.618235098201694e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020295556169003248 -->grad_value: 1.7262182154809125e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018593831919133663 -->grad_value: -1.7687366948848648e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032151849009096622 -->grad_value: 0.00010820975876413286 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024643687065690756 -->grad_value: 0.00010820975876413286 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028042167192325e-05 -->grad_value: 4.115096601253754e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032439217902719975 -->grad_value: 1.852671630331315e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002115512266755104 -->grad_value: 1.852671630331315e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015300300437957048 -->grad_value: -0.0002770603750832379 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038022019434720278 -->grad_value: 0.09459532797336578 

INFO:root:
 ** Round 10 : Batch size = 20 , avg loss = 0.007106670015491545

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007187627488747239 -->grad_value: 0.0004550497978925705 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012632666039280593 -->grad_value: 2.0474212547583193e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179410308599472 -->grad_value: 8.703625553607708e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019977777265012264 -->grad_value: 8.703625553607708e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.001188000780530274 -->grad_value: 5.757805774919689e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995526877697557e-05 -->grad_value: -6.612824954288499e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036792177706956863 -->grad_value: -7.11299151134881e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.00202888622879982 -->grad_value: -7.11299151134881e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002029447932727635 -->grad_value: 3.158193976560142e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018593252752907574 -->grad_value: 4.904819661533111e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032155741937458515 -->grad_value: 0.000199562608031556 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002463978249579668 -->grad_value: 0.000199562608031556 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028129478683695e-05 -->grad_value: 8.357104661627091e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244084306061268 -->grad_value: 4.1660860006231815e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021153506822884083 -->grad_value: 4.1660860006231815e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015300796367228031 -->grad_value: 0.0004791391547769308 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038018738850951195 -->grad_value: 0.19436387717723846 

INFO:root:
 ** Round 11 : Batch size = 20 , avg loss = 0.007199613389093429

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188424933701754 -->grad_value: -1.4399563951883465e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631958816200495 -->grad_value: 7.3561237101671395e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179366070777178 -->grad_value: -3.3731620874277723e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019978228956460953 -->grad_value: -3.3731620874277723e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.001188039779663086 -->grad_value: -0.0007331392844207585 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995267853606492e-05 -->grad_value: -5.8112239464946924e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036792727187275887 -->grad_value: -6.40854580069572e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288305822759867 -->grad_value: -6.40854580069572e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294985733926296 -->grad_value: 4.2560413930914365e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001858934119809419 -->grad_value: 1.1994138731097337e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216214245185256 -->grad_value: 0.00026963421260006726 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002463337266817689 -->grad_value: 0.00026963421260006726 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028787952847779e-05 -->grad_value: 1.2643517948163208e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244386985898018 -->grad_value: 6.162507634144276e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002115047536790371 -->grad_value: 6.162507634144276e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302276005968451 -->grad_value: 0.000985433580353856 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038012471050024033 -->grad_value: 0.24822840094566345 

INFO:root:
 ** Round 12 : Batch size = 20 , avg loss = 0.006897100154310465

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188472663983703 -->grad_value: 0.00020861331722699106 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631906429305673 -->grad_value: 1.0039208575562952e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021793623454868793 -->grad_value: -3.1783881127012137e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019978268537670374 -->grad_value: -3.1783881127012137e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880500242114067 -->grad_value: 0.00013012383715249598 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995219832286239e-05 -->grad_value: -1.275424987845497e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036792673636227846 -->grad_value: 8.406294682572479e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288359373807907 -->grad_value: 8.406294682572479e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002029505412792787 -->grad_value: -1.183675522042904e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588799866847694 -->grad_value: 5.272821681501227e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216252662241459 -->grad_value: -4.943363819620572e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632993154227734 -->grad_value: -4.943363819620572e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028806870337576e-05 -->grad_value: 9.089855268484826e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032444109674543142 -->grad_value: 3.838988504867302e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021150242537260056 -->grad_value: 3.838988504867302e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001530243782326579 -->grad_value: 0.0005100119160488248 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038012065924704075 -->grad_value: -0.07252728939056396 

INFO:root:
 ** Round 13 : Batch size = 19 , avg loss = 0.006776342389026755

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188464514911175 -->grad_value: 0.0009483741014264524 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631846766453236 -->grad_value: 7.309360228191508e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021793353371322155 -->grad_value: -4.932943511448684e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997854094952345 -->grad_value: -4.932943511448684e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880610836669803 -->grad_value: -0.0004897114122286439 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995162352221087e-05 -->grad_value: -3.564412986989396e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679251531139016 -->grad_value: -5.093912136544532e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.00202885246835649 -->grad_value: -5.093912136544532e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002029474708251655 -->grad_value: -4.0391398670180934e-08 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588670354802161 -->grad_value: 6.924652780071483e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032162279821932316 -->grad_value: -2.071702510875184e-06 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002463323762640357 -->grad_value: -2.071702510875184e-06 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028782859677449e-05 -->grad_value: 3.789523077557533e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032444146927446127 -->grad_value: 1.5977440853021108e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.00211502006277442 -->grad_value: 1.5977440853021108e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302475076168776 -->grad_value: 0.0007097485940903425 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.003801229177042842 -->grad_value: -0.010779909789562225 

INFO:root:
 ** Round 14 : Batch size = 20 , avg loss = 0.007341719116084278

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188496529124677 -->grad_value: 0.0005878778756596148 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631737627089024 -->grad_value: 1.5076174975092727e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792766638100147 -->grad_value: -1.4773108887311537e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019979116041213274 -->grad_value: -1.4773108887311537e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880772653967142 -->grad_value: -0.0008731436100788414 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995090320240706e-05 -->grad_value: 1.1734175853206352e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679221495985985 -->grad_value: -8.228839192270243e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002028881572186947 -->grad_value: -8.228839192270243e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294150453992188 -->grad_value: 3.7592110402329126e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001858850009739399 -->grad_value: 6.32372064046649e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032162393908947706 -->grad_value: 0.00014574956730939448 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002463312353938818 -->grad_value: 0.00014574956730939448 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028747935080901e-05 -->grad_value: 1.4007489426148823e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032444384414702654 -->grad_value: 4.4456712203100324e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114995615556836 -->grad_value: 4.4456712203100324e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302482061088085 -->grad_value: 0.0006913235411047935 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038012079894542694 -->grad_value: 0.14317569136619568 

INFO:root:
 ** Round 15 : Batch size = 19 , avg loss = 0.007362198292914974

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718849478289485 -->grad_value: -0.0007163865957409143 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631728895939887 -->grad_value: -3.8010883329775424e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179271774366498 -->grad_value: -9.889228067549993e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997916726395488 -->grad_value: -9.889228067549993e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.001188076799735427 -->grad_value: -0.00010677454702090472 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995078678708524e-05 -->grad_value: 1.7866101931218736e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679218702018261 -->grad_value: 2.566548005233926e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288843661546707 -->grad_value: 2.566548005233926e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294163550715894 -->grad_value: 3.683584282043739e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588441889733076 -->grad_value: 1.3234295010988717e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216251265257597 -->grad_value: 0.000166932528372854 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024633007124066353 -->grad_value: 0.000166932528372854 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0287995943799615e-05 -->grad_value: 6.964754675209406e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244441468268633 -->grad_value: 7.264383384608664e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149918902665377 -->grad_value: 7.264383384608664e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001530247274786234 -->grad_value: -0.0007890284177847207 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038012058939784765 -->grad_value: -0.05477314069867134 

INFO:root:
 ** Round 16 : Batch size = 19 , avg loss = 0.006497820300099097

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188496529124677 -->grad_value: -0.00018344100681133568 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263172598555684 -->grad_value: -8.488956204644182e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179269213229418 -->grad_value: -2.9172940685384674e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997919287532568 -->grad_value: -2.9172940685384674e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880770325660706 -->grad_value: 3.617181209847331e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995070675155148e-05 -->grad_value: -1.4751482257935322e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036792163737118244 -->grad_value: 2.914190133651573e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002028886927291751 -->grad_value: 2.914190133651573e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0002029419265454635 -->grad_value: -1.119931312132394e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001858832547441125 -->grad_value: 1.7956532474272535e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216264769434929 -->grad_value: 0.00011391959560569376 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632872082293034 -->grad_value: 0.00011391959560569376 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028859984828159e-05 -->grad_value: 3.4889757216660655e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442865252495 -->grad_value: -5.161509307072265e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149911917746067 -->grad_value: -5.161509307072265e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001530246576294303 -->grad_value: -0.00026104541029781103 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.003801214275881648 -->grad_value: -0.13671885430812836 

INFO:root:
 ** Round 17 : Batch size = 19 , avg loss = 0.0072844367915470346

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188510498963296 -->grad_value: -0.0006241553346626461 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631723075173795 -->grad_value: -2.1946892303503773e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179265022277832 -->grad_value: -1.5634373085049447e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019979237113147974 -->grad_value: -1.5634373085049447e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880781967192888 -->grad_value: 0.0007409836398437619 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995051757665351e-05 -->grad_value: -2.8006148511394713e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036792131140828133 -->grad_value: 1.933904059114866e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288899540901184 -->grad_value: 1.933904059114866e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294179557822645 -->grad_value: -2.8955423658771906e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588145030662417 -->grad_value: 2.1077289602544624e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216276876628399 -->grad_value: 0.00014938377717044204 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632744025439024 -->grad_value: 0.00014938377717044204 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.02891164412722e-05 -->grad_value: 6.715168865412124e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.00324444193392992 -->grad_value: 6.365916306094732e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149911917746067 -->grad_value: 6.365916306094732e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001530247274786234 -->grad_value: 0.00031191069865599275 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0038012275472283363 -->grad_value: -0.11680725961923599 

INFO:root:
 ** Round 18 : Batch size = 19 , avg loss = 0.0072246251358209475

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188509916886687 -->grad_value: 0.0002954940719064325 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631723075173795 -->grad_value: 2.176694380295885e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792645566165447 -->grad_value: 4.507218704929983e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0019979241769760847 -->grad_value: 4.507218704929983e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.000690597458742559 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995049574878067e-05 -->grad_value: -2.8340718660757602e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.324373556599312e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288906525820494 -->grad_value: 1.324373556599312e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294181013014168 -->grad_value: 1.0252007314193179e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588142120279372 -->grad_value: -4.71344833385956e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216277342289686 -->grad_value: 6.022568413754925e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632737040519714 -->grad_value: 6.022568413754925e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.02891673729755e-05 -->grad_value: -8.242099625022092e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.00324444193392992 -->grad_value: 2.7508456241776003e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149911917746067 -->grad_value: 2.7508456241776003e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302473912015557 -->grad_value: -0.00013495629536919296 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.040698058903217316 

INFO:root:
 ** Round 19 : Batch size = 20 , avg loss = 0.006753991218283772

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188512245193124 -->grad_value: 0.00037382927257567644 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012631717254407704 -->grad_value: 9.62950386096395e-10 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.002179264323785901 -->grad_value: 4.503139621192531e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997924642637372 -->grad_value: 4.503139621192531e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880786623805761 -->grad_value: 0.0007536964258179069 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.99505103006959e-05 -->grad_value: -4.571076406278962e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0036792121827602386 -->grad_value: 1.520623300166335e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288913510739803 -->grad_value: 1.520623300166335e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294185378588736 -->grad_value: 1.866674665507162e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588153761811554 -->grad_value: -1.2714735930785537e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0032162778079509735 -->grad_value: 0.00010231674241367728 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632734712213278 -->grad_value: 0.00010231674241367728 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028913099318743e-05 -->grad_value: 1.3373954743656213e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.00324444193392992 -->grad_value: 1.0572523024166003e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149911917746067 -->grad_value: 1.0572523024166003e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302475076168776 -->grad_value: 0.00022654695203527808 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.07609929144382477 

INFO:root:
 ** Round 20 : Batch size = 20 , avg loss = 0.0066886429442092775

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851457349956 -->grad_value: -0.0004497751942835748 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: 1.3045758251450934e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: 9.358536772197112e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: 9.358536772197112e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.0011232801480218768 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.99505103006959e-05 -->grad_value: -5.257410506942506e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 2.118480551871471e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.002028890885412693 -->grad_value: 2.118480551871471e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294185378588736 -->grad_value: 3.7946349493722664e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -2.1832005359101458e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278040781617 -->grad_value: 0.00013974259491078556 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00013974259491078556 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 3.5437989254205604e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032444423995912075 -->grad_value: 7.03856858308427e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149907261133194 -->grad_value: 7.03856858308427e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302479732781649 -->grad_value: -0.0006326954462565482 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.015230097807943821 

INFO:root:
 ** Round 21 : Batch size = 20 , avg loss = 0.05730309484060854

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -0.00021416446543298662 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: 1.1274156719309758e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -3.370685703885101e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -3.370685703885101e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: -1.7435850168112665e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995050302473828e-05 -->grad_value: 6.828573706485486e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 7.064430178616021e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 7.064430178616021e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 2.7371468149794964e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001858817267930135 -->grad_value: 4.918178433399589e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278040781617 -->grad_value: 0.00013736559776589274 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00013736559776589274 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.028915282106027e-05 -->grad_value: 7.538694717368344e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032444423995912075 -->grad_value: 2.8192278477945365e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149907261133194 -->grad_value: 2.8192278477945365e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001530247856862843 -->grad_value: -0.00016102386871352792 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.1349971741437912 

INFO:root:
 ** Round 22 : Batch size = 20 , avg loss = 0.00705632409080863

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0007188515737652779 -->grad_value: -0.00017332605784758925 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: 1.0789674043110153e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -1.3557707916334039e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -1.3557707916334039e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.0005769978160969913 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.99505103006959e-05 -->grad_value: 1.275859062843665e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.718117346172221e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 1.718117346172221e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294189744163305 -->grad_value: 4.631822775991168e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0001858817267930135 -->grad_value: 3.2876857858354924e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278040781617 -->grad_value: 0.00019561871886253357 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00019561871886253357 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.1997435649391264e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0032444423995912075 -->grad_value: 4.0315717342309654e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0021149904932826757 -->grad_value: 4.0315717342309654e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.001530247856862843 -->grad_value: 8.703209459781647e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.1878211796283722 

INFO:root:
 ** Round 23 : Batch size = 20 , avg loss = 0.006715337885543704

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: 7.284278399311006e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: 1.5333375458226328e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -1.1546613905011327e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -1.1546613905011327e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.000428168976213783 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 1.1495466800681697e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 6.836401098553324e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 6.836401098553324e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 5.465590220410377e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: 2.6269364639119885e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.000197609857423231 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.000197609857423231 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.4681803577332175e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 4.09168642363511e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 4.09168642363511e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -9.087612852454185e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.1803675889968872 

INFO:root:
 ** Round 24 : Batch size = 20 , avg loss = 0.007198991440236569

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -0.00024646520614624023 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: 3.1518012644227156e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -4.777269850819721e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -4.777269850819721e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.00043551018461585045 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 6.0000404644711125e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.065416086021287e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 1.065416086021287e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 3.080025180679513e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -2.3092775336408522e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.00018250133143737912 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00018250133143737912 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 7.14453051386954e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 3.811725036939606e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 3.811725036939606e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.0004092195304110646 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.2163863182067871 

INFO:root:
 ** Round 25 : Batch size = 18 , avg loss = 0.006421017977926467

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -0.00034772988874465227 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -2.566568291229032e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -8.854195812091348e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -8.854195812091348e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.000499057350680232 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 1.0363199187679584e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.3294786640472012e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 1.3294786640472012e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 4.93118932354264e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588175589684397 -->grad_value: -1.3460842751555901e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.0002536872052587569 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.0002536872052587569 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.1680758689180948e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 5.266730295261368e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 5.266730295261368e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.0004468515980988741 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.32212886214256287 

INFO:root:
 ** Round 26 : Batch size = 20 , avg loss = 0.057051823125220835

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -0.0009696651832200587 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -1.2213043021347403e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -1.6178942132683005e-06 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -1.6178942132683005e-06 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.00033949653152376413 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 1.543596539477221e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.2843888725910801e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 1.2843888725910801e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 6.8312206167320255e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: 3.3529079246363835e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.0004126978456042707 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.0004126978456042707 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.8837546349459444e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 9.261843661079183e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 9.261843661079183e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.0005194002296775579 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.49403366446495056 

INFO:root:
 ** Round 27 : Batch size = 19 , avg loss = 0.007108516991138458

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: 0.0007153120823204517 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: 4.39378800010104e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: 3.348763470967242e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: 3.348763470967242e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.00029543921118602157 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 8.231210379960885e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 4.978475089956191e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 4.978475089956191e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 4.012968474853551e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: 1.4760679789560527e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.00016242818674072623 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00016242818674072623 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 8.711243708603433e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 2.686818697839044e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 2.686818697839044e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.00017890153685584664 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.18502876162528992 

INFO:root:
 ** Round 28 : Batch size = 20 , avg loss = 0.007005097670480609

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: 0.0003736379148904234 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -5.712155193293711e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -2.6322237545173266e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -2.6322237545173266e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.0005362200317904353 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 1.544088412686051e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.5044258816487854e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 1.5044258816487854e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 6.421850230253767e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -8.53374615417124e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.00024248950649052858 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00024248950649052858 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.659666963860218e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 4.901269858237356e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 4.901269858237356e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.00025951419956982136 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.25564754009246826 

INFO:root:
 ** Round 29 : Batch size = 20 , avg loss = 0.006817844905890524

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: 0.0005194451659917831 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -6.703537280827732e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -2.1199525690462906e-08 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -2.1199525690462906e-08 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.00022527713736053556 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 1.807724459013116e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 8.806217692836071e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 8.806217692836071e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 8.668960617796984e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -2.7443437033980445e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.00031113880686461926 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00031113880686461926 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 2.0349029909993988e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 5.359486021916382e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 5.359486021916382e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.0007319822907447815 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.32415324449539185 

INFO:root:
 ** Round 30 : Batch size = 20 , avg loss = 0.006839051190763712

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: 0.0006211877334862947 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -3.2701441554650046e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: 4.5039894303045003e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: 4.5039894303045003e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.0003633703163359314 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: -2.2971939905858108e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.4188472050591372e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 1.4188472050591372e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 4.4050446490473405e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -4.080742144196847e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 2.5960222046705894e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 2.5960222046705894e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 2.9698057346649875e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 1.8056472299576853e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 1.8056472299576853e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.00021945560001768172 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.008685104548931122 

INFO:root:
 ** Round 31 : Batch size = 19 , avg loss = 0.006573986997337718

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: 0.0005406350828707218 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -8.455264932649698e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: 3.460148718659184e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: 3.460148718659184e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: -5.8893696404993534e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: -9.047944615758752e-10 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 1.6174560641957214e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 1.6174560641957214e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 2.5699757770780707e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -1.462309882072077e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.0001161208056146279 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.0001161208056146279 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 3.512532202876173e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 1.3974951798445545e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 1.3974951798445545e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: 5.89367700740695e-05 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.10888759791851044 

INFO:root:
 ** Round 32 : Batch size = 20 , avg loss = 0.007216266356408596

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -6.901208689669147e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -1.6990224338542248e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -9.660295745561598e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -9.660295745561598e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: 0.0001368597149848938 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 9.480030094266567e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: 2.5419747089472366e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: 2.5419747089472366e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 7.474577159882756e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: 2.425817910989281e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.00037985239760018885 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.00037985239760018885 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.4013314739713678e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 5.930106999585405e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 5.930106999585405e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: -0.0003128398675471544 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.42669677734375 

INFO:root:
 ** Round 33 : Batch size = 17 , avg loss = 0.007495774764238912

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -0.0002808475401252508 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -8.087984504356882e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -4.533394530881196e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -4.533394530881196e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: -0.0008204428595490754 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: -1.2991306919118983e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: -1.1489926237118198e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: -1.1489926237118198e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 1.0915866823779652e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -6.784031114648315e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 6.1011149227852e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 6.1011149227852e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 7.726471267233137e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 2.7585758289205842e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 2.7585758289205842e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: 0.00014592724619433284 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.036956317722797394 

INFO:root:
 ** Round 34 : Batch size = 19 , avg loss = 0.0073465947551946895

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -0.0002736772585194558 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -2.38121149465087e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -8.371852118216339e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -8.371852118216339e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: -0.0003895825066138059 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 3.6824279181502106e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: -2.3352500022610911e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: -2.3352500022610911e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 3.2833781915542204e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: -6.372194860659874e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.0001406657975167036 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.0001406657975167036 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.2738083796648425e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 3.7832702219020575e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 3.7832702219020575e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: 0.0005349211278371513 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.10696714371442795 

INFO:root:
 ** Round 35 : Batch size = 19 , avg loss = 0.0065983192456003864

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -0.00012743836850859225 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: -2.2276093858408785e-08 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -8.658621482027229e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -8.658621482027229e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: -0.0014461502432823181 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: 4.328801317399211e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: -1.0241881227557315e-06 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: -1.0241881227557315e-06 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: 3.674074378068326e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: 2.0649306975428772e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: 0.0001769044902175665 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: 0.0001769044902175665 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: 1.396304242007318e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: 3.975657091359608e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: 3.975657091359608e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: 0.0006102286279201508 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: 0.134266197681427 

INFO:root:
 ** Round 36 : Batch size = 20 , avg loss = 0.006153450184501708

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.000718851515557617 -->grad_value: -5.992640581098385e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.0001263170561287552 -->grad_value: 1.3189811465252888e-09 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0021792633924633265 -->grad_value: -1.0043088138900202e-07 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.001997925341129303 -->grad_value: -1.0043088138900202e-07 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0011880784295499325 -->grad_value: -0.00017516178195364773 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -8.995052485261112e-05 -->grad_value: -2.305705848471007e-09 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.003679212648421526 -->grad_value: -2.1727586840825097e-07 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0020288911182433367 -->grad_value: -2.1727586840825097e-07 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00020294188288971782 -->grad_value: -2.905813744291663e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00018588174134492874 -->grad_value: 9.201348234455509e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.003216278273612261 -->grad_value: -0.00010372258839197457 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0024632730055600405 -->grad_value: -0.00010372258839197457 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -4.0289160097017884e-05 -->grad_value: -3.8532903090526816e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight 6.35010510450229e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.003244442632421851 -->grad_value: -1.4095369806454983e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.002114990260452032 -->grad_value: -1.4095369806454983e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight -0.0015302477404475212 -->grad_value: 0.0006338490638881922 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.00380122778005898 -->grad_value: -0.12709371745586395 

