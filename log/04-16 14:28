INFO:root:
 ======== Start Log Recording :04-16 14:28 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 97 , avg loss = 0.020217799239542297

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0004592608893290162 -->grad_value: -0.06224492937326431 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -7.010667468421161e-05 -->grad_value: 4.3881850615434814e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00034241253160871565 -->grad_value: -0.00019364421314094216 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0004641880514100194 -->grad_value: -0.00019364421314094216 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0003840432036668062 -->grad_value: -0.04377434030175209 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.483980253804475e-05 -->grad_value: 2.521707926916861e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0004288827767595649 -->grad_value: -3.5502413084032014e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0022631885949522257 -->grad_value: -3.5502413084032014e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 6.003338421578519e-05 -->grad_value: -0.0001220603589899838 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00029881641967222095 -->grad_value: -8.651216376165394e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 1.2078788131475449e-05 -->grad_value: 0.0025794049724936485 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0011756226886063814 -->grad_value: 0.0025794049724936485 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -6.78700307616964e-05 -->grad_value: 0.00042577809654176235 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00014676166756544262 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.002459663199260831 -->grad_value: -0.010439064353704453 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.005521711427718401 -->grad_value: -0.010439064353704453 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0027871597558259964 -->grad_value: -0.027993083000183105 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.001824221690185368 -->grad_value: -25.357635498046875 

INFO:root:
 ** Round 1 : Batch size = 97 , avg loss = 0.05004272913056505

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0004577511572279036 -->grad_value: 8164639744.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -8.203561446862295e-05 -->grad_value: 212561.484375 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00039597670547664165 -->grad_value: 23805274.0 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0005177523125894368 -->grad_value: 23805274.0 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0003872406086884439 -->grad_value: -10075868160.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -3.283349360572174e-05 -->grad_value: 464329.03125 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0004244414158165455 -->grad_value: -44083892.0 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.0022676289081573486 -->grad_value: -44083892.0 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00014058983651921153 -->grad_value: -194910192.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003452235832810402 -->grad_value: -15199735.0 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0008759242482483387 -->grad_value: 4556814336.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.00028761819703504443 -->grad_value: 4556814336.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -2.4031327484408394e-05 -->grad_value: -71038160.0 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00014676166756544262 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.001961964648216963 -->grad_value: 1876006656.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.005024012178182602 -->grad_value: 1876006656.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0026723197661340237 -->grad_value: 17804021760.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight 0.0009161441121250391 -->grad_value: 2625658683392.0 

INFO:root:
 ** Round 2 : Batch size = 99 , avg loss = 0.2587082305978372

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.00042446277802810073 -->grad_value: 8164639744.0 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -9.860713907983154e-05 -->grad_value: 212561.484375 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0004671712522394955 -->grad_value: 23805274.0 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0005889507010579109 -->grad_value: 23805274.0 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.00035780511097982526 -->grad_value: -10075868160.0 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -2.4577020667493343e-05 -->grad_value: 464329.03125 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0005126490723341703 -->grad_value: -44083892.0 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight 0.00217942101880908 -->grad_value: -44083892.0 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 0.00025248434394598007 -->grad_value: -194910192.0 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00043350778287276626 -->grad_value: -15199735.0 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0023251287639141083 -->grad_value: 4556814336.0 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.0011615860275924206 -->grad_value: 4556814336.0 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 4.190432446193881e-05 -->grad_value: -71038160.0 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00014676166756544262 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0010325041366741061 -->grad_value: 1876006656.0 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.00409455131739378 -->grad_value: 1876006656.0 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.002436146605759859 -->grad_value: 17804021760.0 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.002298976294696331 -->grad_value: 2625658683392.0 

