INFO:root:
 ======== Start Log Recording :04-17 11:28 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 9.792256320300309

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.000543236732483 -->grad_value: -0.01485983096063137 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00014581996947526932 -->grad_value: -0.014932483434677124 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030306848930194974 -->grad_value: -0.0002855517668649554 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.367016223724931e-05 -->grad_value: 2.0352215415186947e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0014898369554430246 -->grad_value: -0.0011290598195046186 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013345003826543689 -->grad_value: -0.0011290598195046186 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0003119879693258554 -->grad_value: -0.00016229433822445571 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00033025856828317046 -->grad_value: -1.0230796760879457e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038188560865819454 -->grad_value: -0.0007280231220647693 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.001321976538747549 -->grad_value: -0.0007280231220647693 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00018898241978604347 -->grad_value: 8.235038876591716e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004903678200207651 -->grad_value: -2.971493813674897e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.00263547757640481 -->grad_value: -0.005391486920416355 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002812574850395322 -->grad_value: -0.005391486920416355 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.933217208716087e-05 -->grad_value: -1.59777385988491e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.00010115382610820234 -->grad_value: 6.262177339522168e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.3878063075244427e-05 -->grad_value: 6.262177339522168e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009749727323651314 -->grad_value: -0.005433045327663422 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04235995560884476 -->grad_value: -3.2260594367980957 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.7003773115575314

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0001248121261597 -->grad_value: -0.00024282145022880286 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.0001613224158063531 -->grad_value: 0.007850561290979385 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030857441015541553 -->grad_value: -2.2223041014513e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.318667485378683e-05 -->grad_value: -1.8730158899415983e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015069881919771433 -->grad_value: 0.0005808345740661025 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013173494953662157 -->grad_value: 0.0005808345740661025 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0003158519393764436 -->grad_value: -2.5502959033474326e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032965769059956074 -->grad_value: -1.9255088190561764e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038021057844161987 -->grad_value: 0.00035483832471072674 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013387262588366866 -->grad_value: 0.00035483832471072674 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00018560489115770906 -->grad_value: -2.90204411612649e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004947238485328853 -->grad_value: 1.562969555379823e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027051905635744333 -->grad_value: 0.0025882876943796873 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002882289234548807 -->grad_value: 0.0025882876943796873 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7339334590360522e-05 -->grad_value: 1.5110469320234188e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -8.171956869773567e-05 -->grad_value: -2.7109555958304554e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -4.443369107320905e-06 -->grad_value: -2.7109555958304554e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009616021998226643 -->grad_value: 0.0014737255405634642 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.0417211689054966 -->grad_value: 1.439953327178955 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.7301786935329437

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0004265308380127 -->grad_value: 0.0020456125494092703 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.000162934185937047 -->grad_value: -0.017437145113945007 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0003091468242928386 -->grad_value: 8.446561696473509e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313648529816419e-05 -->grad_value: 2.129334234268754e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015087707433849573 -->grad_value: -0.0012568954844027758 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013155664782971144 -->grad_value: -0.0012568954844027758 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0003162536595482379 -->grad_value: 6.77725620334968e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0003295952337794006 -->grad_value: 1.1496970842017618e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.003800364676862955 -->grad_value: -0.0008210752857849002 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013404672499746084 -->grad_value: -0.0008210752857849002 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00018525379709899426 -->grad_value: 4.633748176274821e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004951767041347921 -->grad_value: -2.8863640181953087e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.002712438115850091 -->grad_value: -0.005868312902748585 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002889536088332534 -->grad_value: -0.005868312902748585 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7132173525169492e-05 -->grad_value: -3.34854526329309e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.969854050315917e-05 -->grad_value: 6.156388553790748e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.423301339149475e-06 -->grad_value: 6.156388553790748e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009602124919183552 -->grad_value: -0.002625570632517338 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04165475815534592 -->grad_value: -3.2691919803619385 

INFO:root:
 ** Round 3 : Batch size = 25 , avg loss = 0.7791977059841156

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.000518560409546 -->grad_value: 0.001281118718907237 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.0001630608458071947 -->grad_value: -0.017304660752415657 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919164419174194 -->grad_value: 6.630256393691525e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313251990126446e-05 -->grad_value: 1.6029073321988108e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089111402630806 -->grad_value: -0.0012535757850855589 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154266634956002 -->grad_value: -0.0012535757850855589 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628465512767434 -->grad_value: 3.706843563122675e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.0003295903734397143 -->grad_value: 1.648267016207683e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.003800228936597705 -->grad_value: -0.0008281349437311292 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406032230705023 -->grad_value: -0.0008281349437311292 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00018522629397921264 -->grad_value: 5.956197128398344e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952121526002884 -->grad_value: -2.7759313525166363e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.002713005058467388 -->grad_value: -0.005872318055480719 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901027981191874 -->grad_value: -0.005872318055480719 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7115973605541512e-05 -->grad_value: -5.4997215670482547e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.954047759994864e-05 -->grad_value: 5.7775003369897604e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.265063812956214e-06 -->grad_value: 5.7775003369897604e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.000960103701800108 -->grad_value: -0.002364132320508361 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.041649557650089264 -->grad_value: -3.249185800552368 

INFO:root:
 ** Round 4 : Batch size = 24 , avg loss = 0.8235855636497339

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.000650405883789 -->grad_value: -0.0021956968121230602 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307097394019365 -->grad_value: 0.007384735159575939 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919513665139675 -->grad_value: 0.0005755534511990845 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313222886295989e-05 -->grad_value: -4.4281568989390507e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089225489646196 -->grad_value: 0.00044191800407133996 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154149055480957 -->grad_value: 0.00044191800407133996 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628733268007636 -->grad_value: 0.00010806358477566391 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.000329589907778427 -->grad_value: 9.41612768201594e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002177607268095 -->grad_value: 0.00023635131947230548 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406140496954322 -->grad_value: 0.00023635131947230548 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852239656727761 -->grad_value: -7.531036771979416e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952150629833341 -->grad_value: 1.3124886208970565e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.002713051624596119 -->grad_value: 0.0025450289249420166 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.002890149364247918 -->grad_value: 0.0025450289249420166 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.711463846731931e-05 -->grad_value: 2.688618110369134e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952708983793855e-05 -->grad_value: -0.00013004060019738972 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.251297701150179e-06 -->grad_value: -0.00013004060019738972 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600943885743618 -->grad_value: 0.0063417041674256325 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164913296699524 -->grad_value: 1.429600715637207 

INFO:root:
 ** Round 5 : Batch size = 25 , avg loss = 0.7856639468669891

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0007367134094238 -->grad_value: 0.00038220317219384015 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307178884744644 -->grad_value: -0.015798285603523254 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919560231268406 -->grad_value: -0.00021765670680906624 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313214155146852e-05 -->grad_value: 7.939654096844606e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089227817952633 -->grad_value: -0.0012913458049297333 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: -0.0012913458049297333 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: -0.00012995816359762102 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: 1.5512244999627e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: -0.0008268223027698696 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: -0.0008268223027698696 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00018522382015362382 -->grad_value: 1.624498690944165e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: -3.401958383619785e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: -0.005854147486388683 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: -0.005854147486388683 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.711458753561601e-05 -->grad_value: -1.6306000816257438e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.95266532804817e-05 -->grad_value: 5.395354673964903e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.25039548240602e-06 -->grad_value: 5.395354673964903e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: -0.0025445434730499983 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: -3.175541639328003 

INFO:root:
 ** Round 6 : Batch size = 24 , avg loss = 0.737721665451924

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0005208253860474 -->grad_value: -0.0007921815849840641 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307190526276827 -->grad_value: -0.018882323056459427 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919554410502315 -->grad_value: -7.092489977367222e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313211972359568e-05 -->grad_value: 4.246020580467302e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089228982105851 -->grad_value: -0.0009210265707224607 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: -0.0009210265707224607 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: -0.0005728132091462612 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: -1.3203184607846197e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: -0.0008076640078797936 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: -0.0008076640078797936 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852238056017086 -->grad_value: 4.9554741963220295e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: -3.376246604602784e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: -0.00571306049823761 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: -0.00571306049823761 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7114572983700782e-05 -->grad_value: -1.3248413210931176e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952668238431215e-05 -->grad_value: 6.019243301125243e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.2504827938973904e-06 -->grad_value: 6.019243301125243e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: -0.0029831037390977144 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: -3.213629722595215 

INFO:root:
 ** Round 7 : Batch size = 24 , avg loss = 0.7707872614264488

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0005301237106323 -->grad_value: -0.00028375390684232116 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307190526276827 -->grad_value: 0.00785832665860653 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919554410502315 -->grad_value: 9.54570987232728e-06 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313211972359568e-05 -->grad_value: -1.3230288686827407e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089228982105851 -->grad_value: 0.000549667573068291 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: 0.000549667573068291 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: 1.611099833098706e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: -1.2185965125866005e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: 0.0003719391825143248 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: 0.0003719391825143248 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852238056017086 -->grad_value: -3.818109689746052e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: 1.555565177113749e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: 0.002605642192065716 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: 0.002605642192065716 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7114572983700782e-05 -->grad_value: 4.2032013425341574e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952668238431215e-05 -->grad_value: -2.2935284505365416e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.2504827938973904e-06 -->grad_value: -2.2935284505365416e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: 0.0015098050935193896 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: 1.4500222206115723 

INFO:root:
 ** Round 8 : Batch size = 25 , avg loss = 0.7516557085514068

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0012445449829102 -->grad_value: 0.007023905403912067 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307190526276827 -->grad_value: -0.021493814885616302 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919554410502315 -->grad_value: -0.00013372980174608529 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313211972359568e-05 -->grad_value: 1.9864000933011994e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089228982105851 -->grad_value: -0.0010982347885146737 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: -0.0010982347885146737 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: -2.555482933530584e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: 6.367412197505473e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: -0.000889776274561882 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: -0.000889776274561882 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852238056017086 -->grad_value: 4.532918865152169e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: -2.1499141439562663e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: -0.006029037293046713 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: -0.006029037293046713 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7114572983700782e-05 -->grad_value: -4.3682934602884416e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952668238431215e-05 -->grad_value: 8.611848897999153e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.2504827938973904e-06 -->grad_value: 8.611848897999153e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: -0.0008055082289502025 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: -3.5446670055389404 

INFO:root:
 ** Round 9 : Batch size = 25 , avg loss = 0.8865069615840911

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.001209020614624 -->grad_value: 0.0006273064063861966 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307190526276827 -->grad_value: 0.007876561023294926 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919554410502315 -->grad_value: -4.441000419319607e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313211972359568e-05 -->grad_value: -9.545269676891621e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089228982105851 -->grad_value: 0.0005904990248382092 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: 0.0005904990248382092 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: -2.9277678549988195e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: 2.1986165776866073e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: 0.0003714894119184464 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: 0.0003714894119184464 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852238056017086 -->grad_value: -2.023537263085018e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: 1.3729958482144866e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: 0.0026487442664802074 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: 0.0026487442664802074 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7114572983700782e-05 -->grad_value: 1.4520217916924594e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952668238431215e-05 -->grad_value: -2.360863800277002e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.2504827938973904e-06 -->grad_value: -2.360863800277002e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: 0.0014714461285620928 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: 1.4588561058044434 

INFO:root:
 ** Round 10 : Batch size = 24 , avg loss = 0.7626899940272173

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.000831127166748 -->grad_value: -0.003308048937469721 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307190526276827 -->grad_value: -0.016889415681362152 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919554410502315 -->grad_value: 1.44737605296541e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313211972359568e-05 -->grad_value: 7.517538506363053e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089228982105851 -->grad_value: -0.0014227103674784303 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: -0.0014227103674784303 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: 4.8947869800031185e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: 2.0756875329652758e-08 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: -0.0007905325619503856 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: -0.0007905325619503856 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852238056017086 -->grad_value: 1.1047704902011901e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: -3.922034738934599e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: -0.005806904286146164 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: -0.005806904286146164 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7114572983700782e-05 -->grad_value: -4.749136195414394e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952668238431215e-05 -->grad_value: 4.3986510718241334e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.2504827938973904e-06 -->grad_value: 4.3986510718241334e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: -0.004171553999185562 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: -3.1163365840911865 

INFO:root:
 ** Round 11 : Batch size = 25 , avg loss = 0.7298466479778289

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0009454488754272 -->grad_value: -0.0003621524083428085 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307190526276827 -->grad_value: -0.016162127256393433 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919554410502315 -->grad_value: -3.1957271858118474e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313211972359568e-05 -->grad_value: 6.843763912911527e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089228982105851 -->grad_value: -0.0012938519939780235 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: -0.0012938519939780235 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: 6.321333785308525e-06 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: 1.408800045510361e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: -0.0008065578294917941 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: -0.0008065578294917941 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852238056017086 -->grad_value: 1.3550452422350645e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: -3.129351534880698e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: -0.005840519443154335 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: -0.005840519443154335 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7114572983700782e-05 -->grad_value: -9.387541410887934e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952668238431215e-05 -->grad_value: 5.624048935715109e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.2504827938973904e-06 -->grad_value: 5.624048935715109e-05 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: -0.0030990394297987223 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: -3.190126419067383 

INFO:root:
 ** Round 12 : Batch size = 24 , avg loss = 0.8095542540152868

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.000906229019165 -->grad_value: 0.006270898040384054 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00016307190526276827 -->grad_value: 0.008260447531938553 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00030919554410502315 -->grad_value: 0.00011453214392531663 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 7.313211972359568e-05 -->grad_value: -5.1454144340823404e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0015089228982105851 -->grad_value: 0.0008528898470103741 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0013154132757335901 -->grad_value: 0.0008528898470103741 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.00031628759461455047 -->grad_value: 2.4384407879551873e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032958987867459655 -->grad_value: 2.3490389366997988e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight 0.0038002170622348785 -->grad_value: 0.00041282468009740114 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0013406143989413977 -->grad_value: 0.00041282468009740114 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0001852238056017086 -->grad_value: -6.624517482123338e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004952152958139777 -->grad_value: 1.9350532966200262e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight 0.0027130553498864174 -->grad_value: 0.0030207079835236073 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight 0.0028901526238769293 -->grad_value: 0.0030207079835236073 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -1.7114572983700782e-05 -->grad_value: 1.0816229689680767e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -6.468820356531069e-05 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -7.952668238431215e-05 -->grad_value: -6.47389970254153e-06 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -2.2504827938973904e-06 -->grad_value: -6.47389970254153e-06 

INFO:root:-->name: linear.weight -->grad_requirs: True --weight 0.0009600937482900918 -->grad_value: 0.0020885542035102844 

INFO:root:-->name: linear.bias -->grad_requirs: True --weight -0.04164910316467285 -->grad_value: 1.5456016063690186 

