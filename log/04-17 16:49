INFO:root:
 ======== Start Log Recording :04-17 16:49 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ======== Start Log Recording :04-17 16:49 ========

INFO:root:
 Model Initialization = LSTM(8, 128, num_layers=2, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, num_layers=2, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 18 , avg loss = 0.5

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9968478679656982 -->grad_value: -0.0002642328036017716 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight 0.005697605200111866 -->grad_value: 0.009874904528260231 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 5.712895654141903e-05 -->grad_value: 1.778835940058343e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -5.2789600886171684e-05 -->grad_value: 2.8013382689096034e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00028510327683761716 -->grad_value: 0.00045410264283418655 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0016464076470583677 -->grad_value: 0.00045410264283418655 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.00019673549104481936 -->grad_value: 3.541122714523226e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00018993724370375276 -->grad_value: -2.8363544402054686e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0026960489340126514 -->grad_value: 4.783106123795733e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.005729169584810734 -->grad_value: 4.783106123795733e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight 7.040626951493323e-05 -->grad_value: 2.1047694644948933e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00014856601774226874 -->grad_value: -1.5563404303975403e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.0012763920240104198 -->grad_value: 0.0014779741177335382 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.006457866169512272 -->grad_value: 0.0014779741177335382 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight 6.19021084276028e-05 -->grad_value: -3.041195739683644e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight 0.0008913945639505982 -->grad_value: 0.0002929416950792074 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight 0.0005283941281959414 -->grad_value: 0.0002929416950792074 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.00026061132666654885 -->grad_value: -8.945435547502711e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.003769896924495697 -->grad_value: 0.02448386326432228 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.0008781258948147297 -->grad_value: 0.018564486876130104 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.0100967762991786 -->grad_value: -1.3658027648925781 

INFO:root:
 ** Round 1 : Batch size = 20 , avg loss = 0.6

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9979199171066284 -->grad_value: -0.026298731565475464 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight 0.004249109886586666 -->grad_value: 0.0971992164850235 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.00030791162862442434 -->grad_value: 0.0009381643030792475 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0003281394310761243 -->grad_value: 3.867483428621199e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0038495557382702827 -->grad_value: 0.0003797437238972634 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.0019180437084287405 -->grad_value: 0.0003797437238972634 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.001119745196774602 -->grad_value: 0.0008281480404548347 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0004890921409241855 -->grad_value: 3.7196282391960267e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.004760741256177425 -->grad_value: -2.8061593184247613e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.00779386144131422 -->grad_value: -2.8061593184247613e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00018452999938745052 -->grad_value: 1.3263732398627326e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -0.00010282446601195261 -->grad_value: -3.7538415199378505e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.005964111536741257 -->grad_value: 0.002226861659437418 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.011145586147904396 -->grad_value: 0.002226861659437418 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00018126302165910602 -->grad_value: 4.051440100738546e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0013247041497379541 -->grad_value: 0.0003754190693143755 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0016877049347385764 -->grad_value: 0.0003754190693143755 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.00019601036910898983 -->grad_value: -0.00017190272046718746 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.005836847238242626 -->grad_value: 0.011928590014576912 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.0019541222136467695 -->grad_value: 0.16354072093963623 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.020973414182662964 -->grad_value: 0.2310502529144287 

INFO:root:
 ** Round 2 : Batch size = 19 , avg loss = 0.3157894736842105

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9976915121078491 -->grad_value: 0.012307907454669476 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.00732358219102025 -->grad_value: 0.07219290733337402 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00041708454955369234 -->grad_value: 0.00018919713329523802 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0006453258683905005 -->grad_value: 6.085807058298087e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.007471856661140919 -->grad_value: -0.000155341112986207 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.005540344398468733 -->grad_value: -0.000155341112986207 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0013375035487115383 -->grad_value: 4.669374175136909e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0007849503308534622 -->grad_value: 3.305776488105039e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.00846388190984726 -->grad_value: -0.0006707560969516635 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.01149700116366148 -->grad_value: -0.0006707560969516635 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00034444755874574184 -->grad_value: -9.758468877407722e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -1.375643114442937e-05 -->grad_value: -3.0304629490274237e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.011200765147805214 -->grad_value: 0.0009753290796652436 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.016382239758968353 -->grad_value: 0.0009753290796652436 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0003030411317013204 -->grad_value: -6.650410568909138e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0057666609063744545 -->grad_value: 0.0002941141719929874 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.006129661574959755 -->grad_value: 0.0002941141719929874 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.00023223560128826648 -->grad_value: -0.000107798827229999 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.009081844240427017 -->grad_value: 0.059896353632211685 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.0007568063447251916 -->grad_value: 0.12522871792316437 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.012368066236376762 -->grad_value: 4.180449485778809 

INFO:root:
 ** Round 3 : Batch size = 20 , avg loss = 0.55

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9986827373504639 -->grad_value: -0.011345617473125458 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.012069638818502426 -->grad_value: 0.000671932939440012 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.0006262032547965646 -->grad_value: -1.1628482752712443e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0009007840417325497 -->grad_value: 1.7971940451388946e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.010200520977377892 -->grad_value: 0.00033191428519785404 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.008269009180366993 -->grad_value: 0.00033191428519785404 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0013322124723345041 -->grad_value: 4.104134495719336e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0008218161528930068 -->grad_value: 1.4605089404540195e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.011088648810982704 -->grad_value: 0.0002695044386200607 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0141217689961195 -->grad_value: 0.0002695044386200607 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00038204799056984484 -->grad_value: 1.467216605988142e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 1.752448224578984e-05 -->grad_value: -5.6189094266301254e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.013932280242443085 -->grad_value: 0.00010167759319301695 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.019113754853606224 -->grad_value: 0.00010167759319301695 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0003456464328337461 -->grad_value: -3.570416140519228e-08 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.007870545610785484 -->grad_value: -0.00016697091632522643 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.008233546279370785 -->grad_value: -0.00016697091632522643 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.00028034846764057875 -->grad_value: 3.533875087669003e-06 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.011322211474180222 -->grad_value: 0.005266458727419376 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.0003190557472407818 -->grad_value: -0.016839992254972458 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.011669760569930077 -->grad_value: -1.8946048021316528 

INFO:root:
 ** Round 4 : Batch size = 20 , avg loss = 0.45

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0009827613830566 -->grad_value: 0.006865089759230614 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.012071972712874413 -->grad_value: 0.033703502267599106 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00011031411122530699 -->grad_value: 4.8997793783200905e-05 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0012174836592748761 -->grad_value: 2.9654896138708864e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.010428915731608868 -->grad_value: -0.0003205591347068548 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.008497403934597969 -->grad_value: -0.0003205591347068548 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0018137663137167692 -->grad_value: 4.154416092205793e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0006887141498737037 -->grad_value: 1.0320275123376632e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.011199673637747765 -->grad_value: -5.438728112494573e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.01423279382288456 -->grad_value: -5.438728112494573e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00042814877815544605 -->grad_value: -1.928912354287604e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -5.177810089662671e-05 -->grad_value: 3.744617060874589e-08 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.014198658056557178 -->grad_value: -7.871421985328197e-07 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.019380131736397743 -->grad_value: -7.871421985328197e-07 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0004755721311084926 -->grad_value: -3.230042864288407e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.006683680694550276 -->grad_value: 0.00010165780986426398 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0070466818287968636 -->grad_value: 0.00010165780986426398 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.00034325860906392336 -->grad_value: -1.2748188964906149e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.01255246251821518 -->grad_value: 0.002238122746348381 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.0023453349713236094 -->grad_value: -0.0037567750550806522 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.010040661320090294 -->grad_value: 0.16213589906692505 

INFO:root:
 ** Round 5 : Batch size = 19 , avg loss = 0.5789473684210527

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9979531764984131 -->grad_value: -0.006275249645113945 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.01675795204937458 -->grad_value: 0.08569549024105072 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -5.5773649364709854e-05 -->grad_value: -0.00039201584877446294 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0011966126039624214 -->grad_value: 1.437878268006898e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.011092621833086014 -->grad_value: -0.0012040839064866304 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.009161110036075115 -->grad_value: -0.0012040839064866304 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017633684910833836 -->grad_value: -6.722506077494472e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00038379832403734326 -->grad_value: -1.5538062143605202e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.00976797565817833 -->grad_value: 8.316260937135667e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.012801095843315125 -->grad_value: 8.316260937135667e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00033017946407198906 -->grad_value: -3.1806303013581783e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight -2.2042804630473256e-06 -->grad_value: -1.1717035874880821e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.015049267560243607 -->grad_value: 4.530686419457197e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.020230742171406746 -->grad_value: 4.530686419457197e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00040172209264710546 -->grad_value: -3.0022115424799267e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.004004061687737703 -->grad_value: -0.0004115775809623301 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.004367061425000429 -->grad_value: -0.0004115775809623301 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.00026974594220519066 -->grad_value: 9.692127059679478e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.013369349762797356 -->grad_value: -0.029051203280687332 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.0019730094354599714 -->grad_value: -0.053359195590019226 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.012615099549293518 -->grad_value: -3.396836996078491 

INFO:root:
 ** Round 6 : Batch size = 20 , avg loss = 0.45

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0040489435195923 -->grad_value: -0.04082578420639038 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.01550342794507742 -->grad_value: -0.09893407672643661 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0024741729721426964 -->grad_value: -0.0008133045630529523 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0012032997328788042 -->grad_value: 1.122946741816122e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.013003142550587654 -->grad_value: 0.0008089807815849781 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.01107163168489933 -->grad_value: 0.0008089807815849781 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.005402146838605404 -->grad_value: -0.0015069390647113323 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.00015081418678164482 -->grad_value: -9.798361588764237e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.01203135959804058 -->grad_value: 0.00014337478205561638 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.015064479783177376 -->grad_value: 0.00014337478205561638 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.000246431736741215 -->grad_value: 1.2657469596888404e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.00017443473916500807 -->grad_value: -5.975128715363098e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.019842714071273804 -->grad_value: 0.000930200272705406 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.025024190545082092 -->grad_value: 0.000930200272705406 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.00038437568582594395 -->grad_value: 1.6553681234654505e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.000636557349935174 -->grad_value: 1.0186879080720246e-05 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0009995570871978998 -->grad_value: 1.0186879080720246e-05 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 1.4203018508851528e-05 -->grad_value: 0.0001413031277479604 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.013237111270427704 -->grad_value: -0.00576902087777853 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.0078972689807415 -->grad_value: 0.16135337948799133 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.010939816012978554 -->grad_value: 1.1042084693908691 

INFO:root:
 ** Round 7 : Batch size = 20 , avg loss = 0.55

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0110410451889038 -->grad_value: -0.02494795434176922 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.011167135089635849 -->grad_value: -0.06313785165548325 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.004009604454040527 -->grad_value: 0.0013126914855092764 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0012469051871448755 -->grad_value: -3.0353187412401894e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.01210060529410839 -->grad_value: -0.00046810609637759626 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.010169094428420067 -->grad_value: -0.00046810609637759626 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0075210090726614 -->grad_value: 0.003697699401527643 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0009188419207930565 -->grad_value: 4.701484795077704e-05 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.015230237506330013 -->grad_value: 0.0005665377248078585 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.018263358622789383 -->grad_value: 0.0005665377248078585 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.00044003891525790095 -->grad_value: 2.49287040787749e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0003641951479949057 -->grad_value: -2.1259533241391182e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.024347830563783646 -->grad_value: 0.0016341917216777802 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.029529305174946785 -->grad_value: 0.0016341917216777802 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0005934311775490642 -->grad_value: 2.4598464733571745e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.0006844140589237213 -->grad_value: 0.001777977915480733 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0010474135633558035 -->grad_value: 0.001777977915480733 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -1.9226994481869042e-05 -->grad_value: -0.001418107422068715 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.012663550674915314 -->grad_value: 0.008411363698542118 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.005169193726032972 -->grad_value: -1.053666591644287 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.010522667318582535 -->grad_value: -2.5458738803863525 

INFO:root:
 ** Round 8 : Batch size = 19 , avg loss = 0.5789473684210527

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0127512216567993 -->grad_value: 0.06894198805093765 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.009752791374921799 -->grad_value: -0.09803882986307144 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.003932604566216469 -->grad_value: -0.0005280759651213884 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0016163454856723547 -->grad_value: -2.4069857317954302e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.010744540020823479 -->grad_value: -0.0008750527631491423 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.008813027292490005 -->grad_value: -0.0008750527631491423 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.006561683025211096 -->grad_value: 0.0014959650579839945 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0018293559551239014 -->grad_value: 9.22261222058296e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02059120126068592 -->grad_value: 0.000959847355261445 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.023624323308467865 -->grad_value: 0.000959847355261445 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0007183307898230851 -->grad_value: -1.1791851193265757e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0005108454497531056 -->grad_value: 2.0624802345992066e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.027951952069997787 -->grad_value: 6.755517097190022e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.03313342481851578 -->grad_value: 6.755517097190022e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0009487331844866276 -->grad_value: 6.450839578064915e-07 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.004329140298068523 -->grad_value: 0.00031363163725472987 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0046921381726861 -->grad_value: 0.00031363163725472987 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 3.12511547235772e-05 -->grad_value: -8.455650822725147e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.0140847098082304 -->grad_value: 0.01431502029299736 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.00014335219748318195 -->grad_value: -0.2469502091407776 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.0140381483361125 -->grad_value: -1.2460123300552368 

INFO:root:
 ** Round 9 : Batch size = 19 , avg loss = 0.5789473684210527

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0064828395843506 -->grad_value: 0.4935850203037262 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.01758849434554577 -->grad_value: 1.9548404216766357 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.006675821729004383 -->grad_value: -0.00995100848376751 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0012316822540014982 -->grad_value: 0.0002591948432382196 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.013541890308260918 -->grad_value: 0.10376137495040894 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.011610378511250019 -->grad_value: 0.10376137495040894 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.005285954102873802 -->grad_value: 0.0010577134089544415 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0018482387531548738 -->grad_value: -8.089658876997419e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02317752316594124 -->grad_value: -0.0012752278707921505 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.026210643351078033 -->grad_value: -0.0012752278707921505 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.000887039874214679 -->grad_value: 1.0552076673775446e-05 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0004711542569566518 -->grad_value: -5.067933216196252e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.030196065083146095 -->grad_value: 0.0019084294326603413 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.035377539694309235 -->grad_value: 0.0019084294326603413 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0011024924460798502 -->grad_value: -2.910760485974606e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.006689560599625111 -->grad_value: 0.0006323343841359019 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.007052559405565262 -->grad_value: 0.0006323343841359019 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00010344491602154449 -->grad_value: 8.523573342245072e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.01661772094666958 -->grad_value: 0.03565925359725952 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.001215706579387188 -->grad_value: 0.51220703125 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.007874245755374432 -->grad_value: 3.2936196327209473 

INFO:root:
 ** Round 10 : Batch size = 20 , avg loss = 0.45

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9975863695144653 -->grad_value: 2.714804172515869 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.03920267894864082 -->grad_value: 8.97388744354248 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010342799127101898 -->grad_value: -0.007234934717416763 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.00044233573134988546 -->grad_value: 0.0015299825463443995 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.01635187305510044 -->grad_value: 0.24519993364810944 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.014420358464121819 -->grad_value: 0.24519993364810944 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.005802715662866831 -->grad_value: -0.00039567146450281143 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0019404864870011806 -->grad_value: 6.818140718678478e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.025749437510967255 -->grad_value: 0.0014034789055585861 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.02878255769610405 -->grad_value: 0.0014034789055585861 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0010527155827730894 -->grad_value: 2.53525877269567e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0007139305816963315 -->grad_value: -1.9876850274158642e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.03437766060233116 -->grad_value: 0.0025679063983261585 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.03955913335084915 -->grad_value: 0.0025679063983261585 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.001236751559190452 -->grad_value: 1.83488882612437e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.013196848332881927 -->grad_value: 0.0035800037439912558 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.013559847138822079 -->grad_value: 0.0035800037439912558 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00027004926232621074 -->grad_value: -0.00039378568180836737 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.02027249149978161 -->grad_value: 0.05794584006071091 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight -0.001838169526308775 -->grad_value: -0.5153093338012695 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.003870801068842411 -->grad_value: -0.8328953981399536 

INFO:root:
 ** Round 11 : Batch size = 20 , avg loss = 0.7

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9943026304244995 -->grad_value: -0.1124730110168457 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.05083645135164261 -->grad_value: 0.13809269666671753 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.011588326655328274 -->grad_value: 0.0001333737891400233 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.00013921191566623747 -->grad_value: -5.928708560531959e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.017212072387337685 -->grad_value: 0.006777022499591112 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.015280560590326786 -->grad_value: 0.006777022499591112 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.00660572899505496 -->grad_value: -0.0002685659273993224 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.002145907375961542 -->grad_value: 5.188410909795493e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.028623636811971664 -->grad_value: -0.00014925313007552177 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.03165675699710846 -->grad_value: -0.00014925313007552177 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0011377891059964895 -->grad_value: 2.373106326558627e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0009979067835956812 -->grad_value: -1.067430957846227e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.03754951059818268 -->grad_value: -8.879190863808617e-05 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.04273098707199097 -->grad_value: -8.879190863808617e-05 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0012447766494005919 -->grad_value: -6.061562089598738e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.018926868215203285 -->grad_value: 0.00039292697329074144 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.019289866089820862 -->grad_value: 0.00039292697329074144 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00027673947624862194 -->grad_value: -9.966799552785233e-06 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.0239080972969532 -->grad_value: -0.00360319996252656 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.002408668166026473 -->grad_value: -0.13559377193450928 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.006554636172950268 -->grad_value: -1.2543100118637085 

INFO:root:
 ** Round 12 : Batch size = 20 , avg loss = 0.6

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.993676483631134 -->grad_value: -0.06679098308086395 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.05612262338399887 -->grad_value: 1.949644923210144 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.011900501325726509 -->grad_value: -0.0005609659710898995 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0001460846106056124 -->grad_value: 0.00020139951084274799 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.015301715582609177 -->grad_value: -0.0019794339314103127 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.013370202854275703 -->grad_value: -0.0019794339314103127 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.009150262922048569 -->grad_value: -0.0011820087675005198 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.002290046075358987 -->grad_value: 1.6944804883678444e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.023920468986034393 -->grad_value: -0.0018108737422153354 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.02695358917117119 -->grad_value: -0.0018108737422153354 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0012542204931378365 -->grad_value: 9.676931540525402e-07 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0010674017248675227 -->grad_value: 7.73958731770108e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.037550028413534164 -->grad_value: -0.00020991271594539285 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.042731501162052155 -->grad_value: -0.00020991271594539285 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0012602517381310463 -->grad_value: 1.1226487913518213e-05 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.019736897200345993 -->grad_value: -0.0010044033406302333 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.02009989507496357 -->grad_value: -0.0010044033406302333 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00031463021878153086 -->grad_value: 5.440254244604148e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.02413027733564377 -->grad_value: -0.0048843733966350555 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.008105260320007801 -->grad_value: -0.30764347314834595 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.01582838036119938 -->grad_value: -2.4381303787231445 

INFO:root:
 ** Round 13 : Batch size = 19 , avg loss = 0.5789473684210527

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9959776401519775 -->grad_value: -0.35615968704223633 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.058703161776065826 -->grad_value: -0.2675924599170685 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.012319972738623619 -->grad_value: -0.00497552752494812 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.000123807301861234 -->grad_value: -7.811786781530827e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.014279317110776901 -->grad_value: 0.0069844601675868034 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.012347802519798279 -->grad_value: 0.0069844601675868034 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.011463518254458904 -->grad_value: -0.001724296365864575 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0023469985462725163 -->grad_value: 5.450763183034724e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.019579056650400162 -->grad_value: -0.0007028320687822998 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.022612174972891808 -->grad_value: -0.0007028320687822998 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0012870965292677283 -->grad_value: -3.071912260566023e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0011637682328000665 -->grad_value: 6.734929911544896e-07 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.03818179666996002 -->grad_value: -0.00029097654623910785 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.043363265693187714 -->grad_value: -0.00029097654623910785 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0012795268557965755 -->grad_value: -5.08975972479675e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.02128666639328003 -->grad_value: 0.0007185355061665177 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.021649666130542755 -->grad_value: 0.0007185355061665177 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00038225483149290085 -->grad_value: 3.390611527720466e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.02537086233496666 -->grad_value: 0.007043854333460331 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.0069827367551624775 -->grad_value: 0.21867841482162476 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.016570791602134705 -->grad_value: 2.0772037506103516 

INFO:root:
 ** Round 14 : Batch size = 20 , avg loss = 0.45

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.002243995666504 -->grad_value: -0.24156969785690308 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.05830318480730057 -->grad_value: -0.4005933105945587 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.012386627495288849 -->grad_value: 0.0017901469254866242 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -7.873753202147782e-05 -->grad_value: -9.649502317188308e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.014822576195001602 -->grad_value: 0.005486595910042524 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.01289106160402298 -->grad_value: 0.005486595910042524 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.012646518647670746 -->grad_value: 0.0018027606420218945 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.002331673866137862 -->grad_value: -2.411659579593106e-06 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.021312929689884186 -->grad_value: -9.257422061637044e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.02434604801237583 -->grad_value: -9.257422061637044e-05 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.0012920713052153587 -->grad_value: -1.9039960079680895e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0012069696094840765 -->grad_value: -8.931689080782235e-06 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.040581896901130676 -->grad_value: 0.0012551137479022145 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.045763373374938965 -->grad_value: 0.0012551137479022145 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.0012974354904145002 -->grad_value: 3.356127081133309e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.023332200944423676 -->grad_value: -0.00030944630270823836 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.023695198819041252 -->grad_value: -0.00030944630270823836 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0004128724685870111 -->grad_value: -3.642345473053865e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.02749788388609886 -->grad_value: 0.011742692440748215 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.0035933824256062508 -->grad_value: 0.02719086781144142 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.010101664811372757 -->grad_value: 1.3929033279418945 

INFO:root:
 ** Round 15 : Batch size = 19 , avg loss = 0.3684210526315789

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0032055377960205 -->grad_value: 0.15129587054252625 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.057796649634838104 -->grad_value: 0.02856382541358471 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.012082293629646301 -->grad_value: 0.0010987925343215466 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -7.513075252063572e-05 -->grad_value: 3.000981087097898e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.015101760625839233 -->grad_value: -0.0021595030557364225 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.013170246034860611 -->grad_value: -0.0021595030557364225 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.011661849915981293 -->grad_value: -0.000495135085657239 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight -0.0022850928362458944 -->grad_value: -6.500315521407174e-07 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.024469390511512756 -->grad_value: -0.00026341533521190286 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.027502508834004402 -->grad_value: -0.00026341533521190286 

INFO:root:-->name: lstm.weight_ih_l1 -->grad_requirs: True --weight -0.001270714565180242 -->grad_value: -5.856662028236315e-06 

INFO:root:-->name: lstm.weight_hh_l1 -->grad_requirs: True --weight 0.0011256986763328314 -->grad_value: 1.2977112419321202e-05 

INFO:root:-->name: lstm.bias_ih_l1 -->grad_requirs: True --weight -0.042735353112220764 -->grad_value: 0.00048004183918237686 

INFO:root:-->name: lstm.bias_hh_l1 -->grad_requirs: True --weight -0.047916825860738754 -->grad_value: 0.00048004183918237686 

INFO:root:-->name: lstm.weight_ih_l1_reverse -->grad_requirs: True --weight -0.001292888424359262 -->grad_value: -9.465557013754733e-06 

INFO:root:-->name: lstm.weight_hh_l1_reverse -->grad_requirs: True --weight -0.00023277556465473026 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l1_reverse -->grad_requirs: True --weight -0.024387482553720474 -->grad_value: 0.0009200166678056121 

INFO:root:-->name: lstm.bias_hh_l1_reverse -->grad_requirs: True --weight -0.0247504822909832 -->grad_value: 0.0009200166678056121 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.000424150814069435 -->grad_value: 0.00019348024216014892 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.028735686093568802 -->grad_value: 0.017996974289417267 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.0011494789505377412 -->grad_value: -0.23002508282661438 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight 0.0039037782698869705 -->grad_value: -1.110436201095581 

