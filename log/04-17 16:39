INFO:root:
 ======== Start Log Recording :04-17 16:39 ========

INFO:root:
 Model Initialization = LSTM(8, 128, bidirectional=True)
 *Parameters = <bound method Module.parameters of LSTM(8, 128, bidirectional=True)>

INFO:root:
 ** Round 0 : Batch size = 23 , avg loss = 0.664988337651543

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0016629695892334 -->grad_value: -0.030491527169942856 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight 0.001381382578983903 -->grad_value: -0.030170254409313202 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight -0.00044537149369716644 -->grad_value: -0.000408209947636351 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight 0.00012814727961085737 -->grad_value: -7.92593891674187e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight 0.0008270784164778888 -->grad_value: -0.0017693346599116921 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight 0.0010033249855041504 -->grad_value: -0.0017693346599116921 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0010162226390093565 -->grad_value: -0.0001773114054230973 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.0017568363109603524 -->grad_value: -0.0004154514754191041 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.003691357094794512 -->grad_value: -0.0004154514754191041 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.0002780636423267424 -->grad_value: 8.596137922722846e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight 0.007065620273351669 -->grad_value: -0.06974141299724579 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.02740582264959812 -->grad_value: -0.19392088055610657 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.0923503115773201 -->grad_value: -3.8538689613342285 

INFO:root:
 ** Round 1 : Batch size = 24 , avg loss = 0.7218090693155924

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9988886713981628 -->grad_value: 0.030625466257333755 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.007434302009642124 -->grad_value: 0.08046392351388931 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0009126760414801538 -->grad_value: 0.0024782975669950247 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0005586310871876776 -->grad_value: 2.1713720343541354e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00463009811937809 -->grad_value: 6.108541856519878e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.004453851841390133 -->grad_value: 6.108541856519878e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0017197637353092432 -->grad_value: -0.0007595641654916108 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.004405002109706402 -->grad_value: 0.00028750469209626317 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.006339523941278458 -->grad_value: 0.00028750469209626317 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.0007469758274964988 -->grad_value: -0.0005202265456318855 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.0001266738399863243 -->grad_value: 0.09441212564706802 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.023697249591350555 -->grad_value: 0.26066142320632935 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.0961047038435936 -->grad_value: 3.4474282264709473 

INFO:root:
 ** Round 2 : Batch size = 25 , avg loss = 0.6969880819320678

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9967547655105591 -->grad_value: -0.008960910141468048 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.008116001263260841 -->grad_value: -0.010216919705271721 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0009493154939264059 -->grad_value: 0.0008518756367266178 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0010150573216378689 -->grad_value: 9.393790605827235e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.008390361443161964 -->grad_value: 0.0009815015364438295 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.008214115165174007 -->grad_value: 0.0009815015364438295 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.001935657812282443 -->grad_value: 2.526168100303039e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.007998818531632423 -->grad_value: 0.00015184444782789797 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.00993334036320448 -->grad_value: 0.00015184444782789797 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.0007193748606368899 -->grad_value: 4.0216920751845464e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.005999852437525988 -->grad_value: 0.010001086629927158 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.018386609852313995 -->grad_value: 0.0007135556079447269 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.10770633071660995 -->grad_value: -0.014452338218688965 

INFO:root:
 ** Round 3 : Batch size = 25 , avg loss = 0.6887154912948609

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9977304935455322 -->grad_value: -0.0057798586785793304 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.011700967326760292 -->grad_value: 0.0850163996219635 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0011570617789402604 -->grad_value: -0.00013528918498195708 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0011464293347671628 -->grad_value: -4.431132765603252e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.009128785692155361 -->grad_value: -0.0009183822548948228 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.008952539414167404 -->grad_value: -0.0009183822548948228 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0023201708681881428 -->grad_value: -3.2211653888225555e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.006676146760582924 -->grad_value: -0.00027247704565525055 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.008610669523477554 -->grad_value: -0.00027247704565525055 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.0006799363764002919 -->grad_value: -7.683733565500006e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.005557585973292589 -->grad_value: -0.026439962908625603 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.019440142437815666 -->grad_value: -0.039481841027736664 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.10901905596256256 -->grad_value: -1.0190165042877197 

INFO:root:
 ** Round 4 : Batch size = 24 , avg loss = 0.6863115454713503

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9920005798339844 -->grad_value: -0.011482171714305878 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.02708754502236843 -->grad_value: 0.12441302835941315 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0028337733820080757 -->grad_value: -0.002016882412135601 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0011577989207580686 -->grad_value: 1.5361147234216332e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.00884354766458273 -->grad_value: 0.0011379439383745193 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.008667301386594772 -->grad_value: 0.0011379439383745193 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0020446283742785454 -->grad_value: -0.0004052145523019135 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.009328287094831467 -->grad_value: 0.0005762468790635467 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.011262807995080948 -->grad_value: 0.0005762468790635467 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.0007786486530676484 -->grad_value: 6.259281508391723e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.00543286232277751 -->grad_value: 0.0021533959079533815 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.01832200586795807 -->grad_value: 0.07136785984039307 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.09811539947986603 -->grad_value: -2.1942570209503174 

INFO:root:
 ** Round 5 : Batch size = 25 , avg loss = 0.6306040787696838

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9961634874343872 -->grad_value: -0.09504048526287079 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.03168192133307457 -->grad_value: -0.05147590488195419 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.006868329364806414 -->grad_value: -0.0014322276692837477 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.001366457319818437 -->grad_value: 1.5242258996295277e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.006804217584431171 -->grad_value: 4.990797606296837e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.006627972703427076 -->grad_value: 4.990797606296837e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0047053624875843525 -->grad_value: -0.0006958016892895103 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.00794885866343975 -->grad_value: -0.000608492991887033 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.009883380495011806 -->grad_value: -0.000608492991887033 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.0008484701393172145 -->grad_value: -4.176700531388633e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.006128960754722357 -->grad_value: -0.002534788567572832 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.01895034871995449 -->grad_value: -0.10847380757331848 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.09397298097610474 -->grad_value: -0.10379433631896973 

INFO:root:
 ** Round 6 : Batch size = 24 , avg loss = 0.8194401967921294

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9949216246604919 -->grad_value: 0.20224076509475708 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.028136780485510826 -->grad_value: 0.06691199541091919 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.0062045743688941 -->grad_value: 0.0077301329001784325 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0010821735486388206 -->grad_value: 3.650541475508362e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.006652778014540672 -->grad_value: 0.003373632673174143 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.00647653266787529 -->grad_value: 0.003373632673174143 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.0015646570827811956 -->grad_value: 0.007988925091922283 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.014166263863444328 -->grad_value: 0.00216365372762084 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.01610078476369381 -->grad_value: 0.00216365372762084 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.0007245365995913744 -->grad_value: 0.00033554621040821075 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.010497543029487133 -->grad_value: 0.07776142656803131 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.030795831233263016 -->grad_value: -0.498483806848526 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.09222517162561417 -->grad_value: 0.5388134717941284 

INFO:root:
 ** Round 7 : Batch size = 24 , avg loss = 0.6329804565757513

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9937310218811035 -->grad_value: -0.08232039213180542 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.03570801764726639 -->grad_value: 0.461165189743042 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.00796480756253004 -->grad_value: -0.004172791261225939 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0011398454662412405 -->grad_value: 0.00016860741015989333 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.013102719560265541 -->grad_value: 0.010245950892567635 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.012926475144922733 -->grad_value: 0.010245950892567635 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight 0.000580973457545042 -->grad_value: -0.0007719574496150017 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.01593514159321785 -->grad_value: -4.882208304479718e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.01786966249346733 -->grad_value: -4.882208304479718e-05 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight 0.00043639534851536155 -->grad_value: 0.0004413480346556753 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.013803405687212944 -->grad_value: 0.06414231657981873 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.03537365794181824 -->grad_value: 0.09156420826911926 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.09089794009923935 -->grad_value: 2.0642788410186768 

INFO:root:
 ** Round 8 : Batch size = 25 , avg loss = 0.7321351966354996

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9929087162017822 -->grad_value: 0.21376460790634155 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.048579152673482895 -->grad_value: 0.13380514085292816 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.008208345621824265 -->grad_value: 0.005552062764763832 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0017154308734461665 -->grad_value: 2.644932465045713e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.02088528871536255 -->grad_value: 0.00010953005403280258 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.020709041506052017 -->grad_value: 0.00010953005403280258 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0008547763573005795 -->grad_value: 0.0036124305333942175 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02306554839015007 -->grad_value: 0.0027262461371719837 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0250000711530447 -->grad_value: 0.0027262461371719837 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -4.4940708903595805e-05 -->grad_value: 0.0004825688083656132 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.024537554010748863 -->grad_value: 0.09681732952594757 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.026025237515568733 -->grad_value: 0.16985851526260376 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.10101884603500366 -->grad_value: 1.9159940481185913 

INFO:root:
 ** Round 9 : Batch size = 25 , avg loss = 0.6393685865402222

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9936041235923767 -->grad_value: -0.21415328979492188 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.050270892679691315 -->grad_value: -0.05237811431288719 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.007461352273821831 -->grad_value: 0.0002867693838197738 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0019066258100792766 -->grad_value: 2.86784052150324e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.02282797172665596 -->grad_value: 0.0036557966377586126 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.022651728242635727 -->grad_value: 0.0036557966377586126 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.002017166931182146 -->grad_value: -0.0006198781775310636 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02564815990626812 -->grad_value: -0.0009078368311747909 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0275826845318079 -->grad_value: -0.0009078368311747909 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00032439976348541677 -->grad_value: 0.00018538825679570436 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.029264898970723152 -->grad_value: -0.030930573120713234 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.02393079549074173 -->grad_value: -0.2067440003156662 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.09665660560131073 -->grad_value: -4.004637718200684 

INFO:root:
 ** Round 10 : Batch size = 24 , avg loss = 0.5830624485388398

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9946779012680054 -->grad_value: -0.060473278164863586 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.04900986701250076 -->grad_value: 0.030757147818803787 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.008031608536839485 -->grad_value: -0.0013237444218248129 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.002167354803532362 -->grad_value: 1.6915122614591382e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0236688069999218 -->grad_value: 0.00020795133605133742 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.023492559790611267 -->grad_value: 0.00020795133605133742 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0021995343267917633 -->grad_value: -0.0006977391894906759 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02450128272175789 -->grad_value: -0.0001156089419964701 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.02643580734729767 -->grad_value: -0.0001156089419964701 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0004460135824047029 -->grad_value: 3.193115844624117e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.028669655323028564 -->grad_value: -0.00564564298838377 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.027744624763727188 -->grad_value: 0.08845318853855133 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.08880383521318436 -->grad_value: 0.11005133390426636 

INFO:root:
 ** Round 11 : Batch size = 25 , avg loss = 0.6831856626272201

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9918109178543091 -->grad_value: 0.20920486748218536 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.05089278519153595 -->grad_value: 0.21769794821739197 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010032099671661854 -->grad_value: -0.002404498402029276 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0019892307464033365 -->grad_value: -3.399112029001117e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.022975817322731018 -->grad_value: -0.0028407052159309387 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.022799571976065636 -->grad_value: -0.0028407052159309387 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0022791472729295492 -->grad_value: 0.00010662199929356575 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.024678941816091537 -->grad_value: -0.0006207264959812164 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.026613466441631317 -->grad_value: -0.0006207264959812164 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0005805058171972632 -->grad_value: 0.00034220347879454494 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.030029181391000748 -->grad_value: 0.01801726222038269 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.027767006307840347 -->grad_value: 0.176802396774292 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.10172222554683685 -->grad_value: 3.4198031425476074 

INFO:root:
 ** Round 12 : Batch size = 24 , avg loss = 0.7685436426351467

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9976373910903931 -->grad_value: -0.06563535332679749 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.04764699935913086 -->grad_value: 0.049538783729076385 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010567011311650276 -->grad_value: 0.015027588233351707 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0016503514489158988 -->grad_value: 2.0936971850460395e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.03206038847565651 -->grad_value: 0.010882407426834106 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.03188414126634598 -->grad_value: 0.010882407426834106 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0027964164037257433 -->grad_value: 3.356768866069615e-05 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.024595316499471664 -->grad_value: 5.9243597206659615e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.026529837399721146 -->grad_value: 5.9243597206659615e-05 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00041780032915994525 -->grad_value: -0.000343176769092679 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.03354838117957115 -->grad_value: 0.03759570047259331 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.01932617276906967 -->grad_value: 0.6337391138076782 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.11389170587062836 -->grad_value: -0.5958924293518066 

INFO:root:
 ** Round 13 : Batch size = 24 , avg loss = 0.6528008238722881

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0032129287719727 -->grad_value: -0.107216477394104 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.04082346707582474 -->grad_value: -0.12800544500350952 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010533548891544342 -->grad_value: -0.002503461902961135 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.001750101917423308 -->grad_value: 1.3066109204373788e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.03612777218222618 -->grad_value: 1.0062649380415678e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.03595152497291565 -->grad_value: 1.0062649380415678e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0026739081367850304 -->grad_value: -0.000896110781468451 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02468593791127205 -->grad_value: -6.21614744886756e-05 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.02662046067416668 -->grad_value: -6.21614744886756e-05 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00037151918513700366 -->grad_value: 0.0001552342582726851 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.034004874527454376 -->grad_value: -0.026729097589850426 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.017503704875707626 -->grad_value: -0.16487471759319305 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.10592252016067505 -->grad_value: -2.8448915481567383 

INFO:root:
 ** Round 14 : Batch size = 23 , avg loss = 0.5500221727010997

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.0041918754577637 -->grad_value: -0.07192020118236542 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.03909773379564285 -->grad_value: -0.029573027044534683 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010723276995122433 -->grad_value: -0.0003956448344979435 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0018105949275195599 -->grad_value: -3.9224835290951887e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.0358850434422493 -->grad_value: 0.00021101805032230914 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.035708799958229065 -->grad_value: 0.00021101805032230914 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0021359315142035484 -->grad_value: -0.0002630618691910058 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02421071007847786 -->grad_value: -0.00028861628379672766 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.02614523097872734 -->grad_value: -0.00028861628379672766 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0004343853215686977 -->grad_value: 4.3926265789195895e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.033492881804704666 -->grad_value: -0.007190943229943514 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.020311754196882248 -->grad_value: -0.23629654943943024 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.10099542886018753 -->grad_value: 0.42464879155158997 

INFO:root:
 ** Round 15 : Batch size = 25 , avg loss = 0.6451947446353734

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 1.002406120300293 -->grad_value: -0.006104663014411926 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.039242155849933624 -->grad_value: 0.11708265542984009 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010860328562557697 -->grad_value: 0.005102910567075014 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0017735834699124098 -->grad_value: -5.6170247262343764e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.03541179001331329 -->grad_value: -0.0015758909285068512 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.03523554652929306 -->grad_value: -0.0015758909285068512 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0017056262586265802 -->grad_value: 0.00011210594675503671 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.023938143625855446 -->grad_value: 0.0004335692501626909 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.025872666388750076 -->grad_value: 0.0004335692501626909 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0004953679163008928 -->grad_value: 7.675193774048239e-05 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.03330807760357857 -->grad_value: 0.01067683007568121 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.022199781611561775 -->grad_value: 0.036687031388282776 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.09456314146518707 -->grad_value: -1.06675386428833 

INFO:root:
 ** Round 16 : Batch size = 25 , avg loss = 0.6511736726760864

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9987807869911194 -->grad_value: -0.076015904545784 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.03662458062171936 -->grad_value: -0.25469672679901123 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.01094810664653778 -->grad_value: -0.0007771527743898332 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0017632124945521355 -->grad_value: 5.406581067290972e-07 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.03479384630918503 -->grad_value: -0.0012195351300761104 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.034617602825164795 -->grad_value: -0.0012195351300761104 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0015614376170560718 -->grad_value: 0.0004812753468286246 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02337520569562912 -->grad_value: -0.0008490571053698659 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.0253097265958786 -->grad_value: -0.0008490571053698659 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0005058867391198874 -->grad_value: -0.0002114418166456744 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.03218834847211838 -->grad_value: -0.060768142342567444 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.024295972660183907 -->grad_value: -0.2978909909725189 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.08666815608739853 -->grad_value: -4.038769245147705 

INFO:root:
 ** Round 17 : Batch size = 25 , avg loss = 0.6729506865143776

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9946350455284119 -->grad_value: 0.09769406914710999 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.03519584238529205 -->grad_value: 0.09228762984275818 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010972504504024982 -->grad_value: -0.002225978299975395 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0019396183779463172 -->grad_value: 1.1369545063644182e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.035472676157951355 -->grad_value: 4.1564751882106066e-05 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.03529643267393112 -->grad_value: 4.1564751882106066e-05 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.001971331425011158 -->grad_value: 0.00024124569608829916 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.024206751957535744 -->grad_value: 0.0010575917549431324 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.026141274720430374 -->grad_value: 0.0010575917549431324 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0005216312711127102 -->grad_value: 0.00014793602167628706 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.033497970551252365 -->grad_value: 0.03816395252943039 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.025110531598329544 -->grad_value: 0.05479099228978157 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.08655060082674026 -->grad_value: 1.1347386837005615 

INFO:root:
 ** Round 18 : Batch size = 25 , avg loss = 0.5878865602560108

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9937340021133423 -->grad_value: -0.06116102635860443 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.035510413348674774 -->grad_value: -0.2400086522102356 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.011084392666816711 -->grad_value: 0.0020176151301711798 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0020833355374634266 -->grad_value: 1.5217066902550869e-05 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.03573005646467209 -->grad_value: 0.0001435475132893771 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.035553812980651855 -->grad_value: 0.0001435475132893771 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.0020443801768124104 -->grad_value: 0.0014553205110132694 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02429286018013954 -->grad_value: -0.0005373214371502399 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.026227381080389023 -->grad_value: -0.0005373214371502399 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0005361265502870083 -->grad_value: -0.00013911873975303024 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.033792369067668915 -->grad_value: -0.03883391246199608 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.026023704558610916 -->grad_value: -0.3730679750442505 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.09055045247077942 -->grad_value: -2.298635721206665 

INFO:root:
 ** Round 19 : Batch size = 25 , avg loss = 0.8044719952344894

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9887900352478027 -->grad_value: 0.2746950089931488 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.04500381276011467 -->grad_value: 0.7667079567909241 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.010129870846867561 -->grad_value: 0.005744886118918657 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.001978154294192791 -->grad_value: -5.492263426276622e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.03953520581126213 -->grad_value: 0.005396501626819372 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.039358966052532196 -->grad_value: 0.005396501626819372 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.002144576283171773 -->grad_value: -0.00038613667129538953 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.025426778942346573 -->grad_value: 0.0009665465913712978 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.027361301705241203 -->grad_value: 0.0009665465913712978 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.0004966604756191373 -->grad_value: -0.00020224382751621306 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.03543455898761749 -->grad_value: 0.09517496824264526 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.02342347800731659 -->grad_value: 0.5619156360626221 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.10345403850078583 -->grad_value: 6.015052795410156 

INFO:root:
 ** Round 20 : Batch size = 23 , avg loss = 0.7614348835878723

INFO:root:-->name: normalization.weight -->grad_requirs: True --weight 0.9849296808242798 -->grad_value: 0.30790290236473083 

INFO:root:-->name: normalization.bias -->grad_requirs: True --weight -0.05289550870656967 -->grad_value: 0.19203966856002808 

INFO:root:-->name: lstm.weight_ih_l0 -->grad_requirs: True --weight 0.00911547802388668 -->grad_value: 0.0032441173680126667 

INFO:root:-->name: lstm.weight_hh_l0 -->grad_requirs: True --weight -0.0018731189193204045 -->grad_value: 4.026689566671848e-06 

INFO:root:-->name: lstm.bias_ih_l0 -->grad_requirs: True --weight -0.04338456690311432 -->grad_value: 0.0023886743001639843 

INFO:root:-->name: lstm.bias_hh_l0 -->grad_requirs: True --weight -0.043208327144384384 -->grad_value: 0.0023886743001639843 

INFO:root:-->name: lstm.weight_ih_l0_reverse -->grad_requirs: True --weight -0.002008163370192051 -->grad_value: -0.0010533775202929974 

INFO:root:-->name: lstm.weight_hh_l0_reverse -->grad_requirs: True --weight 0.00032063270919024944 -->grad_value: 0.0 

INFO:root:-->name: lstm.bias_ih_l0_reverse -->grad_requirs: True --weight -0.02687627077102661 -->grad_value: 0.0012483360478654504 

INFO:root:-->name: lstm.bias_hh_l0_reverse -->grad_requirs: True --weight -0.028810793533921242 -->grad_value: 0.0012483360478654504 

INFO:root:-->name: linears.0.weight -->grad_requirs: True --weight -0.00043267617002129555 -->grad_value: -0.0003207713598385453 

INFO:root:-->name: linears.0.bias -->grad_requirs: True --weight -0.03770192340016365 -->grad_value: 0.03302791714668274 

INFO:root:-->name: linears.3.weight -->grad_requirs: True --weight 0.018330559134483337 -->grad_value: 0.572553277015686 

INFO:root:-->name: linears.3.bias -->grad_requirs: True --weight -0.11491032689809799 -->grad_value: 2.220200300216675 

INFO:root:TEST Processing --> pred = tensor([0.6791], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4636], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4628], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4616], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6916], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4658], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4639], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4667], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4885], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4637], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4626], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5533], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4849], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4614], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4645], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5218], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4721], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4634], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9663], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5811], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4765], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4699], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4631], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5721], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5292], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4606], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5677], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4640], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4610], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4573], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4616], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4731], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4618], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4685], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4687], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4616], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4667], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4802], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5142], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4624], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4578], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4711], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5634], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4712], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9593], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5559], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4622], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4693], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.7697], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4730], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4713], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5087], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4697], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4687], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4543], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4758], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4618], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4729], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4731], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6725], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4620], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4965], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4668], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4591], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4627], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4701], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4627], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4672], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4642], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4621], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6328], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4563], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5215], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.9577], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4669], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4597], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6066], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.9779], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5545], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6137], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4620], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4711], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4607], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5034], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4825], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4576], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4815], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4586], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4614], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3083], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4864], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4760], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5600], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5842], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4734], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5271], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4995], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4770], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4619], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4813], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4678], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9893], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4630], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4698], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4640], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4748], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4958], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4688], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4928], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4681], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4744], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4814], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4620], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4778], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4644], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5478], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4642], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5575], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9511], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4619], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4910], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4627], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4583], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4766], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5195], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.2813], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5333], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3082], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4563], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4833], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4599], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4875], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4569], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4612], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4658], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4612], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4566], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4603], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4658], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6978], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4701], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6052], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4617], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4698], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4672], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4590], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4659], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4596], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5666], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4603], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4962], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4732], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4899], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5359], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4660], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4654], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4738], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.7437], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4987], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5529], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4729], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6326], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4840], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4845], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4762], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9643], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9810], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4605], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4611], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4629], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4918], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4833], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.3413], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4577], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6542], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4666], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4854], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4586], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4574], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4645], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4578], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4603], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4698], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4866], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5019], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4573], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.8529], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4601], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4686], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4574], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4681], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4580], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4574], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4737], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4868], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4709], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.9849], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4675], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4567], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4747], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.7575], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4653], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.7592], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4722], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5712], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4717], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5147], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.6998], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4737], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4573], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5667], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.7361], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.9284], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4773], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4683], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4793], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4875], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6052], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4645], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4706], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4711], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5272], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4637], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4629], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5886], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4711], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4593], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4603], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9768], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4636], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.7420], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5121], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.9343], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4571], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4547], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4609], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5247], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4708], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5086], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5077], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4621], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.2552], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:
** TEST RESULT --> Accurary = 2.4223814397816446% **

INFO:root:TEST Processing --> pred = tensor([0.6791], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4636], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4628], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4616], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.6916], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4658], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4639], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4667], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4885], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4637], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4626], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5533], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4849], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4614], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4645], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5218], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4721], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4634], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.9663], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5811], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4765], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4699], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4631], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5721], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5292], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4606], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5677], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4640], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4610], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4573], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4616], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4731], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4618], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4685], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4687], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4616], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4667], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4802], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.5142], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4624], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.4578], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4711], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
INFO:root:TEST Processing --> pred = tensor([0.5634], device='mps:0', grad_fn=<SigmoidBackward0>) target = 1.0
INFO:root:TEST Processing --> pred = tensor([0.4712], device='mps:0', grad_fn=<SigmoidBackward0>) target = 0.0
